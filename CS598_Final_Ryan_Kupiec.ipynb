{"cells":[{"cell_type":"code","source":["# NEEDED PACKAGES\n","!pip install --upgrade transformers==4.30.2 tqdm==4.64.1\n","!pip install --upgrade \\\n","  torch torchvision torchaudio \\\n","  transformers \\\n","  pytorch-pretrained-bert \\\n","  scikit-learn \\\n","  pandas \\\n","  tqdm \\\n","  dotmap \\\n","  matplotlib"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"s29w49gl9Jh8","executionInfo":{"status":"ok","timestamp":1746492457819,"user_tz":300,"elapsed":185598,"user":{"displayName":"Ryan Kupiec","userId":"06324388248644264738"}},"outputId":"73fadedc-31a6-4480-dfaa-27be2b64f5d6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.30.2\n","  Downloading transformers-4.30.2-py3-none-any.whl.metadata (113 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tqdm==4.64.1\n","  Downloading tqdm-4.64.1-py2.py3-none-any.whl.metadata (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (0.30.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (2.32.3)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.2)\n","  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.30.2) (0.5.3)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (2025.3.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.30.2) (2025.4.26)\n","Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, tqdm, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.21.1\n","    Uninstalling tokenizers-0.21.1:\n","      Successfully uninstalled tokenizers-0.21.1\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.67.1\n","    Uninstalling tqdm-4.67.1:\n","      Successfully uninstalled tqdm-4.67.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.51.3\n","    Uninstalling transformers-4.51.3:\n","      Successfully uninstalled transformers-4.51.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.30.2 which is incompatible.\n","dataproc-spark-connect 0.7.2 requires tqdm>=4.67, but you have tqdm 4.64.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tokenizers-0.13.3 tqdm-4.64.1 transformers-4.30.2\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Collecting torch\n","  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n","Collecting torchvision\n","  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Collecting torchaudio\n","  Downloading torchaudio-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.30.2)\n","Collecting transformers\n","  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n","Collecting pytorch-pretrained-bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl.metadata (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Collecting pandas\n","  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.64.1)\n","Collecting tqdm\n","  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dotmap\n","  Downloading dotmap-1.3.30-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Collecting matplotlib\n","  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n","Collecting sympy>=1.13.3 (from torch)\n","  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n","  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n","  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n","  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n","Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n","  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n","Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n","  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n","  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n","Collecting triton==3.3.0 (from torch)\n","  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch) (75.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Collecting tokenizers<0.22,>=0.21 (from transformers)\n","  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Collecting boto3 (from pytorch-pretrained-bert)\n","  Downloading boto3-1.38.9-py3-none-any.whl.metadata (6.6 kB)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Collecting botocore<1.39.0,>=1.38.9 (from boto3->pytorch-pretrained-bert)\n","  Downloading botocore-1.38.9-py3-none-any.whl.metadata (5.7 kB)\n","Collecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch-pretrained-bert)\n","  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n","Collecting s3transfer<0.13.0,>=0.12.0 (from boto3->pytorch-pretrained-bert)\n","  Downloading s3transfer-0.12.0-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n","Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m134.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchaudio-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dotmap-1.3.30-py3-none-any.whl (11 kB)\n","Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m138.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m131.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading boto3-1.38.9-py3-none-any.whl (139 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading botocore-1.38.9-py3-none-any.whl (13.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Downloading s3transfer-0.12.0-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, dotmap, triton, tqdm, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jmespath, pandas, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, matplotlib, botocore, tokenizers, s3transfer, nvidia-cusolver-cu12, transformers, torch, boto3, torchvision, torchaudio, pytorch-pretrained-bert\n","  Attempting uninstall: nvidia-cusparselt-cu12\n","    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n","    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n","      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.2.0\n","    Uninstalling triton-3.2.0:\n","      Successfully uninstalled triton-3.2.0\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.64.1\n","    Uninstalling tqdm-4.64.1:\n","      Successfully uninstalled tqdm-4.64.1\n","  Attempting uninstall: sympy\n","    Found existing installation: sympy 1.13.1\n","    Uninstalling sympy-1.13.1:\n","      Successfully uninstalled sympy-1.13.1\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.4.127\n","    Uninstalling nvidia-nvtx-cu12-12.4.127:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.21.5\n","    Uninstalling nvidia-nccl-cu12-2.21.5:\n","      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 2.2.2\n","    Uninstalling pandas-2.2.2:\n","      Successfully uninstalled pandas-2.2.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.10.0\n","    Uninstalling matplotlib-3.10.0:\n","      Successfully uninstalled matplotlib-3.10.0\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.13.3\n","    Uninstalling tokenizers-0.13.3:\n","      Successfully uninstalled tokenizers-0.13.3\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.30.2\n","    Uninstalling transformers-4.30.2:\n","      Successfully uninstalled transformers-4.30.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.6.0+cu124\n","    Uninstalling torch-2.6.0+cu124:\n","      Successfully uninstalled torch-2.6.0+cu124\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.21.0+cu124\n","    Uninstalling torchvision-0.21.0+cu124:\n","      Successfully uninstalled torchvision-0.21.0+cu124\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.6.0+cu124\n","    Uninstalling torchaudio-2.6.0+cu124:\n","      Successfully uninstalled torchaudio-2.6.0+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n","fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed boto3-1.38.9 botocore-1.38.9 dotmap-1.3.30 jmespath-1.0.1 matplotlib-3.10.1 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 pandas-2.2.3 pytorch-pretrained-bert-0.6.2 s3transfer-0.12.0 sympy-1.14.0 tokenizers-0.21.1 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0 tqdm-4.67.1 transformers-4.51.3 triton-3.3.0\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"id":"q01IXfGrOjvr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746502601998,"user_tz":300,"elapsed":444,"user":{"displayName":"Ryan Kupiec","userId":"06324388248644264738"}},"outputId":"29501a67-1608-41dd-eedf-bee3bfe1fa09"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["# Mount to your drive so you can persist data and find the repo in your drive\n","from google.colab import drive\n","drive.mount('/content/drive/', force_remount=False)"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"NTAI5-mnPKEW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746502603618,"user_tz":300,"elapsed":34,"user":{"displayName":"Ryan Kupiec","userId":"06324388248644264738"}},"outputId":"99d96529-76f0-4cf0-d0e7-911eb9294dc9"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CS598-DL-Healthcare/FTL-Trans\n"]}],"source":["# Original cloning\n","#!git clone https://github.com/zdy93/FTL-Trans.git\n","%cd /content/drive/MyDrive/CS598-DL-Healthcare/FTL-Trans"]},{"cell_type":"code","source":["# This piece pre-processes your raw data file created by merging and subsetting the NOTEEVENTS + ADMISSIONS datasets\n","# bert-large-uncased, bert-base-uncased, clinical-bert\n","!python preprocessing.py \\\n","  --original_data \"../mortality.csv\" \\\n","  --output_dir \"../clinical-bert-data\" \\\n","  --temp_dir \"../clinical-bert-tmp\" \\\n","  --task_name \"FTLTrans_Readmission\" \\\n","  --log_path \"../whatever.txt\" \\\n","  --id_num_neg 5276 \\\n","  --id_num_pos 5276 \\\n","  --random_seed 42 \\\n","  --bert_model \"./ClinicalBERT_pretraining\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"bo2KKPkKk8oU","executionInfo":{"status":"ok","timestamp":1746499845131,"user_tz":300,"elapsed":1287585,"user":{"displayName":"Ryan Kupiec","userId":"06324388248644264738"}},"outputId":"43ff949e-2ad5-497d-93ee-1f1a0655763a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["New Pre-processing Job Start! \n","original_data: ../mortality.csv, output_dir: ../clinical-bert-data, temp_dir: ../clinical-bert-tmp \n","task_name: FTLTrans_Readmission, log_path: ../whatever.txt\n","id_num_neg: 5276, id_num_pos: 5276\n","random_seed: 42, bert_model: ./ClinicalBERT_pretraining\n","chunk 0 tokenize start!\n","First sentence tokenized\n","['normal', 'sin', '##us', 'rhythm', '.', 'non', '-', 'diagnostic', 'rep', '##olar', '##ization', 'abnormalities', '.', 'compared', 'to', 'the', '##pre', '##vious', 'tracing', 'of', 'no', 'major', 'change', ',', 'although', 'non', '-', 'diagnostic', 'rep', '##olar', '##ization', 'abnormalities', 'are', 'now', 'evident', '.', 'tracing', '#', '2']\n","chunk 1 tokenize start!\n","First sentence tokenized\n","['clinical', 'nutrition', 'o', ':', '~', '28', 'w', '##k', 'c', '##ga', 'bb', 'on', 'do', '##l', 'w', '##t', ':', '97', '##0', 'g', '(', '-', '60', ')', '(', '~', '25th', 'to', '50th', '%', 'ile', ')', ';', 'birth', 'w', '##t', ':', '124', '##5', 'g', '.', 'w', '##t', 'currently', 'down', '~', '22', '%', 'from', 'birth', 'w', '##t', '.', 'hc', ':', '25', 'cm', '(', '~', '10th', 'to', '25th', '%', 'ile', ')', ';', 'last', ':', '75', 'cm', 'l', '##n', ':', '39', 'cm', '(', '~', '50th', 'to', '75th', '%', 'ile', ')', ';', 'last', ':', '5', 'cm', 'noted', 'nutrition', ':', '160', 'cc', '/', 'kg', '/', 'day', 't', '##f', '.', 'feeds', 'currently', '@', '70', 'cc', '/', 'kg', '/', 'day', 'b', '##m', '20', ',', 'increasing', '10', 'cc', '/', 'kg', '/', '.', 'remainder', 'of', 'fluids', 'as', 'p', '##n', 'via', 'du', '##vc', ';', 'plan', 'to', 'pull', 'du', '##vc', 'today', 'after', 'new', 'p', '##n', 'comes', 'up', 'and', 'run', 'via', 'pi', '##v', '.', 'projected', 'intake', 'for', 'next', '24', 'hr', '##s', 'from', 'p', '##n', '~', '35', 'kc', '##al', '/', 'kg', '/', 'day', ',', '~', '1', 'g', 'pro', '/', 'kg', '/', 'day', ',', 'and', 'no', 'lip', '##ids', '.', 'from', 'en', ':', '~', '53', 'kc', '##al', '/', 'kg', '/', 'day', ',', '~', '8', 'g', 'pro', '/', 'kg', '/', 'day', 'and', '3', 'g', 'fat', '/', 'kg', '/', 'day', '.', 'gi', '##r', 'from', 'p', '##n', '~', '5', 'mg', '/', 'kg', '/', 'min', '.', 'gi', ':', 'abdomen', 'benign', '.', 'a', '/', 'goals', ':', 'to', '##ler', '##ating', 'p', '##n', 'with', 'good', 'bs', 'control', '.', 'to', '##ler', '##ating', 'feeds', 'without', 'gi', 'problems', '.', 'noted', 'and', 'p', '##n', 'adjusted', 'accordingly', '.', 't', '##f', 'increased', 'due', 'to', 'significant', 'w', '##t', 'loss', '.', 'current', 'p', '##n', '+', 'feeds', 'meeting', 'rec', '##s', 'for', 'fat', 'and', 'vi', '##ts', '.', 'not', 'meeting', 'rec', '##s', 'for', 'kc', '##als', '/', 'pro', '/', 'and', 'minerals', 'due', 'to', 'loss', 'of', 'central', 'line', 'today', ',', 'but', 'no', 'plan', 'to', 'place', 'pic', '##c', 'line', 'as', 'infant', 'is', 'advancing', 'and', 'to', '##ler', '##ating', 'feeds', 'well', 'and', 'will', 'be', 'meeting', 'full', 'nutrition', 'rec', '##s', 'when', 'feeds', 'advance', 'to', '~', '150', 'cc', '/', 'kg', '/', 'day', 'b', '##m', '/', 'ss', '##c', 'growth', 'should', 'improve', 'as', 'feeds', 'advance', 'to', 'initial', 'goal', '.', 'will', 'continue', 'to', 'follow', 'w', '/', 'team', 'and', 'participate', 'in', 'nutrition', 'plans', '.']\n","chunk 2 tokenize start!\n","First sentence tokenized\n","['np', '##n', '(', '07', '##00', '-', '1900', ')', 'review', 'of', 'systems', ':', 'ne', '##uro', ':', 'more', 'let', '##har', '##gic', 'today', ',', 'ar', '##ouse', '##s', 'to', 'voice', 'and', 'stimuli', ',', 'opens', 'eyes', ',', 'not', 'answering', 'yes', '/', 'no', 'questions', ',', 'mae', ',', 'continues', 'with', 'l', 'sided', 'weakness', '.', 'withdraw', '##s', 'all', 'ex', '##tre', '##mit', '##ies', 'to', 'nail', 'bed', 'pressure', '.', 'per', '##rl', 'c', 'l', 'pupil', 'irregular', 'in', 'shape', '.', 'mri', 'yesterday', 'no', 'significant', 'change', 'per', 'dr', '.', 'cv', ':', 'ns', '##r', 'c', 'hr', '=', '60', '-', '100', ',', 'no', 'ec', '##top', '##y', '.', 'sb', '##p', '140', '-', '160', '##s', ',', 'ni', '##pr', '##ide', 'drip', 'we', '##ane', '##d', 'off', '.', 'iv', 'lo', '##press', '##or', ',', 'iv', 'hydra', '##li', '##zine', 'and', 'po', 'capt', '##op', '##ril', 'continues', '.', 'a', 'line', 'd', '/', 'c', \"'\", 'd', '.', 'color', 'pink', ',', 'skin', 'warm', 'and', 'dry', '.', 'pal', '##pa', '##ble', 'pulses', '.', 'res', '##p', ':', 'l', '##s', 'd', '##m', 'at', 'bases', ',', 'sao', '##2', '=', '95', '-', '98', '%', 'ra', '.', '+', 'np', '##c', '.', 'gi', ':', 'abd', 'soft', ',', '+', 'bs', '##x', 'impact', 'with', 'fiber', 'at', 'goal', 'of', '90', '##cc', '/', 'hr', 'in', '##fus', '##ing', 'via', 'do', '##bh', '##off', 'tube', '.', 'proton', '##ix', 'and', 'cara', '##fat', '##e', 'd', '/', 'c', \"'\", 'd', '.', 'lb', '##m', '.', 'gu', ':', 'ind', '##well', '##ing', 'foley', 'intact', 'and', 'draining', 'clear', 'yellow', 'urine', ',', 'su', '##ffi', '##cent', 'u', '##o', '.', 'hem', '##e', ':', 'no', 'new', 'issues', '.', 'sq', 'he', '##par', '##in', '.', 'id', ':', 't', '##max', '=', '1', '##po', 'and', 'am', 'wb', '##c', '=', '8', '(', '1', ')', ',', 'pt', 'pan', 'culture', '##d', 'except', 'unable', 'to', 'obtain', 'sp', '##ut', '##um', 'sample', '.', 'z', '##os', '##yn', 'and', 'flag', '##yl', 'd', '/', 'c', \"'\", 'd', '.', 'end', '##o', ':', 'coverage', 'required', 'per', 'ri', '##ss', '.', 'skin', ':', 'skin', 'warm', 'and', 'dry', '.', 'l', 'head', '/', 'neck', 'con', '##tus', '##ion', 'unchanged', '.', 'co', '##cc', '##yx', 'red', '##dened', ',', 'no', 'change', '.', 'pt', 'turned', 'and', 'rep', '##osition', '##ed', ',', 'air', 'mattress', 'in', 'place', '.', 'skin', 'care', 'provided', '.', 'activity', ':', 'pt', 'o', '##ob', 'to', 'chair', 'pi', '##vio', '##t', 'c', '3', 'assist', 'and', 'required', 'slide', 'board', 'on', 'return', 'back', 'to', 'bed', ',', 'pt', 'to', '##l', 'well', '.', 'soc', ':', 'no', 'contact', 'from', 'family', 'this', 'shift', '.', 'plan', ':', 'continue', 'support', 'as', 'above', '.', 'continue', 'to', 'follow', 'ne', '##uro', 'status', '.', '?', 'change', 'iv', 'med', '##s', 'to', 'po', 'med', '##s', '.']\n","chunk 3 tokenize start!\n","First sentence tokenized\n","['newborn', 'med', 'attending', 'do', '##l', '#', 'con', '##t', 'in', 'ra', ',', 'no', 'spells', '.', 'af', 'flat', ',', 'clear', 'bs', ',', 'no', 'murmur', ',', 'abd', 'soft', ',', 'mae', '.', 'w', '##t', '=', '232', '##5', 'up', '10', ',', 'min', 'of', '120', 'cc', '/', 'kg', '.', 'bi', '##li', '=', 'a', '/', 'p', ':', 'growing', 'infant', 'with', 'slug', '##gis', '##h', 'po', 'feeding', '.', 'con', '##t', 'to', 'encourage', 'po', 'feeds', '.', 'repeat', 'bi', '##li', 'in', 'am', '.']\n","chunk 4 tokenize start!\n","First sentence tokenized\n","['3', ':', '19', 'pm', 'chest', '(', 'portable', 'ap', ')', 'clip', '#', 'reason', ':', 'eva', '##l', 'for', 'p', '##ne', '##um', '##o', 's', '/', 'p', 'left', 'sc', 'line', 'placement', 'and', 'eva', '##l', 'lu', '##l', 'p', '##ne', '##u', 'medical', 'condition', ':', '52', 'year', 'old', 'man', 'with', 'p', '##na', 'int', '##uba', '##ted', '.', 'reason', 'for', 'this', 'examination', ':', 'eva', '##l', 'for', 'p', '##ne', '##um', '##o', 's', '/', 'p', 'left', 'sc', 'line', 'placement', 'and', 'eva', '##l', 'lu', '##l', 'pneumonia', 'due', 'to', 'st', '##re', '##p', 'p', '##ne', '##um', '##o', 'after', 'int', '##iation', 'of', 'pc', '##n', '.', 'final', 'report', 'indication', ':', 'pneumonia', ',', 'int', '##uba', '##ted', ',', 'left', 'sub', '##cl', '##avian', 'line', 'placement', '.', 'single', 'frontal', 'chest', 'radio', '##graph', 'dated', 'is', 'compared', 'with', 'prior', 'c', '##x', '##r', 'dated', '.', 'et', 'tube', 'terminates', 'approximately', '5', 'cm', 'above', 'the', 'car', '##ina', '.', 'the', 'left', 'sub', '##cl', '##avian', 'cat', '##het', '##er', 'is', 'poorly', 'seen', 'distal', '##ly', ',', 'probably', 'terminating', 'in', 'the', 'upper', 'sv', '##c', '.', 'note', 'is', 'again', 'made', 'of', 'the', 'left', 'lung', 'op', '##ac', '##ification', 'with', 'probable', 'associated', 'pl', '##eur', '##al', 'e', '##ff', '##usion', '.', 'impression', ':', 'no', 'significant', 'change', 'since', 'the', 'prior', 'study', ',', 'allowing', 'for', 'the', 'technical', 'difference', '.', 'there', 'is', 'no', 'evidence', 'of', 'p', '##ne', '##um', '##otho', '##ra', '##x', '.']\n","chunk 5 tokenize start!\n","First sentence tokenized\n","['np', '##n', '7', '##p', '-', '7', '##a', 'sep', '##sis', ':', 'infant', 'continues', 'on', 'amp', '##i', '/', 'gen', '##t', '.', 'cbc', 'benign', '.', 'b', '##ld', 'c', '##x', 'pending', '.', 'infant', 'showing', 'no', 'over', '##t', 's', '/', 's', 'of', 'infection', '.', 'temps', 'stable', '.', 'continue', 'to', 'monitor', 'for', 'sep', '##sis', '.', 'res', '##p', ':', 'infant', 'remains', 'in', 'nc', 'o', '##2', '100', '%', ',', '13', '##cc', 'flow', 'rate', '.', 'sat', '##ting', '97', '-', '98', '%', '.', 'l', '##s', 'cl', '/', '=', 'with', 'sub', '##cos', '##tal', '/', 'sub', '##ster', '##nal', 're', '##t', '##x', '##ns', ',', 'moderate', 'at', 'times', '.', 'intermittent', 'grunt', '##ing', 'noted', 'during', 'ton', '##oc', '.', 'rr', '30', '-', '70', \"'\", 's', '.', 'continue', 'to', 'provide', 'respiratory', 'support', 'and', 'assess', 'respiratory', 'status', '.', 'fen', ':', 'b', '##w', '266', '##3', ',', 'cw', '259', '##5', '(', 'down', '68', '##g', ')', '.', 't', '##f', '60', '##cc', '/', 'k', '/', 'd', 'of', 'd', '##10', '=', '7', '##cc', '/', 'hr', 'in', '##fus', '##ing', 'via', 'pi', '##v', 'in', 'l', '.', 'hand', ';', 'without', 'incident', '.', 'infant', 'bf', 'x', '##2', 'and', 'bottled', '15', '##cc', 'each', 'time', 'after', '.', 'infant', 'unable', 'to', 'latch', ',', 'acting', 'sleepy', 'at', 'breast', '.', 'mom', 'pumping', 'scan', '##t', 'amount', 'of', 'col', '##ost', '##rum', '.', 'abd', '.', 'benign', '.', 'gi', '##rth', '26', '##cm', '.', 'void', '##ing', ',', 'no', 'stool', '.', 'ds', 'continue', 'to', 'encourage', 'po', \"'\", 's', 'and', 'we', '##an', 'iv', 'when', 'respiratory', 'status', 'stable', '.', 'parents', ':', 'mom', 'and', 'dad', 'in', 'to', 'visit', '.', 'mom', 'participated', 'in', 'cares', ';', 'changed', 'dia', '##per', 'and', 'took', 'te', '##mp', ';', 'held', 'and', 'bf', 'infant', '.', 'both', 'asking', 'appropriate', 'questions', '.', 'excited', 'about', 'first', 'baby', '.', 'returned', 'for', '02', '##00', 'cares', '.', 'continue', 'to', 'support', 'and', 'update', '.', 'dev', ':', 'infant', 'nest', '##ed', 'on', 'ser', '##vo', 'warmer', '.', 'temps', 'stable', '.', 'alert', 'and', 'active', 'with', 'cares', ';', 'slightly', 'ir', '##rita', '##ble', '.', 'mae', '.', 'sucking', 'some', 'on', 'pac', '##ifier', '.', 'learning', 'how', 'to', 'bf', 'and', 'bottle', '.', 'continue', 'to', 'support', 'growth', 'and', 'development', '.']\n","chunk 6 tokenize start!\n","First sentence tokenized\n","['probable', 'at', '##rial', 'fi', '##bri', '##llation', 'with', 'at', '##rial', 'pacing', 'spikes', 'that', 'don', \"'\", 't', 'appear', 'to', 'capture', '.', 'the', 'q', '##rs', 'complexes', 'are', 'conducted', 'with', 'marked', 'left', 'axis', 'deviation', 'and', 'right', 'bundle', '-', 'branch', 'block', 'configuration', 'with', 'q', '-', 't', 'interval', 'pro', '##long', '##ation', 'and', 't', 'wave', 'inversion', '.', 'clinical', 'correlation', 'is', 'suggested', '.', 'tracing', '#', '2']\n","chunk 7 tokenize start!\n","First sentence tokenized\n","['9', 'with', 'potential', 'sep', '##sis', 'revisions', 'to', 'pathway', ':', '9', 'with', 'potential', 'sep', '##sis', ';', 'resolved']\n","chunk 8 tokenize start!\n","First sentence tokenized\n","['ex', '##tub', '##ated', 'w', '/', 'o', 'incident', 'thus', 'far', '.', 'h', '##yp', '##ox', '##ic', 'with', 'pa', '##o', '##2', 'in', '70', \"'\", 's', '.', 'has', 'strong', 'cough', 'at', 'times', '.', 'non', 'productive', '.', 'lungs', 'are', 'course', 'with', 'diminished', 'bases', '.', 'remains', 'on', '50', '%', 'vent', '##i', 'mask', '.', 'pt', 'is', 'let', '##har', '##gic', 'and', 'restless', 'at', 'times', '.', 'does', 'follow', 'commands', 'and', 'mae', '.', 'calls', 'out', 'for', 'wife', '.', 'hyper', '##tens', '##ive', 'when', '.', 'sb', '##p', '190', \"'\", 's', '.', 'gave', 'iv', 'lo', '##press', '##or', 'with', 'noted', 'effect', '.', 'ti', '##tra', '##ted', 'iv', 'nt', '##g', '.', 'give', 'iv', 'hal', '##do', '##l', '5', '##mg', 'for', 'ag', '##git', '##ation', '.', 'continues', 'on', 'cv', '##v', '##h', '.', 'removal', 'rate', '@', '400', '##cc', '.', 'w', '##t', 'down', 'to', 'remains', 'ol', '##ig', '##uri', '##c', 'metabolic', 'acid', '##osis', 'corrected', '.', 'k', '+', 'given', '40', 'iv', 'kc', '##l', '.', 'will', 'follow', '.', 'remains', 'on', 'iv', 'ca', '+', 'gt', '##t', '.', 'noted', 'o', '##cca', '##ssion', '##al', 'pv', '##c', \"'\", 's', '.', 'gave', '2', '##gm', 'iv', 'mg', '##so', 'effect', 'noted', '.', 'remains', 'in', 'ns', '##r', '90', \"'\", 's', '.', 'ng', '##t', 'to', 'l', '##ws', '.', 'placement', 'verified', 'by', 'c', '##x', '##r', '.', 'act', \"'\", 's', '153', 'and', 'bs', 'w', '##nl', '.', 'plan', ':', 'aggressive', 'pu', '##lm', 'toilet', ',', 'monitor', 'ab', '##g', \"'\", 's', ',', 'start', 'al', '##b', '/', 'at', '##r', 'ne', '##bs', 'if', 'nec', '##ces', '##sar', '##y', ',', 'continue', 'cv', '##v', '##h', ',', 'monitor', 'electro', '##ly', '##tes', ',', 'i', '+', 'o', ',', 'and', 'w', '##t', '.', 'monitor', 'bp', '.', 'con', '##ti', '##ue', 'with', 'hydra', '##la', '##zine', ',', 'lo', '##press', '##or', ',', 'and', 'nt', '##g', 'iv', '.']\n","chunk 9 tokenize start!\n","First sentence tokenized\n","['8', ':', '02', 'am', 'chest', '(', 'portable', 'ap', ')', 'clip', '#', 'reason', ':', 'eva', '##l', 'pu', '##lm', 'ed', '##ema', ',', '?', 'p', '##na', 'medical', 'condition', ':', '79', 'admitted', 'for', 'fever', ',', 'h', '##yp', '##ote', '##ns', '##ion', ',', 'mental', 'status', 'changes', 'of', 'unclear', 'et', '##iology', 'reason', 'for', 'this', 'examination', ':', 'eva', '##l', 'pu', '##lm', 'ed', '##ema', ',', '?', 'p', '##na', 'final', 'report', 'indication', ':', 'fever', ',', 'h', '##yp', '##ote', '##ns', '##ion', ',', 'mental', 'status', 'change', '.', 'evaluate', 'for', 'pulmonary', 'ed', '##ema', 'or', 'pneumonia', '.', 'comparison', ':', '.', 'ap', 'su', '##pine', 'chest', ':', 'the', 'right', 'internal', 'jug', '##ular', 'cat', '##het', '##er', 'and', 'left', 'sub', '##cl', '##avian', 'cat', '##het', '##er', 'both', 'terminate', 'in', 'the', 'lower', 'sv', '##c', '.', 'there', 'is', 'no', 'evidence', 'for', 'p', '##ne', '##um', '##otho', '##ra', '##x', '.', 'the', 'ng', 'tube', 'extends', 'into', 'the', 'stomach', '.', 'there', 'is', 'a', 'residual', 'layer', '##ing', 'e', '##ff', '##usion', 'on', 'the', 'right', '.', 'the', 'bi', '##bas', '##ila', '##r', 'ate', '##le', '##cta', '##sis', 'appears', 'improved', 'in', 'the', 'interval', '.', 'no', 'new', 'areas', 'of', 'consolidation', 'are', 'appreciated', '.', 'impression', ':', 'improved', 'appearance', 'of', 'bi', '##bas', '##ila', '##r', 'ate', '##le', '##cta', '##sis', 'with', 'residual', 'layer', '##ing', 'pl', '##eur', '##al', 'e', '##ff', '##usion', 'on', 'the', 'right', '.']\n","chunk 10 tokenize start!\n","First sentence tokenized\n","['mic', '##u', 'a', 'np', '##n', ':', 'ne', '##uro', ':', 'pt', '.', 'spanish', 'sk', '##g', 'only', 'and', 'difficult', 'to', 'communicate', '.', 'family', 'in', 'last', 'pm', 'and', 'stated', 'pt', '.', 'is', 'oriented', 'and', 'not', 'confused', '.', 'complaining', 'intermittent', '##ly', 'of', 'abd', '.', 'pain', 'and', 'med', '##icated', 'with', 'dil', '##aud', '##id', 'pr', '##n', 'with', 'good', 'effect', '.', 'moving', 'l', 'side', 'weakly', 'in', 'bed', '.', 'no', 'movement', 'of', 'r', 'side', 'noted', '.', 'follows', 'simple', 'commands', 'intermittent', '##ly', '.', 'cv', ':', 'low', 'grade', 'te', '##mp', '.', 'hr', '50', '##s', '-', '70s', 'sb', '/', 'sr', ',', 'no', 'ec', '##top', '##y', 'noted', '.', 'bp', 'stable', 'with', 'sb', '##p', '80s', '-', '120', '##s', '.', 'skin', 'warm', ',', 'ja', '##und', '##ice', '##d', 'with', 'pal', '##p', '.', 'pedal', 'pulses', 'bi', '##lat', '.', '1', '+', 'dependent', 'ed', '##ema', '.', 'van', '##co', 'levels', 'being', 'drawn', 'q', '##d', 'until', 'less', 'than', '15', 'and', 'then', 'to', 'give', 'dose', '-', 'level', 'too', 'high', 'last', 'pm', '.', 'due', 'for', 'hd', 'today', '.', 'l', 'qui', '##nton', 'cat', '##h', 'intact', '.', 'iv', 'to', 'l', 'fa', 'intact', 'and', 'patent', '.', 'res', '##p', ':', 'tr', '##ach', 'intact', '.', 'continues', 'on', 'same', 'vent', 'settings', ':', 'ps', '##18', 'pee', '##p', '##5', 'fi', '##o', '##24', '##0', '%', 'with', 'o', '##2', 'sat', '>', '95', '%', '.', 'l', '##s', 'coarse', 'throughout', '.', 's', '##x', \"'\", 'd', 'for', 'moderate', 'to', 'cop', '##ious', 'am', '##ts', 'of', 'thick', 'white', 'to', 'tan', 'sp', '##ut', '##um', '.', 'rr', '##20', '##s', '.', 'gi', '/', 'gu', ':', 'abd', '.', 'soft', ',', 'di', '##sten', '##ded', 'with', 'positive', 'bow', '##el', 'sounds', '.', 'small', 'golden', 'loose', 'b', '##m', 'last', 'pm', '.', 'ne', '##pro', 't', '##f', 'at', 'goal', 'of', '35', '##cc', '/', 'hr', 'via', 'do', '##bh', '##off', '.', 'l', '##ft', 'continue', 'to', 'rise', 'this', 'am', '.', 'no', 'insulin', 'needed', 'overnight', '.', 'foley', 'with', 'ict', '##eric', 'clear', 'amber', 'urine', '10', '-', '30', '##cc', '/', 'hr', '.', 'skin', ':', 'abd', '.', 'ds', '##g', 'changed', 'ti', '##d', 'with', 'wet', 'to', 'dry', 'ds', '##g', '.', 'wound', 'pink', 'with', 'moderate', 'am', '##ts', 'of', 'yellow', '-', 'green', 'drainage', '.', 'ab', '##ras', '##ion', 'to', 'sac', '##rum', 'with', 'duo', '##der', '##m', 'covering', 'and', 'one', 'red', 'area', 'to', 'r', 'butt', '##ock', 'but', 'no', 'breakdown', 'yet', '.', 'l', 'groin', 'mass', 'stable', 'with', 'no', 'further', 'spreading', 'noted', 'and', 'hc', '##t', 'stable', '.', 'multi', '##pod', '##us', 'boots', 'on', 'and', 'r', 'arm', 'sp', '##lin', '##t', 'on', '/', 'off', '.', 'other', ':', 'family', 'into', 'visit', 'last', 'pm', 'and', 'talked', 'to', 'md', '.', 'continue', 'to', 'follow', 'l', '##ft', '##s', '.']\n","chunk 11 tokenize start!\n","First sentence tokenized\n","['nursing', 'update', 'cv', ':', 'hr', 'con', '##t', 'in', 'afi', '##b', ',', 'no', 'ec', '##top', '##y', ',', 'transient', 'dip', '##s', 'in', 'sb', '##p', 'to', '90', ',', 'otherwise', 'norm', '##ote', '##ns', '##ive', '.', 'k', '+', '4', 'rep', '##lete', '##d', 'iv', 'over', '4', '##h', '.', 'id', ':', 'af', '##eb', '##ril', '##e', ',', 'ab', '##x', 'as', 'ordered', 'and', 'van', '##co', 'regime', '##n', 'commenced', '.', 'contact', 'precautions', 'maintained', 'for', 'cd', '##iff', 'coli', '##tis', '.', 'res', '##p', ':', 'sat', '##s', '96', '-', '100', '%', 'on', '4', '##l', 'n', '/', 'pro', '##ng', '##s', '.', 'ct', 'chest', 'with', 'iv', 'contrast', 'done', '-', 'results', 'pending', '.', 'breath', 'sounds', 'clear', 'bilateral', '##ly', '.', 'end', '##o', ':', 'sliding', 'scale', 'in', 'effect', ',', 'glucose', 'stable', ',', 'no', 'insulin', 'requirements', '.', 'gi', ':', 'np', '##o', 'until', 'after', 'ct', 'scan', ',', 'then', 'ate', 'moderately', 'well', 'after', 'return', 'from', 'ct', '.', 'soft', ',', 'bow', '##el', 'sounds', 'active', '.', 'inc', '##ont', '##inen', '##t', 'l', '##g', 'liquid', 'yellow', 'stool', '.', 'per', '##i', 'area', 'begin', '##nni', '##ng', 'to', 'ex', '##cor', '##iate', ',', 'fi', '##b', 'applied', 'for', 'skin', 'protection', 'and', 'quan', '##ti', '##fication', 'of', 'stool', '.', 'gu', ':', 'transient', 'dip', 'in', 'u', '##o', 'to', '5', '##cc', '@', '01', '##00', ',', 'resolved', 'with', 'increased', 'iv', 'fluid', 'rate', '.', 'pt', 'monitored', '.', 'see', 'care', '##vu', '##e', 'flows', '##hee', '##ts', 'for', 'detailed', 'data', '.']\n","chunk 12 tokenize start!\n","First sentence tokenized\n","['np', '##n', '(', '240', '##0', '-', '07', '##00', ')', ':', 'pt', 'is', 'a', '71', 'y', '.', 'o', 'male', 'that', 'came', 'in', 'on', 'c', '/', 'o', 'abd', 'b', '##lo', '##ating', 'and', 'con', '##sti', '##pati', '##on', '.', 'ct', 'scan', 'showed', 'acute', 'cho', '##le', '##cy', '##sti', '##tis', '.', 'pt', 'c', 'elevated', 'in', '##r', '2', \"'\", 'co', '##uma', '##din', 'for', 'h', '##x', 'of', 'af', 'and', 'pre', 'op', 'pt', 'received', 'vi', '##t', 'k', 'and', 'ff', '##p', '.', 'pt', 'went', 'to', 'or', 'and', ',', 'pt', 'had', 'l', '##g', 'am', '##t', 'o', '##oz', '##ing', '/', 'bleeding', ',', 'planned', 'cho', '##le', '##cy', '##ste', '##ct', '##omy', 'converted', 'to', 'cho', '##le', '##cy', '##sto', '##tom', '##y', 'c', 'cho', '##le', '##cy', '##sto', '##tom', '##y', 'tube', 'placement', '.', 'pt', 'then', 'transferred', 'from', 'pac', '##u', 'to', 't', '/', 'sic', '##u', 'for', 'further', 'management', '.', 'see', 'chart', 'for', 'more', 'details', '.', 'review', 'of', 'systems', ':', 'ne', '##uro', ':', 'pt', 'se', '##date', '##d', 'on', 'iv', 'prop', '##of', '##ol', ',', 'pt', 'occasionally', 'lighted', 'and', 'becomes', 'agitated', ',', 'attempting', 'to', 'get', 'o', '##ob', ',', 'pull', 'out', 'tube', ',', 'buck', 'vent', '.', 'pt', 'continues', 'to', 'be', 'un', '##co', '##oper', '##ative', 'despite', 'frequent', 're', '##ass', '##urance', 'and', 're', '##ori', '##entation', ',', 'prop', '##of', '##ol', 'continued', 'overnight', 'for', 'se', '##dation', '.', 'pt', 'nodded', 'head', 'yes', 'when', 'asked', 'if', 'have', 'pain', ',', 'pt', 'med', '##icated', 'with', 'iv', 'ms', '##o', 'cv', ':', 'hr', '=', '60', '-', '70s', 'ns', '##r', ',', 'no', 'ec', '##top', '##y', '.', 'sb', '##p', '=', '120', '-', '140', '##s', '.', 'iv', 'lo', '##press', '##or', 'continues', '.', 'pa', 'line', 'in', 'place', ',', 'co', '=', ',', 'pc', '##w', '##p', '=', '19', ',', 'cv', '##p', '=', '15', '-', 'color', 'pink', ',', 'skin', 'warm', 'and', 'dry', '.', 'pal', '##pa', '##ble', 'pulses', 'all', 'ex', '##tre', '##mit', '##ies', '.', 've', '##no', '##dy', '##nes', 'in', 'place', '.', 'res', '##p', ':', 'l', '##s', 'course', ',', 'a', '/', 'c', 'ventilation', 'continues', '700', '##x', '##10', ',', 'sao', '##2', '=', '98', '-', '100', '%', 'on', '40', '%', 'fi', '##o', '##2', ',', 'adequate', 'ab', '##gs', 'for', 'vent', 'settings', '.', 'pt', 'su', '##ction', '##ed', 'for', 'sm', 'to', 'mod', 'thick', 'white', 'secret', '##ions', ',', 'l', '##g', 'am', '##t', 'of', 'oral', 'secret', '##ions', '.', 'gi', ':', 'abd', 'softly', 'di', '##sten', '##ded', ',', 'h', '##yp', '##oa', '##ctive', 'bs', '##x', 'np', '##o', '.', 'no', 'b', '##m', '.', 'ng', '##t', 'to', 'l', '##ws', 'and', 'draining', 'bi', '##lio', '##us', 'drainage', ',', 'placement', 'confirmed', '.', 'iv', 'pep', '##ci', '##d', 'continues', '.', 'cho', '##le', '##cy', '##sto', '##tom', '##y', 'tube', 'draining', 'ser', '##osa', '##ng', '##uin', '##ous', 'bi', '##lio', '##us', 'drainage', '.', 'gu', ':', 'ind', '##well', '##ing', 'foley', 'intact', 'and', 'draining', 'clear', 'amber', 'urine', ',', 'up', '=', '30', '-', '40', '##cc', '/', 'hr', '.', 'iv', '##f', 'at', '125', '##cc', '/', 'hr', '.', 'electro', '##ly', '##tes', 'rep', '##lete', '##d', 'pr', '##n', '.', 'hem', '##e', ':', '06', '##00', '##hc', '##t', '=', '0', '(', '6', ')', 'c', '2nd', 'pr', '##bc', 'in', '##fus', '##ing', 'at', 'blood', 'draw', '.', 'pt', 'received', 'total', 'of', '2', '##u', 'pr', '##bc', 'overnight', '.', 'in', '##r', '=', '3', '(', '5', ')', '.', 'id', ':', 't', '##max', '=', '5', 'via', 'blood', '.', 'iv', 'pc', '##n', ',', 'lev', '##of', '##lo', '##xa', '##ci', '##llin', ',', 'and', 'flag', '##yl', 'continues', '.', 'wb', '##c', '=', '2', '(', '8', ')', '.', 'end', '##o', ':', 'no', 'issues', '.', 'skin', ':', 'skin', 'warm', 'and', 'dry', '.', 'abd', 'with', 'ds', '##d', 'd', '&', 'i', ',', 'cho', '##le', '##cy', '##sto', '##tom', '##y', 'tube', 'in', 'place', '.', 'pt', 'fr', '##eck', '##led', 'and', 'noted', 'to', 'have', 'multiple', 'scars', '/', 'sc', '##ab', '##s', 'where', '?', 'skin', 'lesions', 'removed', '.', 'soc', ':', 'pt', 'has', 'wife', ',', 'no', 'communication', 'with', 'family', 'overnight', '.', 'plan', ':', 'continue', 'full', 'support', 'as', 'above', '.', 'continue', 'to', 'follow', 'hc', '##t', '.', 'attempt', 'to', 'we', '##an', 'to', 'ex', '##tub', '##ate', '.']\n","chunk 13 tokenize start!\n","First sentence tokenized\n","['neon', '##ato', '##logy', '-', 'np', 'physical', 'exam', 'awake', 'and', 'alert', 'with', 'cares', ',', 'te', '##mp', 'stable', 'in', 'open', 'cr', '##ib', '.', 'in', 'room', 'air', ',', 'bs', 'clear', 'and', 'equal', 'with', 'symmetrical', 'chest', 'movement', ',', 'color', 'pink', '.', 'rr', '##r', ',', 'without', 'murmur', ',', 'pulses', '2', '+', 'and', 'symmetrical', '.', 'active', 'bow', '##el', 'sounds', ',', 'without', 'loops', ',', 'without', 'hs', '##m', ',', 'to', '##ler', '##ating', 'feeds', 'well', '.', 'hem', '##ang', '##iom', '##a', 'on', 'right', 'knee', '.', 'normal', 'female', 'gen', '##ital', '##ia', '.', 'good', 'tone', ',', 'af', '##sf', ',', 'p', '##fs', '##f', ',', '+', 'suck', ',', '+', ',', '+', 'plant', '##ar', 'reflex', '##es', '.', 'please', 'see', 'attending', 'neon', '##ato', '##logist', 'note', 'for', 'detailed', 'plan', 'of', 'care', '.']\n","chunk 14 tokenize start!\n","First sentence tokenized\n","['respiratory', 'care', ':', 'pt', 'continues', 'on', 'nr', '##b', 'mask', '.', 'des', '##ats', 'easily', 'with', 'any', 'o', '##2', 'change', 'or', 'ex', '##cer', '##sion', '.', 'received', 'at', '##rove', '##nt', 'ne', '##bs', '.', 'has', 'strong', ',', 'spa', '##stic', 'cough', 'product', '##io', '##ve', 'of', 'thick', ',', 'tan', 'secret', '##ions', '.']\n","chunk 15 tokenize start!\n","First sentence tokenized\n","['nursing', 'note', ':', 'ne', '##uro', ':', 'gradually', 'becoming', 'more', 'awake', 'through', 'night', ',', 'mae', 'on', 'bed', '.', 'lifts', 'and', 'kicks', 'legs', 'at', 'times', '.', 'opens', 'eyes', 'to', 'voice', ',', 'following', 'simple', 'commands', '.', 'per', '##rl', '##a', '2', '-', '3', '##mm', 'and', 'slug', '##gis', '##h', '.', 'at', '##iva', '##n', 'pr', '##n', 'and', 'at', '##c', 'w', '/', 'good', 'effect', 'on', 'mild', 'agitation', '.', 'attempting', 'to', 'lift', 'hips', 'off', 'bed', 'at', 'times', '.', 'dil', '##aud', '##id', 'gt', '##t', 'w', '/', 'adequate', '-', 'appearing', 'pain', 'control', '.', 'res', '##p', ':', 'lung', 'sounds', 'w', '/', 'r', '##hon', '##chi', 'throughout', ',', 's', '##x', '##n', \"'\", 'd', 'for', 'thick', 'tan', 'sp', '##ut', '##um', 'in', 'small', 'amounts', '.', 'con', '##t', 'w', '/', 'tan', 'sp', '##ut', '##um', 'from', 'na', '##res', '.', 'sim', '##v', '/', 'ps', '600', '##x', '##22', ',', 'pee', '##p', '20', ',', 'ip', '##s', '5', ',', 'fi', '##0', '##2', 'down', 'to', '65', '%', 'w', '/', 'po', '##2', '69', ',', 'pee', '##p', 'increased', 'briefly', 'to', '22', 'and', 'fi', '##0', '##2', 'increased', 'to', '70', 'w', '/', 'next', 'ab', '##g', 'reflecting', 'po', '##2', 'of', '100', '%', '.', 'fi', '##0', '##2', 'again', 'attempted', 'decrease', 'to', '70', '%', ',', 'w', '/', 'pt', '.', 'to', '##ler', '##ating', 'w', '/', 'p', '##0', '##2', 'of', '115', '%', '.', 'left', 'on', '60', '%', 'w', '/', 'acceptable', 'ab', '##gs', '.', 'gi', ':', 'abdomen', 'firm', ',', 'di', '##sten', '##ded', '.', 'ng', '##t', 'patent', 'for', 'bi', '##lio', '##us', 'drainage', '.', '-', 'bs', '.', '-', 'flat', '##us', '.', 'dressing', 'intact', 'to', 'abdomen', '.', 'cv', ':', 'ns', '##r', '-', 'st', ',', 'no', 'ec', '##top', '##y', 'noted', '.', 'te', '##mp', 'down', 'to', '9', 'ax', '##illa', '##ry', '.', 'map', 'kept', '>', '65', 'w', '/', 'lev', '##o', 'gt', '##t', '.', 'do', '##pp', '##ler', '##able', 'pulses', 'bi', '##lat', '.', 'no', 'fluid', 'bo', '##lus', '##es', 'overnight', '.', 'cv', '##p', '14', '-', 'pa', '#', 's', '45', '-', '50', '##s', '/', '20s', '.', 'unable', 'to', 'wedge', '.', 'ho', 'aware', '.', 'doctor', 'd', '/', 'c', \"'\", 'd', 'pa', 'line', 'for', 'contaminated', '/', 'broken', 'sheath', '@', 'cord', '##is', 'remains', '.', 'resident', 'will', 'ref', '##lo', '##at', 'swan', 'this', 'early', 'am', '.', 'gu', ':', 'foley', 'patent', 'amber', 'urine', '>', '30', '##cc', '/', 'hr', '.', 'a', '/', 'p', ':', 'more', 'hem', '##od', '##yna', '##mic', '##ally', 'stable', 'overnight', 'w', '/', 'no', 'fluid', 'bo', '##lus', 'requirements', 'though', 'con', '##t', '.', 'w', '/', 'sept', '##ic', 'picture', '.', 'con', '##t', '.', 'close', 'monitoring', '.', 're', '-', 'float', 'swan', 'today', '.']\n","chunk 16 tokenize start!\n","First sentence tokenized\n","['title', ':', 'chief', 'complaint', ':', '24', 'hour', 'events', ':', '-', 'pt', '.', 'we', '##ane', '##d', 'off', 'va', '##sop', '##ress', '##in', 'in', 'the', 'morning', ',', 'bp', \"'\", 's', 'remained', 'stable', 'in', 'the', '90', \"'\", 's', 'sy', '##sto', '##lic', '-', 'likely', 'call', 'out', 'in', 'the', 'morning', '-', 'pt', '.', 'for', 'tee', 'on', 'monday', '-', 'continuing', 'to', 'leave', 'new', 'line', 'in', 'pending', 'further', 'stability', '-', 't', '##p', '##n', 'adjustments', 'made', 'based', 'on', 'electro', '##ly', '##tes', 'all', '##er', '##gies', ':', 'dem', '##ero', '##l', '(', 'oral', ')', '(', 'me', '##per', '##idi', '##ne', 'hc', '##l', ')', 'seizures', ';', 'com', '##pa', '##zine', '(', 'oral', ')', '(', 'pro', '##ch', '##lor', '##per', '##azi', '##ne', 'male', '##ate', ')', 'rash', ';', 'reg', '##lan', '(', 'oral', ')', '(', 'met', '##oc', '##lo', '##pr', '##ami', '##de', 'hc', '##l', ')', 'rash', ';', 'beta', '##dine', 'sur', '##gi', '-', 'prep', '(', 'topical', ')', '(', 'po', '##vid', '##one', '-', 'io', '##dine', ')', 'b', '##list', '##ers', ';', 'b', '##list', '##ers', '/', 'paper', 'io', '##dine', ';', 'io', '##dine', 'containing', 'hive', '##s', ';', 'nausea', '/', 'v', 'van', '##com', '##y', '##cin', 'rash', ';', 'red', 'man', 's', 'last', 'dose', 'of', 'antibiotics', ':', 'flu', '##cona', '##zo', '##le', '-', '01', ':', '20', 'pm', 'ce', '##fi', '##pi', '##me', '-', '02', ':', '32', 'pm', 'da', '##pt', '##omy', '##cin', '-', '10', ':', '14', 'am', 'am', '##bis', '##ome', '-', '10', ':', '30', 'pm', 'mer', '##open', '##em', '-', '02', ':', '00', 'am', 'in', '##fusion', '##s', ':', 'other', 'ic', '##u', 'medications', ':', 'mor', '##phine', 'sulfate', '-', '12', ':', '00', 'pm', 'other', 'medications', ':', 'changes', 'to', 'medical', 'and', 'family', 'history', ':', 'review', 'of', 'systems', 'is', 'unchanged', 'from', 'admission', 'except', 'as', 'noted', 'below', 'review', 'of', 'systems', ':', 'patient', 'c', '/', 'o', 'continued', 'left', 'groin', 'pain', 'flows', '##hee', '##t', 'data', 'as', 'of', '06', ':', '30', 'am', 'vital', 'signs', 'hem', '##od', '##yna', '##mic', 'monitoring', 'fluid', 'balance', '24', 'hours', 'since', '12', 'am', 't', '##max', ':', '9', 'c', '(', '5', 'tc', '##urrent', ':', '9', 'c', '(', '5', 'hr', ':', '86', '(', '66', '-', '99', ')', 'bp', '##m', 'bp', ':', '100', '/', '53', '(', '64', ')', '{', '89', '/', '44', '(', '55', ')', '-', '110', '/', '61', '(', '69', ')', '}', 'mm', '##hg', 'rr', ':', '17', '(', '13', '-', '25', ')', 'ins', '##p', '/', 'min', 'sp', '##o', '##2', ':', '93', '%', 'heart', 'rhythm', ':', 'sr', '(', 'sin', '##us', 'rhythm', ')', 'w', '##gt', '(', 'current', ')', ':', '5', 'kg', '(', 'admission', ')', ':', '9', 'kg', 'total', 'in', ':', '3', ',', '560', 'ml', '84', '##7', 'ml', 'po', ':', 't', '##f', ':', 'iv', '##f', ':', '1', ',', '99', '##7', 'ml', '265', 'ml', 'blood', 'products', ':', 'total', 'out', ':', '5', ',', '000', 'ml', '2', ',', '050', 'ml', 'urine', ':', '3', ',', '550', 'ml', '1', ',', '050', 'ml', 'ng', ':', 'stool', ':', 'drains', ':', 'balance', ':', '-', '1', ',', '440', 'ml', '-', '1', ',', '203', 'ml', 'respiratory', 'support', 'o', '##2', 'delivery', 'device', ':', 'none', 'sp', '##o', '##2', ':', '93', '%', 'ab', '##g', ':', '/', '/', '/', '29', '/', 'physical', 'examination', 'general', 'appearance', ':', 'thin', ',', 'appears', 'comfortable', ',', 'quiet', ',', 'anxious', 'eyes', '/', 'con', '##jun', '##ct', '##iva', ':', 'per', '##rl', ',', 'e', '##omi', ',', 'con', '##jun', '##ct', '##iva', 'without', 'pal', '##lor', 'cardiovascular', ':', 'normal', 's', '##1', '/', 's', '##2', ',', 'rr', '##r', ',', 'no', 'murmurs', 'rubs', 'or', 'gallo', '##ps', ',', 'no', 'pal', '##pa', '##ble', 'thrill', '##s', 'or', 'he', '##aves', 'peripheral', 'vascular', ':', '2', '+', 'pulses', 'throughout', 'radial', ',', 'd', '##p', ',', 'equal', 'and', 'symmetric', 'bilateral', '##ly', ',', 'warm', 'and', 'well', 'per', '##fus', '##ed', 'with', 'cap', 'ref', '##ill', '<', '2', 'seconds', 'respiratory', '/', 'chest', ':', 'good', 'air', 'movement', 'bilateral', '##ly', ',', 'minimal', 'crack', '##les', 'at', 'bases', 'abdominal', ':', 'soft', ',', 'tender', ':', 'll', '##q', 'tender', ';', 'no', 'tap', 'tenderness', ',', 'no', 'rebound', 'tenderness', ',', 'peg', 'tube', 'in', 'place', ';', 'uneven', 'surgical', 'scar', 'at', 'mid', '##line', ',', 'old', ';', 'os', '##tom', '##y', 'bag', 'in', 'place', ',', 'full', 'of', 'liquid', 'material', ',', 'no', 'skin', 'changes', 'around', 'lines', 'ex', '##tre', '##mit', '##ies', ':', 'no', 'ed', '##ema', 'or', 'cy', '##ano', '##sis', 'skin', ':', 'no', 'rash', '##es', ',', 'no', 'ja', '##und', '##ice', 'ne', '##uro', '##logic', ':', 'at', '##ten', '##tive', ',', 'follows', 'simple', 'commands', ',', 'responds', 'to', ':', 'verbal', 'stimuli', ',', 'oriented', '(', 'to', ')', ':', 'place', ',', 'time', ',', 'situation', ',', 'movement', ':', 'purpose', '##ful', ',', 'tone', ':', 'normal', ',', 'strength', 'in', 'ex', '##tre', '##mit', '##ies', 'left', 'biceps', 'pull', ',', 'right', 'biceps', 'pull', '.', 'hand', 'grip', 'bi', '##lat', '.', 'word', 'finding', 'difficulty', 'noted', 'in', 'conversation', 'labs', '/', 'radio', '##logy', '271', 'k', '/', 'ul', '9', 'g', '/', 'dl', '146', 'mg', '/', 'dl', '6', 'mg', '/', 'dl', '29', 'me', '##q', '/', 'l', '6', 'me', '##q', '/', 'l', '12', 'mg', '/', 'dl', '108', 'me', '##q', '/', 'l', '143', 'me', '##q', '/', 'l', '8', '%', '0', 'k', '/', 'ul', '02', ':', '00', 'am', '02', ':', '08', 'am', '04', ':', '02', 'am', '06', ':', '51', 'pm', '04', ':', '22', 'am', '04', ':', '33', 'am', 'wb', '##c', '5', '1', '4', '0', 'hc', '##t', '0', '2', '2', '8', 'pl', '##t', '178', '198', '212', '271', 'cr', '5', '6', '5', '5', '6', 'glucose', '121', '116', '105', '78', '175', '146', 'other', 'labs', ':', 'ca', '+', '+', ':', '5', 'mg', '/', 'dl', ',', 'mg', '+', '+', ':', '9', 'mg', '/', 'dl', ',', 'po', '##4', ':', '4', 'mg', '/', 'dl', 'assessment', 'and', 'plan', 'this', 'is', 'a', '47', 'year', 'old', 'woman', 'with', 'history', 'of', 't', '##p', '##n', '-', 'dependence', 'leading', 'to', 'many', 'complications', 'of', 'intra', '##ven', '##ous', 'lines', 'including', 'infection', ',', 'cl', '##ots', ',', 'etc', '.', 'p', '/', 'w', '.', 'h', '##yp', '##ote', '##ns', '##ion', 'has', 'currently', 'resolved', ',', 'patient', 'with', 'no', 'press', '##or', 'requirement', 'since', 'yesterday', 'morning', '.', 'associated', 'with', 'fever', 'earlier', '.', 'be', 'related', 'to', 'infection', ';', 'switched', 'to', 'da', '##pt', '##omy', '##cin', ',', 'mer', '##open', '##em', ',', 'am', '##bis', '##one', 'per', 'id', 'rec', '##s', '.', 'id', 'concerned', 'about', 'another', 'mala', '##sse', '##zia', 'infection', 'due', 'to', 'pt', 's', 'recent', 'history', 'of', 'mala', '##sse', '##zia', 'ba', '##cter', '##emia', '.', 'all', 'cultures', 'negative', 'to', 'date', '.', '-', 'we', '##ane', '##d', 'off', 'of', 'lev', '##op', '##hed', 'and', 'now', 'on', 'va', '##sop', '##ress', '##in', '.', 'is', 'currently', 'off', 'va', '##sop', '##ress', '##in', ',', 'but', 'will', '-', 'continue', 'am', '##bis', '##one', ',', 'mer', '##open', '##em', '(', 'day', '1', ')', 'and', 'da', '##pt', '##omy', '##cin', '(', 'day', '1', ')', 'per', 'id', 'they', 'may', 'pull', 'back', 'in', 'the', 'near', 'future', 'if', 'cultures', 'remain', 'negative', '-', 'cultures', 'pending', ',', 'but', 'all', 'with', 'ng', '##t', '##d', 'sub', '-', 'acute', 'stroke', 'word', 'finding', 'difficulty', 'noted', 'by', 'patient', 'to', 'be', 'new', 'over', 'the', 'last', 'weeks', ',', 'noted', 'also', 'by', 'family', 'to', 'be', 'new', 'within', 'the', 'last', '1', 'week', '.', 'areas', 'of', 'h', '##yp', '##ode', '##ns', '##ity', 'on', 'ct', 'head', 'without', 'contrast', 'in', 'l', 'basal', 'gang', '##lia', 'and', 'l', 'ce', '##re', '##bell', '##um', '.', 'given', 'history', 'of', 'cl', '##ots', 'and', 'ba', '##cter', '##emia', ',', 'concern', 'for', 'th', '##rom', '##bo', '##em', '##bol', '##ism', 'or', 'sept', '##ic', 'em', '##bol', '##ism', '.', 'pt', 'cannot', 'have', 'mri', 'given', 'placement', 'of', 'hardware', 'in', 'early', '.', 'ne', '##uro', 'does', 'not', 'think', 'this', 'is', 'a', 'sub', '##ac', '##ute', 'stroke', '.', '-', 'continue', 'sub', '-', 'cut', '##aneous', 'he', '##par', '##in', '5000', 'units', 'per', 'ne', '##uro', 'due', 'to', 'concern', 'for', 'possible', 'sept', '##ic', 'th', '##rom', '##bus', 'that', 'could', 'bleed', ',', 'pt', 'has', 'h', '/', 'o', 'bleeding', 'with', 'love', '##no', '##x', '-', 'tee', 'to', 'evaluate', 'for', 'cl', '##ots', '/', 'vegetation', '##s', 'on', 'monday', '.', 'access', ':', 'patient', 'with', 'difficult', 'access', '.', 't', '##p', '##n', '/', 'hi', '##ckman', 'with', 'double', 'lu', '##men', 'and', 'quad', 'lu', '##men', 'in', 'left', 'fe', '##moral', 'as', 'well', ',', 'but', 'placed', 'in', 'a', 'ste', '##nt', 'in', 'the', 'vein', 'so', 'will', 'be', 'unable', 'to', 'give', 't', '##p', '##n', ',', 'but', 'can', 'use', 'for', 'press', '##ors', '/', 'ab', '##x', '/', 'fluids', '-', 'pl', '##avi', '##x', 'was', 'held', 'in', 'the', 'setting', 'of', 'new', 'line', 'from', 'ir', ',', 'but', 'will', 'restart', 'since', 'it', 'is', '48', 'hours', 'post', 'procedure', '-', 'continue', 'sub', '-', 'cut', '##aneous', 'he', '##par', '##in', 'for', 'now', '.', '.', 'past', 'pulmonary', 'em', '##bol', '##ism', 'pt', 'not', 'on', 'co', '##uma', '##din', 'due', 'to', 'anti', '##biotic', 'interactions', ',', 'difficulties', 'with', 'absorption', '.', 'her', 'love', '##no', '##x', 'was', 'stopped', 'in', 'the', 'past', ',', 'per', 'om', '##r', '\"', 'because', 'the', 'injection', '##s', 'gave', 'her', 'we', '##lts', ',', 'which', 'bled', '.', '\"', '-', 'on', 'sub', '##cut', '##aneous', 'he', '##par', '##in', '-', 'restart', 'pl', '##avi', '##x', 'today', '.', 'an', '##emia', 'stable', 'at', '8', '-', 'gu', '##aia', '##c', 'trace', 'positive', '-', 's', '/', 'p', 'trans', '##fusion', 'of', '1', 'unit', 'pr', '##bc', '##s', '-', 'monitor', 'daily', 'hc', '##ts', '-', 'will', 'follow', 'up', 'prior', 'an', '##emia', 'work', 'up', ',', 'especially', 'since', 'she', 'is', 'now', 'on', 'da', '##pt', '##omy', '##cin', 'which', 'can', 'cause', 'marrow', 'suppression', '.', 'fen', ':', 'iv', '##f', ',', 't', '##p', '##n', ',', 'rep', '##lete', 'electro', '##ly', '##tes', '.', '-', 'will', 'continue', 't', '##p', '##n', 'now', 'that', 'patient', 'has', 'additional', 'access', ',', 't', '##p', '##n', 'through', 'her', 'original', 'line', 'with', 'ethanol', 'dwell', '##s', '-', 'will', 'adjust', 't', '##p', '##n', 'to', 'account', 'for', 'rep', '##let', '##ion', 'of', 'k', 'and', 'mg', 'that', 'she', 'has', 'been', 'receiving', 'daily', 'in', 'the', 'ic', '##u', '-', 'will', 'touch', 'base', 'with', 'nutrition', 'about', 'insulin', 'in', 'her', 't', '##p', '##n', 'ic', '##u', 'care', 'nutrition', ':', 't', '##p', '##n', 'w', '/', 'lip', '##ids', '-', '08', ':', '00', 'pm', '5', 'ml', '/', 'hour', 'g', '##ly', '##ce', '##mic', 'control', ':', 'lines', ':', 'tunnel', '##ed', '(', 'hi', '##ckman', ')', 'line', '-', '05', ':', '10', 'pm', 'multi', 'lu', '##men', '-', '01', ':', '00', 'pm', 'prop', '##hyl', '##ax', '##is', ':', 'd', '##v', '##t', ':', 'he', '##par', '##in', 'sq', 'stress', 'ul', '##cer', ':', 'va', '##p', ':', 'comments', ':', 'communication', ':', 'comments', ':', 'code', 'status', ':', 'd', '##nr', '/', 'd', '##ni', 'disposition', ':', 'call', 'out', 'to', 'floor', 'this', 'morning']\n","chunk 17 tokenize start!\n","First sentence tokenized\n","['np', '##n', 'days', 'res', '##p', ':', 'infant', 'continues', 'in', 'nasal', 'pro', '##ng', 'cp', '##ap', '6', ',', 'in', '21', '%', '.', 'rr', '40', '-', '70', \"'\", 's', ',', 'lungs', 'are', 'clear', 'and', 'equal', ',', 'mild', 'ic', '/', 'sc', 're', '##tra', '##ctions', ',', 'su', '##ction', '##ed', 'na', '##res', 'x', '##1', 'today', 'for', 'small', 'am', '##t', '.', 'cloudy', 'thin', 'secret', '##ions', '.', 'continues', 'on', 'caf', '##fi', '##ene', '.', 'one', 'spell', 'today', 'q', '##sr', '.', 'will', 'continue', 'to', 'monitor', 'cl', '##os', '##ley', 'for', 'signs', 'of', 'increased', 'wo', '##b', '.', 'fen', ':', 'infant', 'on', 'total', 'fluids', '140', '##cc', '/', 'k', '/', 'd', 'of', 'b', '##m', '32', ',', 'ga', '##va', '##ge', 'feeding', '##s', 'q', '##4', '##ho', '##urs', 'over', '1', '##ho', '##ur', '.', 'abdomen', 'is', 'benign', ',', 'active', 'bow', '##el', 'sounds', ',', 'pink', ',', 'round', ',', 'no', 'loops', ',', 'ag', '5', '-', '23', '##cm', '.', 'no', 'spit', '##s', ',', 'as', '##p', '.', 'to', '##ler', '##ating', 'feeds', 'well', ',', 'will', 'continue', 'per', 'feeding', 'plan', 'and', 'monitor', 'closely', '.', 'dev', ':', 'infant', 'in', 'ser', '##vo', 'controlled', 'iso', '##lette', ',', 'temps', 'stable', ',', 'active', 'and', 'with', 'cares', ',', 'at', 'times', 'ir', '##rita', '##ble', ',', 'likes', 'to', 'suck', 'on', 'pac', '##ifier', '/', 'settles', 'well', 'with', 'positioning', 'and', 'pac', '##ifier', '.', 'ag', '##a', '.', 'will', 'continue', 'to', 'support', 'developmental', 'needs', '.', 'parenting', ':', 'no', 'contact', 'with', 'family', 'today', ',', 'will', 'continue', 'to', 'support', 'family', '.']\n","chunk 18 tokenize start!\n","First sentence tokenized\n","['respiratory', 'care', 'note', 'baby', 'remains', 'on', 'h', '##fo', '##v', 'on', 'map', '16', ',', 'amp', '33', ',', 'fi', '##o', '##2', '.', '52', '-', '.', '68', 'this', 'shift', '.', 'bs', 'coarse', '.', 'su', '##ction', '##ed', 'for', 'large', 'amount', 'white', 'secret', '##ions', '.', 'cb', '##g', ':', '31', '/', '56', '/', '28', '/', '30', '/', '-', 'no', 'vent', 'changes', 'made', '.', 'c', '##x', '##r', 'today', 'shows', 'lungs', 'well', 'expanded', 'with', 'chronic', 'changes', '.', 'given', 'las', '##ix', 'today', '.', 'to', 'be', 'started', 'on', 'di', '##uri', '##l', 'tomorrow', '.']\n","chunk 19 tokenize start!\n","First sentence tokenized\n","['6', ':', '39', 'pm', 'chest', 'port', '.', 'line', 'placement', ';', '-', '76', 'by', 'same', 'physician', '#', 'reason', ':', 'assess', 'line', 'placement', 'admitting', 'diagnosis', ':', 'sep', '##sis', 'medical', 'condition', ':', '35', 'y', '/', 'o', 'm', 'w', '/', 'aids', ',', 's', '/', 'p', 'int', '##uba', '##tion', ',', 'left', 'i', '##j', 'placement', 'reason', 'for', 'this', 'examination', ':', 'assess', 'line', 'placement', 'final', 'report', 'exam', 'order', ':', 'chest', '.', 'history', ':', 'status', 'post', 'int', '##uba', '##tion', ',', 'left', 'i', '##j', 'placement', '.', 'chest', ':', 'a', 'single', 'portable', 'su', '##pine', 'view', 'at', '19', 'hours', 'is', 'compared', 'to', 'previous', 'examination', 'of', 'two', 'hours', 'ago', '.', 'since', 'the', 'previous', 'exam', ',', 'there', 'has', 'been', 'insertion', 'of', 'left', 'i', '##j', 'central', 've', '##nous', 'cat', '##het', '##er', 'with', 'the', 'tip', 'in', 'pro', '##xi', '##mal', 'sv', '##c', '.', 'again', 'seen', 'end', '##ot', '##rac', '##hea', '##l', 'tube', 'in', 'thor', '##ac', '##ic', 'inlet', 'and', 'needs', 'to', 'be', 'advanced', '3', 'cm', 'distal', '##ly', '.', 'the', 'right', 'sub', '##cl', '##avian', 'central', 've', '##nous', 'cat', '##het', '##er', 'remains', 'in', 'place', '.']\n","chunk 20 tokenize start!\n","First sentence tokenized\n","['progress', 'note', ':', '7', '##p', '-', '7', '##a', 'patient', 'remained', 'stable', 'overnight', '.', 'see', 'care', '##vu', '##e', 'for', 'details', '.', 'ne', '##uro', ':', 'patient', 'remains', 'se', '##date', '##d', 'on', 'fen', '##tan', '##yl', '50', 'mc', '##gs', ',', 'increased', 'verse', '##d', 'to', '2', 'mg', 'since', 'patient', 'was', 'more', 'awake', 'than', 'se', '##date', '##d', 'over', 'the', 'beginning', 'of', 'the', 'evening', ',', 'is', 'currently', 'on', '2', 'mg', ',', 'but', 'has', 'periods', 'of', 'spontaneously', 'waking', 'up', 'that', 'as', 'if', 'startled', 'from', 'a', 'sleep', 'but', 'quickly', 'relax', '##es', '.', 'pupils', '3', 'mm', ',', 'brisk', ',', 'will', 'not', 'obey', 'commands', 'but', 'opens', 'eyes', 'to', 'voice', '.', 'moves', 'all', 'ex', '##tre', '##mit', '##ies', '.', 'has', 'not', 'been', 'restrained', 'since', 'verse', '##d', 'increased', '.', 'cv', ':', 'stable', 'overnight', '.', 'still', 'having', 'frequent', 'pv', '##c', \"'\", 's', ',', 'hr', '59', '-', 'tried', 'to', 'we', '##an', 'lev', '##o', 'down', 'but', 'only', 'tolerated', 'till', '04', '##1', '##mc', '##g', '/', 'kg', '/', 'min', '.', 'lost', 'ali', '##ne', 'at', '230', '##0', 'with', 'numerous', 'attempts', 'to', 'reins', '##ert', '.', 'abandoned', 'till', '04', '##00', 'when', 'new', 'line', 'inserted', 'into', 'right', 'radial', '.', 'map', '66', '-', '70', 'on', 'current', 'dos', '##age', 'of', '04', '##1', 'mc', '##g', '/', 'kg', '/', 'min', '.', 'hc', '##t', 'has', 'been', 'stable', ',', '6', '/', '31', 'this', 'am', '.', 'wb', '##c', 'high', ',', 'k', 'and', 'ca', 'need', 'replacing', ',', 'currently', 'awaiting', 'orders', '.', 'lac', '##tate', 'this', 'am', 'is', '8', ',', 'up', 'from', '9', 'yesterday', '.', 'resident', 'aware', '.', 'blood', 'cultures', 'and', 'fungal', 'sent', 'this', 'am', '.', 'res', '##p', ':', 'has', 'clear', 'ae', 'on', 'left', 'side', 'but', 'ins', '##pi', '##r', 'w', '##hee', '##ze', 'and', 'coarse', 'to', 'right', '.', 'maintaining', 'sp', '##0', '##2', '96', '-', '100', '%', 'fi', '##o', '##2', 'increased', 'to', '60', '%', 'at', '06', '##00', 'for', 'pa', '##0', '##2', 'other', 'parameters', 'ok', '.', 'su', '##ction', '##ed', 'for', 'very', 'thick', 'yellow', '-', 'white', 'secret', '##ions', '.', 'chest', 'tube', 'rep', '##osition', '##ed', 'by', 'surgery', 'resident', '.', 'c', '##x', '##r', 'done', '.', 'continues', 'to', 'have', 'sq', 'em', '##phy', '##se', '##ma', ',', 'but', 'no', 'air', 'leak', ',', 'draining', 'small', 'amount', 'of', 'ser', '##ous', 'to', 'ser', '##osa', '##ng', 'drainage', '.', 'gi', ':', 'to', '##ler', '##ating', 'feeds', '.', 'residual', '##s', '15', '-', '50', ',', 'will', 'be', 'up', 'to', '70', '##ml', 'by', 'change', 'of', 'shift', '.', 'bow', '##el', 'sounds', 'present', ',', 'belly', 'looks', 'a', 'little', 'more', 'di', '##sten', '##ded', 'this', 'am', '.', 'will', 'be', 'adding', 'album', '##in', 'to', 'am', 'labs', '.', 'gu', ':', 'd', '/', 'c', \"'\", 'ed', 'bladder', 'irrigation', '##s', ',', 'no', 'cl', '##ots', 'seen', ',', 'had', 'some', 'bleeding', 'to', 'meat', '##us', 'earlier', 'in', 'evening', 'that', 'resolved', ',', 'sc', '##rot', '##um', 'remains', 'ed', '##ema', '##tou', '##s', ',', 'is', 'elevated', 'on', 'towel', '.', 'skin', ':', 'unchanged', ',', 'skin', 'is', 'weeping', 'from', 'old', 'pun', '##cture', 'sites', ',', 'co', '##cc', '##yx', 'covered', 'with', 'duo', '##der', '##m', '.', 'still', 'has', '+', 'pitt', '##ing', 'ed', '##ema', '.', 'plan', ':', 'continue', 'ab', '##x', 'ventilation', 'and', 'supportive', 'care', 'prevention', 'of', 'further', 'skin', 'breakdown']\n","chunk 21 tokenize start!\n","First sentence tokenized\n","['neon', '##ato', '##logy', 'attending', 'day', '84', 'pm', '##a', '39', '0', '/', '7', 'w', '##ks', 'remains', 'in', 'ra', '.', 'sat', '##s', '>', '95', '%', '.', 'rr', '40', '-', '60s', '.', 'mild', 're', '##tra', '##ctions', '.', 'mild', 'upper', 'air', '##way', 'congestion', '.', 'no', 'brady', '##card', '##ia', '.', 'on', 'kc', '##l', 'and', 'di', '##uri', '##l', '.', 'occasional', 'drift', '##s', 'with', 'feeds', 'to', 'upper', '80s', '.', 'no', 'murmur', '.', 'hr', '150', '-', '170', '##s', '.', 'pale', '.', 'bp', 'mean', 'weight', '37', '##20', '##g', '(', '+', '25', ')', '.', 't', '##f', 'at', '130', 'ml', '/', 'kg', '/', 'increased', 'proportion', 'of', 'po', 'feeds', '.', 'no', 'spit', '##s', '.', 'on', 'za', '##nta', '##c', ',', 'iron', ',', 'and', 'vitamin', 'e', '.', 'put', 'to', 'breast', '1', '-', '2', 'times', 'daily', '.', 'stable', 'temperature', 'in', 'open', 'cr', '##ib', '.', 'resolving', 'chronic', 'lung', 'disease', '.', 'will', 'continue', 'to', 'monitor', 'card', '##io', '-', 'respiratory', 'status', 'closely', '.', 'improved', 'feeding', '.', 'gaining', 'weight', '.', 'no', 'changes', 'for', 'now', '.']\n","chunk 22 tokenize start!\n","First sentence tokenized\n","['baseline', 'artifact', '.', 'probable', 'sin', '##us', 'rhythm', '.', 'low', 'limb', 'lead', 'voltage', '.', 'st', '-', 't', 'wave', 'abnormalities', '.', 'since', 'the', 'previous', 'tracing', 'of', 't', 'wave', 'abnormalities', 'are', 'now', 'less', 'prominent', '.']\n","chunk 23 tokenize start!\n","First sentence tokenized\n","['neon', '##ato', '##logy', '-', 'procedure', 'note', 'procedure', 'lu', '##mba', '##r', 'pun', '##cture', 'indication', ':', 's', '/', 'o', 'sep', '##sis', 'consent', 'obtained', 'from', 'su', '##cr', '##ose', 'pac', '##ifier', 'during', 'procedure', 'for', 'comfort', 'infant', 'on', 'open', 'warmer', 'with', 'cardiac', '&', 'ox', '##yme', '##try', 'monitoring', ',', 'in', 'nasal', 'can', '##nu', '##la', 'o', '##2', ',', 'in', 'left', 'lateral', 'position', '.', 'using', 'sterile', 'technique', ',', 'prep', '##ped', 'and', 'dr', '##app', '##ed', ',', '.', '2', 'cc', '10', '%', 'lid', '##oca', '##ine', '22', 'ga', 'spinal', 'needle', 'insert', '##ted', 'between', 'l', '##4', '-', '5', ',', 'rec', '##ie', '##ved', 'blood', ',', 'needle', 'removed', ',', 'and', 'another', 'needle', 'inserted', '.', 'again', 'rec', '##ie', '##ved', 'initially', 'blood', 'which', 'cleared', ',', 're', '##em', '##ove', '##d', '~', '5', 'cc', 'fluid', '.', 'needle', 'removed', ',', 'sent', 'for', 'cu', '##ll', '##ture', ',', 'cell', 'count', ',', 'pro', ',', 'glucose']\n","chunk 24 tokenize start!\n","First sentence tokenized\n","['patient', 'ex', '##tub', '##ated', 'and', 'placed', 'on', '50', '%', 'cool', 'mist', ',', 'bs', 'cong', '##ested', ',', 'responding', 'to', 'commands', 'with', 'marked', 'level', 'of', 'pass', '##ivity', '.', 'ordered', 'for', 'al', '##bu', '##terol', 'q', '##4', 'pr', '##n', 'done', 'at', '4', '##pm', '.', 'bs', 'cong', '##ested', ',', 'rr', '18', ',', '%', 'sat', '95', 'changed', 'to', 'n', '/', 'c', '3', 'l', '.']\n","chunk 25 tokenize start!\n","First sentence tokenized\n","['sin', '##us', 'ta', '##chy', '##card', '##ia', 'vent', '##ric', '##ular', 'premature', 'complexes', 'left', 'vent', '##ric', '##ular', 'hyper', '##tro', '##phy', 'with', 'st', '-', 't', 'abnormalities', 'the', 'st', '-', 't', 'changes', 'are', 'diffuse', '-', 'cannot', 'exclude', 'in', 'part', 'is', '##che', '##mia', '-', 'clinical', 'correlation', 'is', 'suggested', 'since', 'previous', 'tracing', 'of', ',', 'sin', '##us', 'ta', '##chy', '##card', '##ia', 'and', 'vent', '##ric', '##ular', 'ec', '##top', '##y', 'present']\n","chunk 26 tokenize start!\n","First sentence tokenized\n","['neon', '##ato', '##logy', 'attending', 'progress', 'note', ':', 'do', '##l', '#', '6', 'continues', 'in', 'ra', 'rr', '=', '50', '-', '70', \"'\", 's', ',', '1', 'spell', 'in', 'past', '24', 'hours', '.', 'bp', 'mean', '=', '49', ',', 'hr', '=', '150', \"'\", 's', ',', 'weight', '=', '154', '##5', '(', 'inc', '20', '##g', ')', ',', 'on', 't', '##f', '=', '120', 'cc', '/', 'kg', '/', 'd', ',', 'increasing', 'feeds', 'at', '15', '##cc', '/', 'kg', '/', 'd', 'q', 'd', '##no', 'spit', '##s', 'ds', '##t', '##x', '=', '70', 'this', 'am', '.', 'rebound', '=', '0', 'pe', ':', 'well', 'appearing', ',', 'br', '##uising', ',', 'slightly', 'ja', '##und', '##ice', '##d', ',', 'af', '##of', ',', 'normal', 's', '##1', '##s', '##2', ',', 'no', 'murmur', '.', 'breath', 'sounds', 'clear', ',', 'mild', 'ic', '/', 'sc', 're', '##t', '##x', '.', 'abdomen', 'soft', ',', 'non', '##ten', '##der', ',', 'bow', '##el', 'sounds', 'present', ',', 'ex', '##t', 'warm', ',', 'well', 'per', '##fus', '##ed', 'tone', 'ag', '##a', '.', 'imp', '/', 'plan', ':', 'x', '-', '31', 'week', 'infant', 'with', 'mild', 'ao', '##p', ',', 'f', 'and', 'g', ',', 's', '/', 'p', 'ph', '##ys', '##iol', '##og', '##ic', 'ja', '##und', '##ice', '.', 'rec', '##he', '##ck', 'in', 'am', 'continue', 'advancing', 'feeds', 'monitor', 'for', 'feeding', 'into', '##ler', '##ance', 'continue', 'monitor', 'for', 'spells']\n","chunk 27 tokenize start!\n","First sentence tokenized\n","['respiratory', 'care', 'baby', 'continues', 'on', 'pro', '##ng', 'cp', '##ap', '6', 'with', '02', 're', '##q', '23', '-', '33', '%', 'this', 'shift', '.', 'bs', 'clear', '.', 'rr', '40', \"'\", 's', '-', '60', \"'\", 's', 'with', 'baseline', 're', '##tra', '##ctions', '.', 'one', 'mild', 'st', '##im', 'brady', 'this', 'shift', '.', 'on', 'caf', '##fe', '##ine', '.', 'will', 'con', '##t', 'cp', '##ap', ',', 'monitor', '.']\n","chunk 28 tokenize start!\n","First sentence tokenized\n","['8', ':', '41', 'am', 'chest', '(', 'portable', 'ap', ')', 'clip', '#', 'reason', ':', 'lines', 'and', 'et', '##t', 'po', '##sit', '##on', 'post', 'op', 'gas', '##tre', '##ct', '##omy', ';', '?', 'ch', '##f', ',', 'pt', '##x', 'medical', 'condition', ':', '84', 'year', 'old', 'man', 'with', 'u', '##gi', '##b', ',', 'arrest', ',', 'urgent', 'gas', '##tre', '##ct', '##omy', ',', 'on', 'vent', '##ila', '##tor', 'reason', 'for', 'this', 'examination', ':', 'lines', 'and', 'et', '##t', 'po', '##sit', '##on', 'post', 'op', 'gas', '##tre', '##ct', '##omy', ';', '?', 'ch', '##f', ',', 'pt', '##x', 'final', 'report', 'indication', ':', 's', '/', 'p', 'gas', '##tre', '##ct', '##omy', '.', 'portable', 'chest', ':', 'comparison', 'is', 'made', 'to', 'film', 'of', 'one', 'day', 'earlier', '.', 'the', 'et', 'tube', ',', 'left', 'sub', '##cl', '##avian', 'central', 'line', ',', 'and', 'sg', 'cat', '##het', '##er', 'remain', 'in', 'good', 'position', ';', 'the', 'ng', 'tube', 'has', 'been', 'removed', '.', 'the', 'lung', 'volumes', 'are', 'reduced', '.', 'the', 'right', 'lung', 'appears', 'essentially', 'clear', '(', 'there', 'may', 'be', 'sub', '##se', '##gm', '##ental', 'ate', '##le', '##cta', '##sis', 'at', 'the', 'periphery', 'of', 'the', 'right', 'upper', 'lobe', ')', '.', 'there', 'is', 'further', 'worse', '##ning', 'of', 'ae', '##ration', 'in', 'the', 'left', 'base', ',', 'with', 'new', 'ob', '##scu', '##ration', 'of', 'the', 'left', 'hem', '##idia', '##ph', '##rag', '##m', 'and', 'left', 'cp', 'angle', '.', 'findings', 'could', 'reflect', 'e', '##ff', '##usion', '/', 'ate', '##le', '##cta', '##sis', ',', 'although', 'pneumonia', 'cannot', 'be', 'excluded', '.', 'impression', ':', 'worsened', 'ae', '##ration', 'at', 'left', 'base', ',', 'as', 'described', '.']\n","chunk 29 tokenize start!\n","First sentence tokenized\n","['np', '##n', '1900', '-', '07', '##00', '3', 'fen', 'current', 'weight', '230', 'kg', ',', 'up', '50', 'grams', '.', 't', '##f', 'remain', 'at', '150', '##cc', '/', 'kg', '/', 'day', 'of', 'b', '##m', '/', 'pe', 'to', '##ler', '##ating', 'feeding', '##s', 'well', '.', 'abd', 'soft', ',', 'bs', '+', '.', 'no', 'spit', '##s', 'min', 'as', '##p', '.', 'void', '##ing', 'and', 'stool', '##ing', '.', 'des', '##iti', '##n', 'applied', 'to', 'butt', '##ocks', '.', '4', 'dev', 'te', '##mp', 'stable', 'in', 'open', 'cr', '##ib', '.', 'awake', 'and', 'active', 'with', 'cares', '.', 'sleeps', 'well', 'between', 'cares', '.', '5', 'parenting', 'dad', 'called', 'for', 'update', '.', 'will', 'be', 'in', 'for', 'visit', 'tomorrow', '.', '8', 'cv', 'mu', '##rm', '##er', 'noted', '.', 'hr', '150', '-', '170', \"'\", 's', '.', 'warm', 'pink', 'and', 'well', 'per', '##fus', '##ed', '.']\n","chunk 30 tokenize start!\n","First sentence tokenized\n","['3', ':', '17', 'pm', 'chest', 'port', '.', 'line', 'placement', ';', '-', '77', 'by', 'different', 'physician', '#', 'reason', ':', 'please', 'assess', 'location', 'of', 'cv', '##l', 'tip', ',', 'and', 'please', 'r', '/', 'o', 'pt', '##x', 'admitting', 'diagnosis', ':', 'amp', '##ulla', '##ry', 'mass', '/', 'sd', '##a', 'medical', 'condition', ':', '81', 'year', 'old', 'woman', 's', '/', 'p', 'new', 'left', 'sub', '##cl', '##avian', 'central', 'line', 'placement', '.', 'reason', 'for', 'this', 'examination', ':', 'please', 'assess', 'location', 'of', 'cv', '##l', 'tip', ',', 'and', 'please', 'r', '/', 'o', 'pt', '##x', 'final', 'report', 'indication', ':', 'new', 'left', '-', 'sided', 'central', 've', '##nous', 'line', ',', 'assess', 'line', 'and', 'question', 'p', '##ne', '##um', '##otho', '##ra', '##x', '.', 'comparison', ':', 'chest', 'x', '-', 'ray', 'from', 'this', 'morning', 'at', '9', ':', '59', 'a', '.', 'm', '.', 'single', 'portable', 'ap', 'su', '##pine', 'chest', 'radio', '##graph', ':', 'there', 'is', 'a', 'new', 'left', 'sub', '##cl', '##avian', 'central', 've', '##nous', 'line', 'with', 'its', 'tip', 'in', 'the', 'upper', 'superior', 've', '##na', 'ca', '##va', '.', 'there', 'is', 'no', 'evidence', 'of', 'p', '##ne', '##um', '##otho', '##ra', '##x', '.', 'the', 'other', 'lines', 'and', 'tubes', 'are', 'unchanged', 'in', 'position', '.', 'there', 'has', 'been', 'slight', 'interval', 'improvement', 'in', 'the', 'bilateral', 'basil', '##ar', 'op', '##ac', '##ities', 'as', 'well', 'as', 'bilateral', 'pl', '##eur', '##al', 'e', '##ff', '##usions', '.', 'impression', ':', 'left', 'sub', '##cl', '##avian', 'central', 've', '##nous', 'line', 'in', 'appropriate', 'position', ',', 'no', 'p', '##ne', '##um', '##otho', '##ra', '##x', '.', 'interval', 'improvement', 'in', 'pulmonary', 'ed', '##ema', '.']\n","chunk 31 tokenize start!\n","First sentence tokenized\n","['1900', '-', '230', '##0', 'pt', 'follow', 'commands', ',', 'mae', ',', 'per', '##rl', '##a', '.', 'fen', '##tan', '##yl', 'gt', '##t', 'dc', \"'\", 'd', 'this', 'am', 'pt', 'c', '/', 'o', 'pain', 'to', 'inc', '##ision', '##al', 'area', '.', 'ro', '##xi', '##ce', '##t', '5', '##ml', 'x', '##2', 'given', 'for', 'pain', 'relief', '.', 'ns', '##r', 'bp', 'h', '##t', '##n', '140', '-', '150', \"'\", 's', 'br', '##ei', '##fly', 'to', '170', \"'\", 's', 'when', 'turned', '.', 'at', 'rest', 'bp', '140', \"'\", 's', '.', 'goal', '>', 'lungs', 'with', 'r', '##hon', '##chi', 'diminished', 'in', 'the', 'l', 'base', '.', 'su', '##ction', 'small', 'thick', 'white', 'sp', '##ut', '##um', '.', 'sat', '##s', '98', '%', 'on', 'ac', 'for', 'no', '##c', '.', 'o', '##cc', 'position', '##al', 'air', '##lea', '##k', 'no', 'loss', 'of', 'tv', 'or', 'sat', '##s', '.', 'pt', 'denies', 'sob', '.', 'stern', '##al', 'wound', 'with', 'wound', 'va', '##c', 'in', 'place', 'draining', 'ser', '##ous', 'drain', '.', 'dr', '##sg', 'leg', 'and', 'media', '##sti', '##nal', 'areas', '.', 'pr', '##bc', '1', 'unit', 'infused', 'hc', '##t', 'sent', 'awaiting', 'results', '.', '30', '##cc', 'residual', 'ne', '##pro', 't', '##f', '.', 'mushroom', 'bag', 'in', 'place', '.', 'see', 'care', '##vu', '##e', '.']\n","chunk 32 tokenize start!\n","First sentence tokenized\n","['neon', '##ato', '##logy', 'attending', 'progress', 'note', 'now', 'day', 'of', 'life', 'card', '##ior', '##es', '##pi', '##rator', '##y', 'status', 'stable', 'in', 'ra', '.', 'one', 'episode', 'of', 'brady', '##card', '##ia', 'during', 'feeding', 'today', '.', 'on', 'caf', '##fe', '##ine', '.', 'w', '##t', '.', '151', '##0', '##gm', 'up', '20', '##gm', 'on', '150', '##cc', '/', 'kg', '/', 'd', 'of', 'mm', '##26', 'well', 'tolerated', '.', 'normal', 'urine', 'and', 'stool', 'output', '.', 'assessment', '/', 'plan', ':', 'steady', 'progress', 'continues', '.', 'will', 'increase', 'to', 'mm', '##26', 'with', 'promo', '##d', '.', 'hu', '##s', 'planned', 'for', 'tomorrow', '.']\n","chunk 33 tokenize start!\n","First sentence tokenized\n","['4', 'ic', '##u', 'nursing', 'progress', 'note', ':', 'gi', ':', 'pt', 'had', 'e', '##g', '##d', 'this', 'am', '.', '.', 'no', 'active', 'bleeding', '.', 'ul', '##cera', '##tion', 'at', 'ge', 'junction', '.', '.', 'started', 'on', 'cara', '##fat', '##e', '.', '.', 'advance', 'diet', 'to', 'clear', 'li', '##q', '##s', '.', 'had', '2', 'stool', '##s', 'today', '.', '.', 'black', '/', 'brown', 'ob', '+', '.', '.', 'last', 'hc', '##t', 'at', '1700', 'is', 'pt', 'is', 'not', 'or', '##th', '##o', '-', 'static', '.', 'iv', '##f', '80', '##hr', 'cardiac', ':', 'hr', '70', '-', '90', '##af', '.', 'no', 've', '##a', '.', 'bp', '88', '-', '120', '/', '60', '-', '.', 'gu', ':', 'foley', 'cat', '##h', 'in', '.', '.', '50', '-', '100', '##cc', 'hr', '.', 'respiratory', ':', 'clear', 'lung', 'sounds', '.', '.', 'ra', 'sat', '##s', '97', '-', '100', '%', '.', 'rr', '16', '-', '.', 'strong', 'cough', '.', '.', '?', '?', 'as', '##piration', 'after', 'vomiting', 'last', 'eve', '.', '.', 'id', ':', 'te', '##mp', '99', '-', '99', ',', 'skin', ':', 'duo', '##der', '##m', 'on', 'co', '##cc', '##yx', '.', '.', 'pt', 'has', 'dry', '.', '.', 'red', 'patch', '##y', 'skin', '.', '.', 'no', 'special', 'care', '.', 'lines', '3', 'pi', '##v', '.', '.', 'social', ':', 'pts', 'wife', 'and', 'daughter', 'in', '.', '.', 'updated', 'on', 'condition', '.', 'di', '##sp', '##o', ':', 'called', 'out', 'to', 'medical', 'floor', '.']\n","chunk 34 tokenize start!\n","First sentence tokenized\n","['at', '##rial', 'sensed', 'vent', '##ric', '##ular', 'paced', 'rhythm', '.', 'vent', '##ric', '##ular', 'premature', 'beat', '.', 'compared', 'to', 'the', 'previous', 'tracing', 'of', 'no', 'diagnostic', 'changes', '.']\n","chunk 35 tokenize start!\n","First sentence tokenized\n","['add', '##end', '##um', 'to', 'np', '##n', 'fen', ':', 'remains', 'ad', 'li', '##b', 'on', 'a', 'minimum', 'of', '100', '##cc', '/', 'kg', '/', 'day', '(', '50', '##cc', 'q', '##4', \"'\", ')', '.', 'attempted', 'to', 'po', '@', '(', 'took', '20', '##cc', 'w', '/', 'dad', ')', ',', '230', '##0', '(', 'took', 'nothing', 'w', '/', 'dad', ')', ',', '01', '##00', '(', 'took', 'nothing', 'w', '/', 'this', 'rn', 'using', 'red', 'nipple', ')', ',', 'and', '02', '##00', '(', 'took', '8', '##cc', 'w', '/', 'this', 'rn', 'using', 'regular', 'yellow', 'nipple', ')', '.', 's', '/', 'w', ',', 'decision', 'was', 'made', 'to', 'ga', '##va', '##ge', 'remaining', 'feed', 'from', '02', '##00', '(', '42', '##cc', 'ga', '##va', '##ged', ')', '.', 'was', 'very', 'hard', 'to', 'calm', 'all', 'evening', '/', 'night', ',', 'not', 'truly', 'sleeping', 'at', 'all', '.', 'at', '01', '##00', ',', 'she', 'grew', 'increasingly', 'agitated', 'w', '/', 'cares', ',', 'especially', 'when', 'touching', 'her', 'lower', 'limbs', '.', 'she', 'was', 'given', 'ace', '##tam', '##ino', '##ph', '##en', '&', 'su', '##cr', '##ose', 'water', '.', 'since', 'her', 'ga', '##va', '##ge', 'feeding', ',', 'she', 'has', 'remained', 'asleep', '.', 'will', 'continue', 'to', 'monitor', 'her', 'pain', 'and', 'fluid', 'status', '.']\n","chunk 36 tokenize start!\n","First sentence tokenized\n","['10', ':', '09', 'am', 'chest', '(', 'portable', 'ap', ')', 'clip', '#', 'reason', ':', 'eva', '##l', 'progression', 'admitting', 'diagnosis', ':', 'dia', '##bet', '##ic', 'ke', '##to', '##ac', '##ido', '##sis', 'medical', 'condition', ':', '47', 'year', 'old', 'man', 'int', '##uba', '##ted', ',', 'pneumonia', 'reason', 'for', 'this', 'examination', ':', 'eva', '##l', 'progression', 'final', 'report', 'chest', 'portable', 'indication', ':', '47', '-', 'year', '-', 'old', 'man', 'int', '##uba', '##ted', ',', 'pneumonia', ',', 'evaluate', 'for', 'progression', '.', 'chest', 'portable', ':', 'comparison', 'is', 'made', 'to', 'a', 'prior', 'examination', 'of', '.', 'the', 'heart', 'is', 'normal', 'in', 'size', '.', 'the', 'media', '##sti', '##nal', 'and', 'hi', '##lar', 'con', '##tour', '##s', 'are', 'unchanged', '.', 'there', 'are', 'patch', '##y', 'op', '##ac', '##ities', 'within', 'both', 'lungs', ',', 'these', 'are', 'significantly', 'improved', '.', 'a', 'left', 'central', 've', '##nous', 'line', 'is', 'seen', 'with', 'its', 'tip', 'in', 'appropriate', 'position', '.', 'the', 'et', 'tube', 'is', 'identified', '1', 'cm', 'from', 'the', 'car', '##ina', 'in', 'adequate', 'position', '.', 'impression', ':', 'improvement', 'in', 'the', 'consolidation', 'in', 'both', 'lungs', '.']\n","chunk 37 tokenize start!\n","First sentence tokenized\n","['neon', '##ato', '##logy', 'attending', 'add', '##end', '##um', '-', 'physical', 'examination', 'hee', '##nt', 'af', '##sf', 'chest', 'minimal', 're', '##tra', '##ctions', ';', 'good', 'bs', 'bi', '##lat', ';', 'no', 'crack', '##les', 'cv', '##s', 'well', 'per', '##fus', '##ed', ';', 'rr', '##r', ';', 'fe', '##m', 'pulses', 'normal', ';', 's', '##1', '##s', '##2', 'normal', ';', 'no', 'murmur', 'abd', 'soft', ',', 'non', '-', 'di', '##sten', '##ded', ';', 'no', 'organ', '##ome', '##gal', '##y', ';', 'no', 'masses', ';', 'bs', 'active', 'cn', '##s', 'active', ',', ',', 'res', '##p', 'to', 'st', '##im', ';', 'ag', '##a', ';', 'moving', 'all', 'ex', '##t', 'int', '##eg', 'normal', '##ad', '##den', '##du', '##m', '-', 'family', 'meeting', 'updated', 'regarding', 'frank', 'and', 'current', 'clinical', 'status', ',', 'natural', 'history', 'of', 'ap', '##nea', 'of', 'prem', '##at', '##urity', ',', 'possible', 'contribution', 'of', 'ref', '##lux', ',', 'management', 'of', 'both', 'dia', '##gno', '##ses', ',', 'discharge', 'criteria', '.', 'asked', 'appropriate', 'questions', '.', '(', 'time', '30', 'minutes', ')', '.']\n","chunk 38 tokenize start!\n","First sentence tokenized\n","['7', '##p', 'to', '7', '##a', 'mic', '##u', 'progress', 'note', 'ne', '##uro', '-', 'a', '+', 'o', 'x', '##3', ',', 'slightly', 'fatigue', '##d', '.', 'pt', 'slept', 'most', 'of', 'the', 'no', '##c', '.', 'res', '##p', '-', 'remains', 'on', '02', '5', '##ln', '##c', 'and', '55', '%', 'vent', '##i', 'mask', '.', '02', 'sat', '##s', '93', '-', '97', '%', 'with', 'rr', '20', '-', '30', 'breaths', '/', 'min', '.', 'lungs', 'coarse', ',', 'diminished', 'at', 'bases', ',', 'no', 'w', '##hee', '##zing', 'noted', '.', 'c', '-', 'v', '-', 'hr', '92', '-', '110', 'st', ',', 'no', 'ec', '##top', '##y', 'noted', '.', 'bp', '110', '-', '130', '/', '50', '-', 'f', '/', 'e', '-', 't', '##fb', 'ne', '##g', 'approx', '1500', 'cc', '##s', 'yes', '##t', '(', 'goal', '2', '##l', 'ne', '##g', ')', '.', 'given', '40', 'mg', '##s', 'las', '##ix', 'at', 'with', 'di', '##ures', '##is', 'of', 'approx', '500', 'cc', '##s', 'over', '2', 'hr', '##s', '.', 'u', '/', 'o', 'decreased', 'to', '45', 'cc', '##s', 'at', '01', '##00', '-', 'given', 'an', 'additional', '40', 'mg', 'las', '##ix', 'iv', 'with', 'good', 'results', '(', 'pt', 'di', '##ures', '##ed', 'approx', '1100', '##cc', '##s', 'over', 'the', 'next', '4', 'hr', '##s', ')', '.', 'k', '+', '2', 'at', 'mn', '.', 'gi', '-', 'to', '##ler', '##ating', '2', 'gm', 'na', 'diet', 'well', '.', '+', 'flat', '##us', ',', 'no', 'stool', '.', 'given', 'cola', '##ce', '.', '?', 'need', 'for', 'mom', 'or', 'du', '##lco', '##la', '##x', '.', 'a', '+', 'p', '-', '?', 'call', '-', 'out', 'to', 'floor', 'if', 'di', '##ures', '##is', 'results', 'in', 'decreased', '02', 'demand', '.', 'con', '##t', 'to', 'monitor', 'res', '##p', 'and', 'f', '+', 'e', 'status', '.', 'ns', '##g', 'transfer', 'note', 'initiated', '.']\n","chunk 39 tokenize start!\n","First sentence tokenized\n","['ne', '##uro', ':', 'se', '##date', '##d', 'on', 'fen', '##t', 'and', 'mid', '##az', 'gt', '##ts', ',', 'pupils', 'are', 'equal', 'and', 'reactive', 'to', 'light', ',', 'patient', 'does', 'open', 'eyes', 'to', 'sp', '##ee', '##ach', ',', 'does', 'grimace', 'with', 'mouth', 'care', ',', 'giving', 'patient', 'mid', '##az', 'and', 'fen', '##t', 'bo', '##lus', '##es', 'with', 'ds', '##d', 'changes', 'and', 'turning', '.', 'cardiac', ':', 'ns', '##r', 'with', 'no', 'ec', '##top', '##y', ',', 'continues', 'lev', '##o', 'gt', '##t', 'and', 'up', 'slightly', 'on', 'rate', ',', 'pal', '##pi', '##ble', 'pe', '##dial', 'pulses', ',', 'skin', 'is', 'warm', 'and', 'dry', ',', '+', '2', 'ed', '##ema', 'in', 'ex', '##tre', '##mit', '##ies', ',', 'continues', 'to', 'be', 'h', '##yp', '##oth', '##er', '##mic', 'requiring', 'bai', '##r', 'hug', '##ger', '.', 'res', '##p', ':', 'lungs', 'are', 'coarse', ',', 'ab', '##gs', 'are', 'good', ',', 'ct', 'system', 'with', '+', 'air', 'leak', 'and', 'is', 'draining', 'ser', '##ous', 'fluid', ',', 's', '##x', '##ned', 'with', 'no', 'secret', '##ions', 'gained', '.', 'skin', ':', 'chest', 'ds', '##d', 'changed', 'per', 'team', ',', 'team', 'thought', 'chest', 'did', 'look', 'a', 'little', 'better', ',', 'co', '##cc', '##yx', 'with', 'ds', '##d', 'that', '##r', 'is', 'cd', '##i', ',', 'bi', '##lat', 'lower', 'legs', 'with', 'ds', '##ds', 'that', 'are', 'cd', '##i', ',', 'heels', 'are', 'elevated', 'off', 'bed', ',', 'does', 'have', 'black', 'areas', 'on', 'back', 'of', 'heels', '.', 'gi', '/', 'gu', ':', 'continues', 'with', 't', '##fs', 'advancing', 'tow', '##rds', 'goal', ',', 't', '##f', 'residual', '##s', 'high', 'md', 'aware', 'and', 'wants', 'to', 'continue', 'tow', '##rds', 'goal', ',', 'h', '##yp', '##oa', '##ctive', 'bow', '##el', 'sounds', ',', 'liquid', 'stool', '##s', '-', 'fi', '##b', 'on', 'and', ',', 'on', 'ri', '##ss', ',', 'continues', 'cv', '##v', '##h', 'with', 'goal', 'to', 'make', 'patient', 'even', '.', 'id', ':', 'multiple', 'ab', '##x', 'see', 'mars', '.', 'plan', ':', 'we', '##an', 'lev', '##o', 'as', 'tolerate', '##s', ',', 'monitor', 'blood', 'sugar', '##s', ',', 'continue', 'ab', '##x', ',', 'continue', 'cv', '##v', '##h', '.']\n","chunk 40 tokenize start!\n","First sentence tokenized\n","['np', '##n', '07', '##00', '-', 'fen', ':', 't', '##f', '=', '140', '##cc', '/', 'k', '/', 'day', 'ss', '##c', '##20', 'po', '/', 'p', '##ng', '##t', '=', '53', '##cc', \"'\", 's', 'q', '##4', '##h', '.', 'infant', 'bottled', '50', '##cc', \"'\", 's', 'at', 'first', 'feed', 'with', 'good', 'coordination', '.', 'full', 'second', 'feed', 'ga', '##va', '##ged', 'over', '1', '##hr', ',', '10', '##min', '.', 'abd', 'benign', '.', 'no', 'spit', '##s', '.', 'max', 'as', '##pi', '##rate', '2', '##cc', \"'\", 's', '.', 'void', '##ing', '.', 'hem', '##e', 'ne', '##g', 'stool', '.', 'continue', 'to', 'monitor', 'tolerance', 'to', 'feeds', 'and', 'ability', 'to', 'po', 'feed', '.', 'dev', ':', 'stable', 'te', '##mp', ',', 'sw', '##ad', '##dled', ',', 'in', 'o', '##ac', '.', 'alert', 'and', 'active', '.', 'sleeps', 'sound', '##ly', 'between', 'cares', '.', 'likes', 'pac', '##ifier', '.', 'des', '##iti', '##n', 'applied', 'to', 'slightly', 'red', 'dia', '##per', 'area', '.', 'continue', 'to', 'promote', 'development', '.', 'parents', ':', 'parents', 'and', 'sibling', 'in', 'for', '1000', 'care', '.', 'parents', '.', 'mom', 'with', 'cares', '.', 'mom', 'bottled', 'infant', '.', 'updated', 'by', 'rn', '.', 'continue', 'to', 'update', 'and', 'support', '.']\n","chunk 41 tokenize start!\n","First sentence tokenized\n","['12', ':', '28', 'pm', 'ct', '##a', 'chest', 'w', '&', 'w', '/', 'o', 'c', '&', 'rec', '##ons', ';', 'ct', '100', '##cc', 'non', 'ionic', 'contrast', 'clip', '#', 'reason', ':', 'please', 'do', 'a', 'ct', '##a', 'with', 'cuts', 'of', 'the', 'root', 'of', 'and', 'ascending', 'ao', '##rta', 'admitting', 'diagnosis', ':', 'end', '##oca', '##rdi', '##tis', 'field', 'of', 'view', ':', '36', 'contrast', ':', 'opt', '##ira', '##y', 'am', '##t', ':', '100', 'medical', 'condition', ':', '42', 'year', 'old', 'man', 'with', 'end', '##oca', '##rdi', '##tis', ',', 'end', '##omy', '##oca', '##rdial', 'abs', '##ces', '##s', 'and', 'an', 'ao', '##rti', '##c', 'root', 'an', '##eu', '##yr', '##ism', 'found', 'by', 'mri', 'reason', 'for', 'this', 'examination', ':', 'please', 'do', 'a', 'ct', '##a', 'with', 'cuts', 'of', 'the', 'root', 'of', 'and', 'ascending', 'ao', '##rta', 'to', 'eva', '##l', 'the', 'ao', '##rti', '##c', 'root', 'an', '##eu', '##yr', '##ism', 'no', 'contra', '##ind', '##ication', '##s', 'for', 'iv', 'contrast', 'final', 'report', 'indication', ':', '42', '-', 'year', '-', 'old', 'with', 'ao', '##rti', '##c', 'valve', 'end', '##oca', '##rdi', '##tis', 'and', 'end', '##omy', '##oca', '##rdial', 'abs', '##ces', '##s', 'and', 'ao', '##rti', '##c', 'root', 'an', '##eur', '##ys', '##m', 'seen', 'on', 'mri', '.', 'technique', ':', 'ct', 'of', 'the', 'chest', 'pre', '-', 'and', 'post', '-', 'iv', 'contrast', '.', '110', 'cc', 'of', 'opt', '##ira', '##y', 'were', 'used', 'for', 'this', 'examination', '.', 'multi', '##pl', '##ana', '##r', 'reform', '##att', '##ed', 'images', 'were', 'obtained', '.', 'comparison', 'is', 'made', 'to', 'mri', 'from', '.', 'findings', ':', 'there', 'is', 'no', 'path', '##olo', '##gic', 'ax', '##illa', '##ry', ',', 'media', '##sti', '##nal', ',', 'or', 'hi', '##lar', 'l', '##ym', '##pha', '##den', '##opa', '##thy', '.', 'there', 'are', 'no', 'pl', '##eur', '##al', 'e', '##ff', '##usions', '.', 'lung', 'window', 'images', 'demonstrate', 'mild', 'bi', '##bas', '##ila', '##r', 'ate', '##le', '##cta', '##sis', '.', 'the', 'bro', '##nch', '##i', 'are', 'patent', 'to', 'the', 'segment', '##al', 'level', '.', 'ct', 'ang', '##io', '##gram', 'demonstrates', 'a', 'large', 'pseudo', '##ane', '##ury', '##sm', 'of', 'the', 'ao', '##rti', '##c', 'root', ',', 'which', 'in', 'the', 'corona', '##l', 'plane', 'measures', 'at', 'least', '3', 'x', '6', 'cm', '.', 'the', 'patient', 'is', 'post', 'ao', '##rti', '##c', 'valve', 'replacement', 'with', 'a', 'metallic', 'valve', 'in', 'place', '.', 'this', 'appears', 'to', 'have', 'a', 'sept', '##ation', 'within', 'it', '.', 'on', 'post', '-', 'contrast', 'images', ',', 'there', 'is', 'contrast', 'material', 'seen', 'within', 'the', 'left', 'lateral', 'aspect', 'of', 'the', 'pseudo', '##ane', '##ury', '##sm', '.', 'an', 'eccentric', 'jet', 'of', 'contrast', 'is', 'seen', 'from', 'the', 'para', '##val', '##vu', '##lar', 'region', 'extending', 'into', 'the', 'pseudo', '##ane', '##ury', '##sm', 'consistent', 'with', 'de', '##his', '##cence', 'of', 'the', 'ao', '##rti', '##c', 'valve', '.', 'clips', 'are', 'also', 'seen', 'in', 'the', 'region', 'of', 'the', 'pseudo', '##ane', '##ury', '##sm', 'from', 'prior', 'surgery', '.', 'there', 'is', 'no', 'per', '##ica', '##rdial', 'e', '##ff', '##usion', '.', 'the', 'heart', 'otherwise', 'appears', 'un', '##rem', '##ark', '##able', '.', 'no', 'pulmonary', 'em', '##bol', '##us', 'is', 'identified', '.', 'images', 'of', 'the', 'upper', 'abdomen', 'demonstrate', 'numerous', 'h', '##yp', '##ode', '##ns', '##ities', 'within', 'the', 'sp', '##leen', 'consistent', 'with', 'sp', '##len', '##ic', 'in', '##far', '##cts', '.', 'the', 'patient', 'is', 'post', '-', 'cho', '##le', '##cy', '##ste', '##ct', '##omy', 'with', 'clips', 'seen', 'in', 'the', 'gall', '##bla', '##dder', 'f', '##ossa', '.', 'soft', 'tissues', 'are', 'un', '##rem', '##ark', '##able', '.', 'os', '##se', '##ous', 'structures', 'demonstrate', 'median', 'stern', '##oto', '##my', '.', 'mild', 'de', '##gen', '##erative', 'changes', 'are', 'seen', 'in', 'the', 'thor', '##ac', '##ic', 'spine', '.', 'multi', '##pl', '##ana', '##r', 'reform', '##att', '##ed', 'images', 'were', 'essential', 'in', 'evaluating', 'the', 'above', 'findings', '.', 'impression', ':', 'large', 'ao', '##rti', '##c', 'root', 'pseudo', '##ane', '##ury', '##sm', ',', 'which', 'appears', 'to', 'have', 'two', 'compartments', '.', 'there', 'is', 'a', 'jet', 'of', 'contrast', 'material', 'extending', 'into', 'one', 'portion', 'of', 'the', 'pseudo', '##ane', '##ury', '##sm', 'sac', '.', 'this', 'likely', 'represents', 'ao', '##rti', '##c', 'reg', '##urg', '##itation', 'or', 'de', '##his', '##cence', '(', 'over', ')', '12', ':', '28', 'pm', 'ct', '##a', 'chest', 'w', '&', 'w', '/', 'o', 'c', '&', 'rec', '##ons', ';', 'ct', '100', '##cc', 'non', 'ionic', 'contrast', 'clip', '#', 'reason', ':', 'please', 'do', 'a', 'ct', '##a', 'with', 'cuts', 'of', 'the', 'root', 'of', 'and', 'ascending', 'ao', '##rta', 'admitting', 'diagnosis', ':', 'end', '##oca', '##rdi', '##tis', 'field', 'of', 'view', ':', '36', 'contrast', ':', 'opt', '##ira', '##y', 'am', '##t', ':', '100', 'final', 'report', '(', 'con', '##t', ')', 'of', 'the', 'ao', '##rti', '##c', 'valve', 'root', '.', 'numerous', 'sp', '##len', '##ic', 'in', '##far', '##cts', '.', 'minor', 'basil', '##ar', 'ate', '##le', '##cta', '##sis', '.', 'findings', 'were', 'immediately', 'communicated', 'to', 'doctor', 'at', 'the', 'completion', 'of', 'the', 'examination', '.']\n","chunk 42 tokenize start!\n","First sentence tokenized\n","['full', 'code', 'nk', '##da', 'universal', 'precautions', '39', 'y', '##r', '-', 'old', 'female', 'tx', 'to', 'm', '/', 'sic', '##u', 'from', '11', '##r', 'at', '.', 'pt', 'had', 'been', 'travelling', 'over', 'the', 'past', 'few', 'weeks', 'w', '/', 'family', 'to', ',', 'and', '.', 'she', 'noted', 'some', 'back', 'pain', 'while', 'on', 'vacation', 'and', 'family', 'noted', 'that', 'ms', 'changes', 'in', 'that', 'she', 'would', 'forget', 'what', 'she', 'was', 'doing', 'or', 'getting', 'lost', '.', 'on', ',', 'experienced', 'n', '/', 'v', '/', 'and', 'headache', 'and', 'went', 'to', '.', 'brain', 'ct', 'showed', 'mu', '##lt', 'lesions', ',', 'ct', 'torso', 'showed', 'ca', 'of', 'lung', '(', 'primary', 'site', ')', ',', 'w', '/', 'mets', 'to', 'liver', ',', 'spine', 'and', 'bones', '.', 'pt', 'was', 'tx', 'to', 'on', '.', 'pt', 'has', 'since', 'had', 'liver', 'b', '##x', ',', 'bone', 'scan', 'and', 'mri', 'spine', '.', 'started', 'on', 'che', '##mo', '.', 'she', 'was', 'to', 'have', 'first', 'x', '##rt', 'today', '(', ')', ',', 'but', 'required', 'at', '##iva', '##n', '1', '##mg', 'so', 'she', 'could', 'lie', 'flat', '.', 'she', 'was', 'then', 'found', 'to', 'be', 'too', 'un', '##res', '##pon', '##sive', '.', 'tx', 'to', 'm', '/', 'sic', '##u', '.', 'she', 'was', 'thought', 'to', 'have', 'had', 'a', 'seizure', '.', 'ne', '##uro', ':', 'upon', 'arrival', ',', 'she', 'was', 'un', '##res', '##pon', '##sive', ',', 'decor', '##tica', '##ting', 'post', '##uring', '.', 'she', 'was', 'moving', 'both', 'arms', 'bi', '##lat', 'and', 'r', 'leg', ',', 'but', 'no', 'movement', 'seen', 'in', 'l', 'leg', '.', 'pupils', '5', '##mm', '/', 'brisk', '.', 'r', 'vent', 'drain', 'placed', 'by', 'ns', '##urg', '.', 'initial', 'ic', '##p', '=', 'head', 'ct', 'done', 'and', 'upon', 'return', ',', 'ic', '##p', 'has', 'been', '.', 'draining', 'sl', 'blood', '-', 'tinged', 'fluid', '.', 'since', 'ct', 'she', 'was', 'more', 'awake', ',', 'moving', 'arms', 'bi', '##lat', '(', 'r', '>', 'l', ')', 'and', 'r', 'leg', ',', 'but', 'still', 'not', 'moving', 'l', 'se', '##g', 'sp', '##ont', '(', 'does', 'moves', 'w', '/', 'ta', '##ct', '##ile', 'st', '##im', ')', '.', 'looking', 'about', ',', 'but', 'not', 'focusing', 'and', 'not', 'following', 'any', 'commands', '.', 'dil', '##ant', '##in', 'level', 'upon', 'arrival', 'was', 'currently', 'no', 'dil', '##ant', '##in', 'ordered', '.', 'started', 'on', 'mann', '##ito', '##l', 'and', 'continued', 'on', 'dec', '##ad', '##ron', '.', 'cv', ':', 'hr', '=', '80', '-', '100', '##s', ',', 'ns', '##r', ',', 'no', 'ec', '##top', '##y', '.', 'bp', '=', '120', '-', '140', '##s', '/', '70s', '.', '+', 'per', '##ip', '##h', 'pulses', ',', 'no', 'ed', '##ema', ',', 'ex', '##tre', '##ms', 'warm', '.', 'res', '##p', ':', '2', '##l', 'n', '/', 'p', 'w', '/', '02', '##sat', '96', '-', '99', '%', '.', 'lungs', 'clear', 'bi', '##lat', ',', 'no', 'cough', 'gi', '/', 'gu', ':', 'abd', 'soft', ',', 'flat', '.', '+', 'bs', ',', 'no', 'b', '##m', '.', 'np', '##o', '.', 'foley', 'cat', '##h', 'clear', 'yellow', 'urine', '.', 'pt', 'has', 'men', '##ses', '.', 'skin', ':', 'intact', '.', 'access', ':', 'pi', '##v', '##x', 'id', ':', 'af', '##eb', '##ril', '##e', '.', 'on', 'ce', '##fo', '##tan', 'end', '##o', ':', 'bs', '=', '261', ',', 'covered', 'by', 'ri', '##ss', '.', 'labs', ':', 'wb', '##c', '=', '23', ',', 'na', '=', '132', ',', 'ab', '##g', 'normal', ',', 'other', 'labs', 'w', '##nl', 'social', ':', 'husband', ',', '2', 'children', '(', 'ages', ')', 'several', 'other', 'family', 'and', 'friends', 'in', '.', 'once', 'pt', 'settled', 'after', 'ct', ',', 'all', 'these', 'people', 'came', 'in', 'to', 'see', 'mrs', 'w', '/', 'their', 'video', 'and', 'regular', 'cameras', '.', 'doctor', 'spoke', 'at', 'length', 'w', '/', 'the', 'family', 'about', 'the', 'findings', 'and', 'pro', '##gno', '##sis', '.', 'hu', '##san', '##d', 'and', 'another', 'family', 'member', 'stayed', 'the', 'night', '.', 'plan', ':', 'q', '##1', '##hr', 'ne', '##uro', 'checks', ',', 'ad', '##m', 'mann', '##ito', '##l', 'and', 'dec', '##ad', '##ron', '.', 'monitor', 'vent', '##ric', 'drain', 'for', 'ic', '##p', '/', 'drainage', '.', 'assess', 'in', 'am', 'for', 'possible', 'tx', 'to', 'nme', '##d', 'team', '/', ',', 'possibly', 'to', 'vs', 'need', 'for', 'che', '##omo', '/', 'x', '##rt', 'on', '.']\n","chunk 43 tokenize start!\n","First sentence tokenized\n","['add', '##end', '##um', 'at', '##ra', '##umatic', 'int', '##uba', '##tion', '.', 'pt', 'comfortable', 'on', 'prop', '##of', '##ol', 'gt', '##t', '.', 'please', 'see', 'care', '##vu', '##e', 'as', 'needed', 'for', 'additional', 'information', '.', 'thank', 'you', '.']\n","chunk 44 tokenize start!\n","First sentence tokenized\n","['title', ':', 'chief', 'complaint', ':', '24', 'hour', 'events', ':', 'all', '##er', '##gies', ':', 'indo', '##met', '##ha', '##cin', 'gi', '##b', ';', 'ace', 'inhibitors', 'hyper', '##kal', '##emia', ';', 'anti', '-', 'in', '##fl', '##am', '/', 'anti', '##arth', 'agents', 'mis', '##c', '.', 'class', '##f', 'gi', '##b', ';', 'last', 'dose', 'of', 'antibiotics', ':', 'in', '##fusion', '##s', ':', 'other', 'ic', '##u', 'medications', ':', 'he', '##par', '##in', 'sodium', '(', 'prop', '##hyl', '##ax', '##is', ')', '-', '11', ':', '01', 'pm', 'other', 'medications', ':', 'changes', 'to', 'medical', 'and', 'family', 'history', ':', 'review', 'of', 'systems', 'is', 'unchanged', 'from', 'admission', 'except', 'as', 'noted', 'below', 'review', 'of', 'systems', ':', 'flows', '##hee', '##t', 'data', 'as', 'of', '07', ':', '15', 'am', 'vital', 'signs', 'hem', '##od', '##yna', '##mic', 'monitoring', 'fluid', 'balance', '24', 'hours', 'since', '12', 'am', 't', '##max', ':', '2', 'c', '(', '4', 'tc', '##urrent', ':', '35', 'c', '(', '95', 'hr', ':', '66', '(', '56', '-', '79', ')', 'bp', '##m', 'bp', ':', '118', '/', '50', '(', '66', ')', '{', '83', '/', '34', '(', '48', ')', '-', '133', '/', '72', '(', '85', ')', '}', 'mm', '##hg', 'rr', ':', '14', '(', '11', '-', '27', ')', 'ins', '##p', '/', 'min', 'sp', '##o', '##2', ':', '95', '%', 'heart', 'rhythm', ':', 'sr', '(', 'sin', '##us', 'rhythm', ')', 'w', '##gt', '(', 'current', ')', ':', '8', 'kg', '(', 'admission', ')', ':', '8', 'kg', 'total', 'in', ':', '69', '##5', 'ml', '68', 'ml', 'po', ':', 't', '##f', ':', 'iv', '##f', ':', '69', '##5', 'ml', '68', 'ml', 'blood', 'products', ':', 'total', 'out', ':', '67', '##4', 'ml', '760', 'ml', 'urine', ':', '67', '##4', 'ml', '760', 'ml', 'ng', ':', 'stool', ':', 'drains', ':', 'balance', ':', '21', 'ml', '-', '69', '##2', 'ml', 'respiratory', 'support', 'o', '##2', 'delivery', 'device', ':', 'nasal', 'can', '##nu', '##la', ',', 'high', 'flow', 'ne', '##b', 'vent', '##ila', '##tor', 'mode', ':', 'cp', '##ap', '/', 'ps', '##v', 'vt', '(', 'spontaneous', ')', ':', '83', '##7', '(', '505', '-', '83', '##7', ')', 'ml', 'rr', '(', 'spontaneous', ')', ':', '27', 'pee', '##p', ':', '8', 'cm', '##h', '##2', '##o', 'fi', '##o', '##2', ':', '95', '%', 'pip', ':', '14', 'cm', '##h', '##2', '##o', 'sp', '##o', '##2', ':', '95', '%', 'ab', '##g', ':', '34', '/', '52', '/', '65', '/', '30', '/', '0', 've', ':', '7', 'l', '/', 'min', 'pa', '##o', '##2', '/', 'fi', '##o', '##2', ':', '108', 'physical', 'examination', 'peripheral', 'vascular', ':', '(', 'right', 'radial', 'pulse', ':', 'not', 'assessed', ')', ',', '(', 'left', 'radial', 'pulse', ':', 'not', 'assessed', ')', ',', '(', 'right', 'd', '##p', 'pulse', ':', 'not', 'assessed', ')', ',', '(', 'left', 'd', '##p', 'pulse', ':', 'not', 'assessed', ')', 'skin', ':', 'not', 'assessed', 'ne', '##uro', '##logic', ':', 'responds', 'to', ':', 'not', 'assessed', ',', 'movement', ':', 'not', 'assessed', ',', 'tone', ':', 'not', 'assessed', 'labs', '/', 'radio', '##logy', '212', 'k', '/', 'ul', '9', 'g', '/', 'dl', '159', 'mg', '/', 'dl', '4', 'mg', '/', 'dl', '30', 'me', '##q', '/', 'l', '0', 'me', '##q', '/', 'l', '96', 'mg', '/', 'dl', '99', 'me', '##q', '/', 'l', '140', 'me', '##q', '/', 'l', '2', '%', '1', 'k', '/', 'ul', '10', ':', '07', 'am', '10', ':', '34', 'am', '04', ':', '58', 'pm', '10', ':', '01', 'pm', '01', ':', '50', 'am', '09', ':', '41', 'am', '04', ':', '14', 'pm', '05', ':', '39', 'pm', '09', ':', '03', 'pm', '04', ':', '07', 'am', 'wb', '##c', '6', '1', 'hc', '##t', '5', '2', 'pl', '##t', '206', '212', 'cr', '0', '0', '5', '4', 'tr', '##op', '##t', '03', '04', '04', '05', 'tc', '##o', '##2', '30', '34', '29', '29', 'glucose', '77', 'other', 'labs', ':', 'pt', '/', 'pt', '##t', '/', 'in', '##r', ':', '6', '/', '7', '/', '1', ',', 'ck', '/', 'ck', '##mb', '/', 'tr', '##op', '##oni', '##n', '-', 't', ':', '74', '/', '4', '/', '05', ',', 'differential', '-', 'ne', '##uts', ':', '9', '%', ',', 'l', '##ym', '##ph', ':', '6', '%', ',', 'mono', ':', '0', '%', ',', 'e', '##os', ':', '3', '%', ',', 'ca', '+', '+', ':', '0', 'mg', '/', 'dl', ',', 'mg', '+', '+', ':', '7', 'mg', '/', 'dl', ',', 'po', '##4', ':', '8', 'mg', '/', 'dl', 'assessment', 'and', 'plan', 'heart', 'failure', '(', 'ch', '##f', ')', ',', 'dia', '##sto', '##lic', ',', 'acute', 'on', 'chronic', 'renal', 'failure', ',', 'acute', '(', 'acute', 'renal', 'failure', ',', 'ar', '##f', ')', 'ic', '##u', 'care', 'nutrition', ':', 'g', '##ly', '##ce', '##mic', 'control', ':', 'lines', ':', '20', 'gauge', '-', '03', ':', '00', 'pm', '18', 'gauge', '-', '10', ':', '00', 'pm', 'prop', '##hyl', '##ax', '##is', ':', 'd', '##v', '##t', ':', 'stress', 'ul', '##cer', ':', 'va', '##p', ':', 'comments', ':', 'communication', ':', 'comments', ':', 'code', 'status', ':', 'disposition', ':']\n","chunk 45 tokenize start!\n","First sentence tokenized\n","['3', ':', '58', 'am', 'baby', '##gram', '(', 'chest', 'only', ')', 'clip', '#', 'reason', ':', 'evaluate', 'lung', 'fields', ',', 'et', '##t', 'position', ',', '?', 'status', 'right', 'sided', 'ate', 'admitting', 'diagnosis', ':', 'newborn', 'medical', 'condition', ':', 'infant', 'with', 'evolving', 'chronic', 'lung', 'disease', ',', 'presumed', 'pneumonia', 'reason', 'for', 'this', 'examination', ':', 'evaluate', 'lung', 'fields', ',', 'et', '##t', 'position', '?', 'status', 'right', 'sided', 'ate', '##le', '##cta', '##sis', 'final', 'report', 'portable', 'chest', 'at', 'at', '4', ':', '10', 'am', '.', 'history', ':', 'evolving', 'chronic', 'lung', 'disease', '.', 'findings', ':', 'comparison', 'is', 'yesterday', 'morning', '.', 'the', 'end', '##ot', '##rac', '##hea', '##l', 'tube', 'terminates', '1', 'cm', 'above', 'the', 'car', '##ina', '.', 'a', 'feeding', 'tube', 'extends', 'into', 'the', 'stomach', '.', 'lung', 'volumes', 'overall', 'are', 'improved', '.', 'the', 'right', 'middle', 'lobe', 'ate', '##le', '##cta', '##sis', 'has', 'resolved', '.', 'changes', 'of', 'diffuse', 'chronic', 'lung', 'disease', 'are', 'stable', '.', 'heart', 'size', 'is', 'unchanged', '.']\n","chunk 46 tokenize start!\n","First sentence tokenized\n","['respiratory', 'care', 'pt', 'continues', 'on', 'full', 'vent', '##ila', '##tory', 'support', '.', 'ni', '##tric', 'oxide', 'added', 'after', 'l', '##y', '##cs', '##is', 'treatment', 'in', 'cat', '##h', 'lab', '.', 'plan', ':', 'we', '##an', 'n', '.', 'o', '.', 'overnight', 'to', 'off', 'for', 'trip', 'to', 'i', '.', 'r', '.', 'in', 'am', 'will', 'continue', 'to', 'follow', 'closely', '.']\n","chunk 47 tokenize start!\n","First sentence tokenized\n","['10', ':', '14', 'am', 'chest', '(', 'portable', 'ap', ')', ';', '-', '76', 'by', 'same', 'physician', '#', 'reason', ':', 'please', 'check', 'placement', 'of', 'right', 'basil', '##ic', 'pic', '##c', 'line', 'please', 'pa', '##g', 'admitting', 'diagnosis', ':', 'stern', '##al', 'wound', 'infection', 'medical', 'condition', ':', '72', 'year', 'old', 'woman', 's', '/', 'p', 'cab', '##g', 'mv', 'repair', 'reason', 'for', 'this', 'examination', ':', 'please', 'check', 'placement', 'of', 'right', 'basil', '##ic', 'pic', '##c', 'line', 'please', 'page', 'iv', 'nurse', 'thanks', '#', 'final', 'report', 'indication', ':', '72', '-', 'year', '-', 'old', 'woman', 'status', 'post', 'cab', '##g', 'and', 'mit', '##ral', 'valve', 'repair', '.', 'assess', 'pic', '##c', 'line', 'position', '.', 'comparison', ':', 'at', '07', '##30', 'hours', '.', 'erect', 'ap', 'portable', 'chest', 'at', '104', '##0', 'hours', ':', 'since', 'the', 'study', 'of', '3', 'hours', 'prior', ',', 'a', 'right', 'arm', 'pic', '##c', 'has', 'been', 'inserted', ',', 'and', 'its', 'tip', 'is', 'not', 'visible', '.', 'the', 'line', 'turns', 'superior', '##ly', 'into', 'the', 'neck', 'and', 'off', 'the', 'film', '.', 'this', 'finding', 'was', 'discussed', 'with', 'the', 'iv', 'access', 'team', 'on', 'the', 'day', 'of', 'this', 'study', 'at', 'approximately', '123', '##0', 'hours', '.', 'two', 'chest', 'tubes', 'remain', 'in', 'similar', 'position', '.', 'stern', '##al', 'wire', 'su', '##tures', ',', 'media', '##sti', '##nal', 'clips', 'and', 'the', 'mit', '##ral', 'valve', 'repair', 'are', 'again', 'noted', '.', 'the', 'heart', 'size', 'is', 'unchanged', '.', 'there', 'is', 'an', 'increase', 'in', 'the', 'inter', '##sti', '##tial', 'markings', ',', 'suggesting', 'worse', '##ning', 'failure', '.', 'persistent', 'op', '##ac', '##ification', 'in', 'the', 'left', 'lung', 'base', ',', 'probably', 'represents', 'ate', '##le', '##cta', '##sis', 'and', 'possibly', 'small', 'e', '##ff', '##usion', '.', 'no', 'p', '##ne', '##um', '##otho', '##ra', '##x', '.', 'impression', ':', 'mal', '##position', '##ed', 'pic', '##c', ',', 'as', 'above', '.', 'increasing', 'inter', '##sti', '##tial', 'markings', ',', 'suggesting', 'worse', '##ning', 'failure', '.', 'persistent', 'left', 'lower', 'lobe', 'op', '##ac', '##ity', '.']\n","chunk 48 tokenize start!\n","First sentence tokenized\n","['probable', 'sin', '##us', 'ta', '##chy', '##card', '##ia', 'poor', 'r', 'wave', 'progression', 'lateral', 'st', '-', 't', 'changes', 'are', 'non', '##sp', '##ec', '##ific', 'since', 'previous', 'tracing', ',', 'sin', '##us', 'ta', '##chy', '##card', '##ia', 'note', ',', 'and', 'vent', '##ric', '##ular', 'premature', 'complex', 'absent']\n","chunk 49 tokenize start!\n","First sentence tokenized\n","['nursing', 'progress', 'note', '.', 'res', '##p', ':', 'pt', 'received', 'int', '##uba', '##ted', 'c', 'cp', '##ap', '/', 'ps', 'of', 'c', '40', '%', 'fi', '##o', 'small', 'amounts', 'of', 'brownish', 'sec', 'per', 'et', '##t', 'this', 'am', '.', 'am', 'rs', '##bi', '=', '90', \"'\", 's', '.', 'se', '##dation', 'we', '##ane', '##d', 'down', 'and', 'pt', 'placed', 'on', 'a', 'sb', '##t', 'c', '5', 'of', 'ps', 'and', 'no', 'pee', '##p', '.', 'pt', 'initially', 'did', 'well', 'before', 'becoming', 'hyper', '##dy', '##nami', '##c', 'and', 'agitated', '(', 'pt', 'had', 'a', 'small', 'no', '7', '#', 'et', '##t', ')', '.', 'ab', '##g', 'drawn', '@', 'this', 'time', 'c', 'the', 'following', 'values', ';', '41', '-', '40', '-', '61', 'c', 'a', 'nl', 'lac', '##tate', 'of', '1', '(', '5', '-', '0', ')', '.', 'team', 'into', 'eva', '##l', 'pt', ',', 'pt', 'subsequently', 'ex', '##tub', '##ated', '@', '13', ':', '00', 'to', 'a', '60', '%', 'cs', 'face', 'tent', '.', 'the', 'pt', 'has', 'done', 'fine', 'post', 'ex', '##tub', '##ation', 'c', 'no', 'evidence', 'of', 'sob', '/', 'd', '##ys', '##p', '##nea', '/', 'h', '##yp', '##ox', '##emia', '.', 'rr', 'has', 'been', 'in', 'the', '20', '-', '30', 'range', ',', 'sat', '##s', 'have', 'been', 'in', 'the', 'mid', '/', 'high', '90', \"'\", 's', 'range', '.', 'fi', '##o', '##2', 'has', 'been', 'we', '##ane', '##d', 'down', 'to', '4', '##ln', '##co', 'incentive', 'sp', '##iro', '##meter', 'provided', 'c', 'instructions', '/', 'encouragement', 'pt', 'easily', 'able', 'to', 'get', 'yellow', 'ball', 'to', 'top', 'of', 'cylinder', '.', 'pt', 'exhibits', 'a', 'strong', 'cough', 'reflex', 'expect', '##ora', '##ting', 'thin', 'clear', '/', 'tan', '-', 'tinged', 'sec', '.', 'pt', 'has', 'good', 'air', '##ation', 'of', 'all', 'lung', 'fields', ',', 'clear', 'in', 'upper', 'lobes', 'and', 'slightly', 'coarse', '@', 'the', 'bases', '.', 'pt', 'is', 'currently', 'resting', 'comfortably', 'in', 'nad', '.', 'the', 'pt', 'is', 'not', 'receiving', 'anti', '##b', '##x', '@', 'this', 'time', '.', 'cv', ':', 'hd', '##s', '.', '7', 't', '##max', ',', 'current', 'te', '##mp', 'is', 'pt', 'auto', '-', 'di', '##ures', '##ing', 'since', 'ex', '##ut', '##bation', '(', '1800', '##ml', 'u', '##o', 'since', ':', '00', ')', ',', 'pt', 'is', 'currently', 'net', 'input', 'approx', 'three', 'liter', '##s', 'since', 'admit', 'though', '.', 'the', 'pts', 'r', 'ac', 'pi', '##v', 'infiltrate', '##d', 'c', 'ph', '##le', '##bit', '##is', 'noted', '@', 'site', ',', 'pi', '##v', 'subsequently', 'd', '/', 'c', \"'\", 'ed', '.', 'ms', ':', 'aa', '##o', 'times', 'three', ',', 'following', 'all', 'commands', ',', 'able', 'to', 'art', '##iculate', 'needs', ',', 'mae', '.', 'pt', 'to', 'be', 'placed', 'on', 'ci', '##ba', 'scale', 'c', 'et', '##oh', 'withdrawal', 'a', 'distinct', 'po', '##ss', '.', 'pt', 'currently', 'denies', 'pain', 'and', 'appears', 'comfortable', '.', 'u', '##e', 'soft', 'wrist', 'restraints', 'd', '/', 'c', \"'\", 'ed', '.', 'gi', ':', 'pt', 'found', 'c', 'og', '##t', 'd', '/', 'c', \"'\", 'ed', 'by', 'pt', 'this', 'am', '.', 'pt', 'is', 'now', 'ex', '##tub', '##ated', 'and', 'has', 'been', 'able', 'to', 'to', '##l', 'po', 'ice', 'chips', 's', 'di', '##ff', '.', 'pt', 'diet', 'ad', '##v', 'to', 'h', '##2', '##o', ',', 'again', 's', 'evidence', 'of', 'as', '##piration', '/', 'd', '##ys', '##pha', '##sia', '.', 'will', 'con', '##t', 'to', 'ad', '##v', 'diet', 'as', 'to', '##l', '.', 'no', 'b', '##m', 'thus', 'far', 'today', '.', 'no', 'abd', 'c', '/', 'o', ',', 'abd', 'is', 'soft', '/', 'nt', '/', 'n', '##d', '.', 'der', '##m', ':', 'intact', '.', 'ph', '##le', '##bit', '##is', 'of', 'l', 'ac', 'noted', 'above', '.', 'family', ':', 'multiple', 'family', 'members', 'have', 'visited', 'today', ',', 'including', 'son', ',', 'wife', ',', 'mother', 'all', 'kept', 'ab', '##rea', '##st', 'of', 'pt', '/', 'status', '.', 'family', 'members', 'are', 'currently', 'visiting', '@', 'the', 'bs', '.', 'the', 'pt', 'is', 'a', 'full', 'code', '.', 'other', ':', 'please', 'see', 'care', '##vu', '##e', 'for', 'additional', 'pt', 'care', 'data', '/', 'comments', '.', 'un', '##iv', 'isolation', 'pro', '##c', 'in', 'place', '.']\n","chunk 50 tokenize start!\n","First sentence tokenized\n","['7', '##a', '-', '7', '##p', 'mic', '##u', 'nursing', 'progress', 'note', 'events', ':', 'pt', 'hyper', '##nat', '##rem', '##ic', '@', '152', 'this', 'am', '.', 'she', 'was', 'ordered', 'for', '2', 'liter', '##s', 'of', 'd', '##5', '##w', '@', '150', 'cc', '/', 'hr', '(', 'liter', '#', '2', 'is', 'currently', 'in', '##fus', '##ing', ')', '.', 'repeat', 'na', 'sent', 'this', 'eve', ';', 'results', 'pending', '.', 'ri', '##ss', 'tightened', 'd', '##5', '##w', 'in', '##fusion', '.', 'she', 'continues', 'to', 'be', 'let', '##har', '##gic', '/', 'confused', '.', 'she', 'had', 'difficulty', 'taking', 'med', '##s', 'this', 'am', '(', 'resulting', 'in', '^', 'coughing', ',', 'decreasing', 'o', '##2', 'sat', '##s', ')', 'and', 'the', 'decision', 'was', 'made', 'to', 'place', 'an', 'ng', '##t', '.', 't', '##fs', 'and', 'f', '##w', '##bs', 'were', 'initiated', 'after', 'tube', 'placement', 'was', 'confirmed', '.', 'art', '-', 'line', 'd', '/', 'c', \"'\", 'ed', '.', 'ro', '##s', ':', 'ne', '##uro', ':', 'pt', 'let', '##har', '##gic', '/', 'confused', '.', 'team', 'feels', 'this', 'is', 'likely', 'd', '/', 't', 'a', 'combination', 'of', 'hyper', '##nat', '##rem', '##ia', ',', 'he', '##pati', '##c', 'en', '##ce', '##pha', '##lo', '##pathy', 'and', 'hal', '##do', '##l', '.', 'hal', '##do', '##l', 'd', '/', 'c', \"'\", 'ed', 'this', 'am', '.', 'lac', '##tu', '##los', '##e', 'continues', 'at', '##c', '.', 'pt', 'is', 'oriented', 'to', 'person', '(', 'and', 'place', 'at', 'times', ')', '.', 'denies', 'pain', '.', 'mae', '.', 'res', '##p', ':', 'l', '##s', 'clear', ',', 'diminished', '@', 'bases', '.', 'rr', 'teens', '.', 'sat', '##s', '>', '94', '%', 'on', '2', 'liter', '##s', '.', 'cv', ':', 'hr', '70', \"'\", 's', '-', '80', \"'\", 's', ',', 'sr', ',', 'no', 'ec', '##top', '##y', 'noted', '.', 'ni', '##b', '##p', '90', \"'\", 's', '-', '100', \"'\", 's', '/', '50', \"'\", 's', '-', '60', \"'\", 's', '.', 'hc', '##t', 'stable', '@', '4', 'this', 'am', '.', 'gi', ':', 'abd', 'firm', '/', 'di', '##sten', '##ded', ',', '+', 'bs', '.', 'draining', 'am', '##ts', 'of', 'liquid', '/', 'green', 'stool', 'via', 'mushroom', 'cat', '##h', ',', 'gu', '##aia', '##c', 'negative', '.', 'flex', '##ise', '##al', 'leaking', 'this', 'am', 'despite', 'irrigation', 'and', 'reins', '##ert', '##ion', 'of', 'the', 'tube', ';', 'mushroom', 'cat', '##h', 'inserted', 'w', '/', 'good', 'results', '.', 't', '##fs', 'in', '##fus', '##ing', 'via', 'ng', '##t', '@', '10', 'cc', '/', 'hr', 'w', '/', 'o', 'difficulty', '(', 'goal', 'is', '40', 'cc', '/', 'hr', ')', '.', 'gu', ':', 'foley', 'cat', '##h', 'in', 'place', ';', 'draining', 'small', 'am', '##ts', 'of', 'amber', 'urine', 'w', '/', 'sediment', ',', '~', '15', '-', '40', 'cc', '/', 'hr', '.', 'id', ':', 'af', '##eb', '##ril', '##e', 'today', '.', 'wb', '##c', 'down', 'to', '8', 'this', 'am', '(', 'from', '5', ')', '.', 'pt', 'continues', 'on', 'van', '##co', '/', 'mer', '##open', '##em', '.', 'social', ':', 'pt', 'is', 'a', 'full', 'code', '.', 'husband', 'in', 'to', 'visit', 'this', 'am', 'and', 'spoke', 'w', '/', 'rn', 'and', 'md', ';', 'updated', 'on', ',', 'pt', \"'\", 's', 'condition', '.', 'plan', ':', 'follow', 'na', 'closely', ',', '?', 'continue', 'f', '##w', '##bs', 'and', 'd', '##5', '##w', ';', 'advance', 't', '##fs', 'as', 'tolerated', ';', 'follow', 'temps', 'and', 'c', '##x', 'data', ';', 'speech', '/', 'swallow', 'study', ';', 'routine', 'ic', '##u', 'care', 'and', 'monitoring', '.']\n","chunk 51 tokenize start!\n","First sentence tokenized\n","['ne', '##uro', '-', 'ex', '##tre', '##ml', '##y', 'anxious', 'regarding', 'hr', '/', 'bp', '&', 'interventions', 'done', 'with', 'no', 'effect', '.', 'prof', '##use', 'sweating', 'from', 'head', 'only', '.', 'md', '-', 'anxiety', 'med', 'x', '##1', 'then', 'agreed', 'to', '1', '##mg', 'iv', '##p', 'at', '##iva', '##n', 'when', 'requested', 'by', 'pt', '.', 'no', 'ne', '##uro', 'deficit', '##s', 'seen', '.', 'cv', '-', 'continued', 'in', 'afi', '##b', 'at', '128', '-', '140', 'with', 'h', '##t', '##n', '.', '10', '##mg', 'iv', '##p', 'and', '25', '##mg', 'po', 'lo', '##press', '##or', 'given', 'a', '/', 'o', 'with', 'no', 'effect', '.', 'remained', 'in', 'afi', '##b', '.', 're', '-', 'bo', '##lus', '##ed', 'with', '150', '##mg', 'ami', '##o', 'and', 'con', '##t', \"'\", 'd', 'gt', '##t', '@', '1', '##mg', '/', 'min', '.', 'r', '##ht', '##y', '##hm', 'broke', 'into', 'ns', '##r', '@', '01', '##00', 'and', 'stayed', 'in', 'ns', '##r', '.', 'pt', 'less', 'anxious', ',', 'hr', '/', 'bp', 'normal', '##izing', '.', 'generalized', 'ed', '##ema', '.', 'gi', '-', 'abd', '.', 'softly', 'di', '##st', '.', 'c', '/', 'o', 'nausea', 'x', '##2', '(', 'with', 'movement', ')', 'med', '.', 'with', '10', '##mg', 'iv', '##p', 'reg', '##lan', 'both', 'times', 'with', 'effect', '.', 'drinking', 'and', 'taking', 'po', 'med', '##s', 'without', 'difficulty', '.', 'gu', '-', 'ad', '##e', '##q', 'hourly', 'u', '/', 'o', '.', 'di', '##ures', '##ing', 'well', 'from', 'las', '##ix', '.', 'labs', '-', 'ca', '+', ',', 'mag', 'rep', '##lete', '##d', 'x', '##1', 'each', '.', 'pain', '-', 'tor', '##ado', '##l', '&', 'dil', '##aud', '##id', 'given', 'sep', '##era', '##tley', 'at', 'times', 'with', 'effect', '.', 'res', '##p', '-', '5', '##ln', '##c', '=', '97', '%', '.', 'we', '##ane', '##d', 'to', '2', '##ln', '##c', '.', 'de', '-', 'sat', '##s', 'to', '88', '%', 'on', 'ra', '.', 'audible', 'upper', 'air', '##way', 'ex', '##p', '.', 'w', '##hee', '##ze', '.', 'l', '##sc', ',', 'dim', 'at', 'bases', '.', 'strong', 'non', '-', 'productive', 'cough', '.', 'plan', '-', 'increase', 'diet', '/', 'activity', 'as', 'to', '##l', '.', 'o', '##ob', 'to', 'chair', '.', 'pain', 'med', 'q', '##4', '##h', '.', 'mont', '##ior', 'hr', '/', 'r', '##ht', '##hy', '##m', 'and', 'bp', '.']\n","chunk 52 tokenize start!\n","First sentence tokenized\n","['ct', '##ic', '##u', '/', 'mic', '##u', 'np', '##n', '7', '##pm', '-', '7', '##am', 'pt', '.', 'remains', 'in', 'ic', '##u', 's', '/', 'p', 'head', 'injury', 'from', 'falling', 'down', 'stairs', ',', 'stable', 'off', 'vent', ',', 'and', 'currently', 'being', 'monitored', 'for', 'res', '##p', '.', 'status', ',', 'and', 'on', 'insulin', 'gt', '##t', '.', 'ne', '##uro', ':', 'pt', '.', 'awake', 'all', 'night', 'long', '.', '2', '##mg', 'iv', 'hal', '##do', '##l', 'given', 'due', 'to', 'pt', '.', '\"', 'sq', '##ui', '##rmin', '##g', '\"', 'in', 'the', 'bed', '.', 'r', 'arm', 'restrained', 'due', 'to', 'pt', '.', 'with', 'pe', '##di', 'tube', 'for', 'feeding', 'and', 'an', 'ali', '##ne', 'in', 'the', 'r', 'wrist', ',', 'however', 'she', 'fr', '##e', '##q', '##eu', '##ntly', 'tries', 'to', 'bend', 'her', 'body', 'so', 'that', 'she', 'can', 'reach', 'her', 'tubes', '.', 'pt', '.', 'reed', '##uca', '##ted', 'on', 'why', 'her', 'hand', 'is', 'tied', ',', 'however', 'she', 'continues', 'to', 'try', 'to', 'reach', 'for', 'things', '.', 'pt', '.', 'states', 'that', 'she', 'is', 'tired', ',', 'but', 'has', 'not', 'slept', '.', 'res', '##p', ':', 'on', '40', '%', ',', 'cool', 'face', 'tent', '.', 'lungs', 'are', 'clear', '-', 'coarse', 'in', 'upper', 'lobes', 'and', 'decreased', 'with', 'crack', '##les', 'in', 'the', 'lower', 'lobes', '.', 'pt', '.', 'encouraged', 'to', 'cough', 'and', 'take', 'deep', 'breaths', 'frequently', '.', 'deep', 'su', '##ction', '##ed', 'the', 'back', 'of', 'her', 'throat', 'for', 'thick', ',', 'yellow', 'secret', '##ions', '.', 'pt', \"'\", 's', 'cough', 'is', 'weak', ',', 'but', 'she', 'is', 'attempting', 'to', 'bring', 'up', 'sec', '##re', '##ition', '##s', '.', 'sat', \"'\", 's', 'in', 'the', '90', \"'\", 's', '.', 'am', 'ab', '##g', '44', '/', '48', '/', 'cv', ':', 'bp', 'in', '##ital', '##ly', 'stable', ',', 'however', 'as', 'night', 'progressed', 'pt', \"'\", 's', 'sb', '##p', '>', '160', '-', 'doctor', 'aware', ',', 'in', '##ital', '##ly', '5', '##mg', 'iv', 'hydra', '##la', '##zine', 'given', 'and', 'bp', 'stab', '##ali', '##zed', 'x', '1', 'hour', ',', 'then', 'el', '##eb', '##ava', '##ted', 'again', 'with', 'sb', '##p', '>', 'doctor', 'made', 'aware', ',', 'and', 'pt', '.', 'given', '10', '##mg', 'iv', 'hydra', '##la', '##zine', 'and', 'sb', '##p', 'now', '140', '-', 'at', 'beginning', 'of', 'shift', 'hr', 'ns', '##r', ',', 'however', 'she', 'started', 'to', 'have', 'short', 'bursts', 'of', 'increasing', 'heart', 'rate', 'to', '120', \"'\", 's', '.', 'it', 'appeared', 'as', 'though', 'pt', '.', 'was', 'trying', 'to', 'convert', 'back', 'to', 'afi', '##b', '.', 'doctor', 'aware', ',', 'l', '##yte', '##s', 'sent', '.', 'ion', '##ized', 'ca', '12', 'and', 'pt', '.', 'was', 'rep', '##lete', '##d', 'with', '2a', '##mps', 'of', 'calcium', 'g', '##lu', '##cona', '##te', ',', 'and', 'k', '+', '2', 'and', 'pt', '.', 'given', '20', '##me', '##q', 'kc', '##l', 'iv', 'x', 'pt', '.', 'now', 'in', 'ns', '##r', ',', 'no', 'ec', '##top', '##y', 'noted', '.', 'remains', 'on', 'po', 'ami', '##od', '##oro', '##ne', '.', 'gi', ':', 'active', 'bow', '##el', 'sounds', ',', 'passing', 'gas', ',', 'and', 'soft', 'brown', 'stool', '.', 'on', 'impact', 'with', 'fiber', 'at', '60', '##cc', '/', 'hr', '.', 'gu', ':', 'pt', '.', 'void', '##ing', 'yellow', 'urine', 'via', 'foley', ',', 'on', 'las', '##ix', 'po', 'bid', '.', 'end', '##o', ':', 'remains', 'on', 'insulin', 'gt', '##t', 'ti', '##tra', '##ting', 'accordingly', 'to', 'blood', 'sugar', '.', 'currently', 'at', '3', '##u', '/', 'hr', '.', 'see', 'care', '##vu', '##e', 'for', 'q', '##1', 'hour', 'finger', 'stick', 'results', 'and', 'ti', '##tra', '##tion', '.', 'l', '##yte', '##s', ':', 'ion', '##in', '##zed', 'ca', 'rep', '##lete', '##d', 'at', 'beginning', 'of', 'shift', 'and', 'now', 'w', '##nl', ',', 'k', 'rep', '##lete', '##d', 'and', 'now', 'id', ':', 'low', 'grade', 'te', '##mp', 'that', 'resolved', 'on', 'own', ',', 'wb', '##c', 'this', 'am', 'plan', ':', 'maintain', 'tight', 'control', 'over', 'blood', 'sugar', '(', 'per', 'report', 'pt', '.', 'is', 'very', 'sensitive', ')', ',', 'monitor', 'res', '##p', '.', 'status', 'and', 'ne', '##uro', 'status', '.', 'rep', '##lete', 'electro', '##ly', '##tes', 'as', 'needed', '.', 'pt', '.', 'remains', 'in', 'ic', '##u', ',', 'full', 'code', '.', 'see', 'care', '##vu', '##e', 'for', 'further', 'data', '.']\n","chunk 53 tokenize start!\n","First sentence tokenized\n","['sin', '##us', 'rhythm', '.', 'normal', 'ec', '##g', '.', 'no', 'previous', 'tracing', 'available', 'for', 'comparison', '.']\n","chunk 54 tokenize start!\n","First sentence tokenized\n","['np', '##n', '7', '##p', '-', '7', '##a', '(', 'see', 'also', 'care', '##vu', '##e', 'flow', '##ote', '##s', 'for', 'objective', 'data', ')', 'd', '##x', ':', 's', '/', 'p', 'new', 'tr', '##ach', ',', 'for', 'air', '##way', 'protection', 're', 'meta', '##static', 'neck', 'mass', 'ne', '##uro', ':', 'pt', 'a', '/', 'o', 'x', '##3', ';', 'com', '##mun', '##icative', ',', 'alert', ';', 'able', 'to', 'speak', 'few', 'words', 'with', 'using', 'finger', 'to', 'cover', 'tr', '##ach', 'opening', ';', 'moves', 'all', 'ex', '##tre', '##mit', '##ies', 'w', '/', 'out', 'issue', ';', 'c', '-', 'v', ':', 'vs', '##s', ';', 'iv', 'to', 'kv', '##o', ';', 'ns', 'to', 'sb', 'overnight', 'via', 'cardiac', 'monitoring', ',', 'no', 'ec', '##top', '##y', 'res', '##p', ':', 'mist', 'mask', 'at', '35', ',', 'with', 'o', '##2', 'sat', '##s', '99', '-', '100', '%', ';', 'able', 'to', 'cough', 'up', 'air', '##way', 'sec', '##rti', '##ons', ';', 'declined', 'su', '##ction', '##ing', 'by', 'nurse', ';', 'occasionally', 'needs', 'tr', '##ach', 'mist', 'mask', 'opening', 'cleared', '/', 'cleaned', 'of', 'coughed', 'up', 'sp', '##ut', '##um', '/', 'secret', '##ions', ';', 'lung', 'sounds', 'coarse', 'bi', '##lat', ';', 'i', '.', 'd', '.', ':', 'af', '##eb', '##ril', '##e', ';', 'started', 'on', 'iv', 'an', '##ce', '##f', '1', 'gm', 'q', '##8', 'hr', '##s', 'last', 'eve', ',', 'apparently', 'prop', '##hyl', '##actic', '##ally', ';', 'unable', 'to', 'find', 'note', 'in', 'chart', 'regarding', ',', 'however', 'md', 'resident', 'confirmed', 'order', ';', 'skin', ':', 'complained', 'of', 'sore', '##ness', 'from', 'sitting', 'for', 'so', 'long', ',', 'pt', 'small', 'and', 'thin', ';', 'chair', 'cushion', 'ordered', 'for', 'pt', 'and', 'obtained', 'from', 'di', '##st', '##ru', '##bution', '/', 'cs', ';', 'patent', 'left', 'a', '.', 'c', '.', 'sl', ',', 'being', 'used', 'for', 'intermittent', 'iv', 'ab', '##x', 'at', 'this', 'time', ';', 'g', '-', 'i', ':', 'remains', 'w', '/', 'out', 'food', 'intake', ';', 'sp', '&', 'sw', 'study', 'completed', '##re', '##com', '##men', '##dation', 'was', 'that', 'pt', \"'\", 's', 'diet', 'could', 'be', 'advanced', 'as', 'tolerated', ',', 'starting', 'w', '/', 'liquids', ';', 'given', 'apple', 'juice', 'x', '##1', 'overnight', ',', 'pt', 'tolerated', 'small', 'am', '##t', 'well', ';', 'g', '-', 'u', ':', 'void', '##ing', 'via', 'room', 'com', '##mo', '##de', ',', 'q', '##s', ',', 'w', '/', 'assist', 'd', '/', 't', 'ek', '##g', 'lines', ',', 'tr', '##ach', 'mask', 'tub', '##ing', ',', 'etc', ';', 'social', ':', 'supportive', 'husband', ',', 'daughter', ',', 'friends', ';', 'plan', ':', '1', ')', 'en', '##t', 'team', 'to', 'discuss', 'potential', 'c', '/', 'o', 'status', '2', ')', 'per', 'manufacturer', '##e', \"'\", 's', 'instructions', ',', 'a', 'valve', 'should', 'only', 'be', 'replaced', '48', 'hr', '##s', 'after', 'initial', 'tr', '##ach', 'placement', '(', 're', 'p', '-', 'm', 'valve', ')', '3', ')', 'f', '/', 'u', 're', 'p', '-', 'm', 'valve', '4', ')', 'iv', 'an', '##ce', '##f', '5', ')', 'diet', 'to', 'clear', 'liquids', '6', ')', 'chair', 'cushion', 'when', 'in', 'chair', '7', ')', '?', 'cream', 'to', 'co', '##cc', '##yx', 'area', 'for', 'protection']\n","chunk 55 tokenize start!\n","First sentence tokenized\n","['chief', 'complaint', ':', 'st', '##rid', '##or', 'hp', '##i', ':', '53', 'yo', 'f', 'w', '/', 'pm', '##h', 'of', 'asthma', 'and', 'psycho', '##genic', 'la', '##ryn', '##ge', '##al', 'spa', '##sm', 's', '/', 'p', 'multiple', 'int', '##uba', '##tions', 'and', 'tr', '##ach', 'transferred', 'from', '4', 'psychiatric', 'in', '##patient', 'unit', 'after', 'code', 'blue', 'called', 'for', 'st', '##rid', '##or', 'and', 'air', '##way', 'compromise', '.', 'prior', 'to', 'the', 'code', 'blue', ',', 'patient', 'was', 'reporting', '30', 'min', '##s', 'of', 'coughing', ',', 'short', '##ness', 'of', 'breath', ',', 'and', 'difficulty', 'breathing', '.', 'she', 'felt', 'as', 'if', 'her', 'throat', 'was', 'swelling', 'and', 'closing', '.', '.', 'a', 'code', 'blue', 'was', 'called', 'when', 'she', 'was', 'witnessed', 'to', 'have', 'difficulty', 'speaking', 'and', 'inability', 'to', 'in', '##hale', 'for', 'a', 'minute', '.', 'during', 'the', 'code', ',', 'vital', 'signs', 'were', 'significant', 'for', 'a', 'hr', '120', ',', 'o', '##2', 'sat', '100', '%', 'and', 'rr', '24', ',', 'she', 'received', '2', 'race', '##mic', 'ep', '##i', 'ne', '##bu', '##lizer', '##s', '.', 'a', 'v', '##b', '##g', 'was', 'obtained', '30', '/', '58', '/', 'she', 'was', 'taken', 'directly', 'to', 'the', 'mic', '##u', 'where', 'she', 'was', 'started', 'on', 'he', '##lio', '##x', ',', 'received', '2', '##mg', 'iv', 'at', '##iva', '##n', 'and', 'repeat', 'ab', '##g', 'showed', '39', '/', '41', '/', '.', 'prior', 'to', 'transfer', 'while', 'on', '4', ',', 'she', 'had', 'an', 'event', 'of', 'presumed', 'pseudo', '##sei', '##zu', '##re', 'on', 'and', 'was', 'complaining', 'of', 'left', 'flank', 'pain', '.', 'on', 'the', 'medical', 'floor', ',', 'she', 'was', 'evaluated', 'for', 'overdose', 'of', '20', 'mo', '##tri', '##n', ',', '20', 'top', '##oma', '##x', ',', 'and', '6', 'k', '##lon', '##op', '##in', 'in', 'the', 'setting', 'of', 'getting', '\"', 'frustrated', '\"', 'and', 'complaints', 'of', 'dia', '##rr', '##hea', 'and', 'poor', 'po', 'intake', 'x', '1', 'year', '.', 'her', 'complaints', 'were', 'not', 'consistent', 'with', 'laboratory', 'data', 'and', 'felt', 'so', '##mat', '##ization', 'disorder', '.', 'when', 'she', 'was', 'refused', 'iv', 'fluids', 'due', 'lack', 'of', 'medical', 'necessity', ',', 'she', 'tied', 'a', 'telephone', 'cord', 'around', 'her', 'neck', '.', 'patient', 'admitted', 'from', ':', ',', 'psychiatry', 'in', '##pt', 'unit', 'history', 'obtained', 'from', 'medical', 'records', 'all', '##er', '##gies', ':', 'pen', '##ici', '##llins', 'unknown', ';', 'e', '-', 'my', '##cin', '(', 'oral', ')', '(', 'er', '##yt', '##hr', '##omy', '##cin', 'base', ')', 'unknown', ';', 'dil', '##ant', '##in', '(', 'oral', ')', '(', 'ph', '##en', '##yt', '##oin', 'sodium', 'extended', ')', 'unknown', ';', 'z', '##olo', '##ft', '(', 'oral', ')', '(', 'ser', '##tral', '##ine', 'hc', '##l', ')', 'unknown', ';', 'io', '##dine', ';', 'io', '##dine', 'containing', 'unknown', ';', 'per', '##co', '##ce', '##t', '(', 'oral', ')', '(', 'ox', '##y', '##co', '##don', '##e', 'hc', '##l', '/', 'ace', '##tam', '##ino', '##ph', '##en', ')', 'rash', ';', 'hal', '##do', '##l', '(', 'oral', ')', '(', 'halo', '##per', '##ido', '##l', ')', 'unknown', ';', 'lid', '##oca', '##ine', '(', 'an', '##est', ')', '(', 'mis', '##cel', '##l', '.', ')', 'unknown', ';', 'car', '##ba', '##ma', '##ze', '##pine', 'allergic', 'to', 'gen', 'sul', '##fo', '##nami', '##des', 'unknown', ';', 'novo', '##ca', '##in', '(', 'injection', ')', '(', 'pro', '##ca', '##ine', 'hc', '##l', ')', 'unknown', ';', 'te', '##tra', '##cy', '##cl', '##ines', 'unknown', ';', 'late', '##x', 'throat', 'swelling', 'last', 'dose', 'of', 'antibiotics', ':', 'in', '##fusion', '##s', ':', 'other', 'ic', '##u', 'medications', ':', 'lo', '##raz', '##ep', '##am', '(', 'at', '##iva', '##n', ')', '-', '08', ':', '02', 'pm', 'other', 'medications', ':', 'prior', 'to', 'transfer', 'to', 'mic', '##u', 'cl', '##ona', '##ze', '##pa', '##m', '5', '##mg', 'po', 'ti', '##d', 'ox', '##car', '##ba', '##ze', '##pine', '300', '##mg', 'po', 'bid', 'du', '##lo', '##x', '##eti', '##ne', '40', '##mg', 'po', 'daily', 'lo', '##raz', '##ep', '##am', '2', '##mg', 'po', 'q', '6', '##h', 'pr', '##n', 'agitation', 'ol', '##anza', '##pine', '5', '##mg', 'po', 'q', '##am', ';', '10', '##mg', 'po', 'bed', '##time', 'ol', '##anza', '##pine', '5', '##mg', 'po', 'q', '6', '##h', 'pr', '##n', 'agitation', 'fen', '##tan', '##yl', 'patch', '25', '##mc', '##g', '/', 'hr', 't', '##p', 'q', '72', '##h', '##f', 'ty', '##len', '##ol', '325', '-', '650', '##mg', 'po', 'pr', '##n', 'lid', '##oca', '##in', '5', '%', 'patch', 'daily', 'insulin', 'sc', 'sliding', 'scale', 'est', '##rogen', '##s', 'con', '##ju', '##gated', '1', '##gm', 'v', '##g', 'bed', '##time', 'met', '##oc', '##lo', '##pr', '##ami', '##de', '10', '##mg', 'po', 'ma', '##alo', '##x', 'pr', '##n', 'pain', 'with', 'eating', 'pan', '##top', '##raz', '##ole', '40', '##mg', 'po', 'daily', 'sim', '##eth', '##icon', '##e', '40', '-', '80', '##mg', 'po', 'qi', '##d', 'pr', '##n', 'flat', '##ule', '##nce', 'su', '##cr', '##al', '##fat', '##e', '1', 'gm', 'po', 'qi', '##d', 'before', 'meals', 'and', 'at', 'bed', '##time', 'gu', '##ai', '##fen', '##es', '##in', '5', '-', '10', '##ml', 'po', 'q', '##6', '##h', 'pr', '##n', 'cough', '.', 'at', 'home', ':', '(', 'per', 'patient', ')', 'pro', '-', 'air', 'in', '##hai', '##ler', 'e', '##ze', '##ti', '##mi', '##be', '10', 'mg', 'po', 'daily', 'pan', '##top', '##raz', '##ole', '40', 'mg', 'every', '12', 'hours', 'f', '##olic', 'acid', '1', 'mg', 'po', 'daily', 'du', '##lo', '##x', '##eti', '##ne', '40', 'mg', 'po', 'daily', 'sim', '##vas', '##tat', '##in', '20', 'mg', 'po', 'daily', 'cl', '##ona', '##ze', '##pa', '##m', '1', 'mg', 'po', 'every', 'twelve', 'hours', 'as', 'needed', 'for', 'anxiety', '.', 'im', '##it', '##re', '##x', 'oral', 'g', '##lu', '##cer', '##na', 'po', 'three', 'times', 'a', 'day', 'at', 'meal', 'times', '.', 'multi', '##vita', '##min', 'po', 'once', 'a', 'day', '.', '\\\\', '.', '(', 'per', 'pharmacy', ',', 'in', ',', 'ma', ')', ':', 'tri', '##le', '##pta', '##l', '300', 'mg', 'su', '##cr', '##al', '##fat', '##e', '1', 'gm', 'qi', '##d', 'before', 'meals', 'and', 'at', 'bed', '##time', 'prem', '##ari', '##n', 'cream', '1', 'gm', 'va', '##g', 'q', '##hs', 'vic', '##od', '##in', '5', '/', '500', 'q', '##6', '##h', 'pr', '##n', 'x', '5', 'days', '(', ')', 'k', '##lon', '##op', '##in', '5', 'mg', 'ti', '##d', 'cy', '##mba', '##lta', '40', 'mg', 'q', '##am', 'lyric', '##a', '75', 'mg', 'ti', '##d', 'ser', '##o', '##quel', '50', 'mg', 'q', '##hs', 'act', '##os', '30', 'mg', 'q', '##d', 'past', 'medical', 'history', ':', 'family', 'history', ':', 'social', 'history', ':', '-', 'seizures', ',', 'possibly', 'ps', '##y', '##co', '##genic', ',', 'most', 'in', 'setting', 'of', 'car', 'accident', '.', 'she', 'reports', 'being', 'off', 'seizure', 'medications', '-', 'd', '##m', 'ii', 'on', 'insulin', '-', 'asthma', '-', 'hyper', '##lip', '##ide', '##mia', '-', 'fi', '##bro', '##my', '##al', '##gia', '-', 'ins', '##om', '##nia', '-', '?', 's', '##jo', '##gren', '##s', 'syndrome', '-', 'depression', '-', 's', '/', 'p', 'mu', '##lt', 'ps', '##ych', 'hospital', '##izations', '-', 'anxiety', '-', 'border', '##line', 'personality', 'disorder', '-', 'right', 'knee', 'replacement', '-', 'psycho', '##genic', 'la', '##ryn', '##ge', '##al', 'spa', '##sm', 'requiring', 'tr', '##ache', '##ost', '##omy', 'x', '1', '-', 'ge', '##rd', '-', 's', '/', 'p', 'fund', '##up', '##lica', '##tion', '-', 'ob', '##st', '##ru', '##ctive', 'sleep', 'ap', '##nea', '-', 'on', 'bi', '##pa', '##p', '-', 'chronic', 'an', '##emia', '-', 's', '/', 'p', 'h', '##yst', '##ere', '##ct', '##omy', 'non', '-', 'contributor', '##y', 'occupation', ':', 'drugs', ':', 'tobacco', ':', 'alcohol', ':', 'other', ':', 'she', 'denies', 'et', '##oh', ',', 'tobacco', 'or', 'any', 'current', 'or', 'prior', 'illicit', 'drug', 'use', '.', 'she', 'lives', 'alone', 'and', 'has', 'never', 'been', 'married', ',', 'no', 'children', '.', 'review', 'of', 'systems', ':', '(', '+', ')', 'cough', ',', 'short', '##ness', 'of', 'breath', '(', '-', ')', 'denies', 'fever', ',', 'chill', '##s', ',', 'night', 'sweat', '##s', ',', 'recent', 'weight', 'loss', 'or', 'gain', '.', 'denies', 'headache', ',', 'sin', '##us', 'tenderness', ',', 'rhino', '##rr', '##hea', 'or', 'congestion', '.', 'denied', 'chest', 'pain', 'or', 'tight', '##ness', ',', 'pal', '##pit', '##ations', '.', 'denied', 'nausea', ',', 'vomiting', ',', 'dia', '##rr', '##hea', ',', 'con', '##sti', '##pati', '##on', 'or', 'abdominal', 'pain', '.', 'no', 'recent', 'change', 'in', 'bow', '##el', 'or', 'bladder', 'habits', '.', 'no', 'd', '##ys', '##uria', '.', 'denied', 'art', '##hra', '##l', '##gia', '##s', 'or', 'my', '##al', '##gia', '##s', '.', 'flows', '##hee', '##t', 'data', 'as', 'of', '10', ':', '47', 'pm', 'vital', 'signs', 'hem', '##od', '##yna', '##mic', 'monitoring', 'fluid', 'balance', '24', 'hours', 'since', '12', 'am', 't', '##max', ':', '9', 'c', '(', '4', 'tc', '##urrent', ':', '9', 'c', '(', '4', 'hr', ':', '124', '(', '108', '-', '124', ')', 'bp', '##m', 'bp', ':', '132', '/', '67', '(', '83', ')', '{', '116', '/', '36', '(', '63', ')', '-', '138', '/', '78', '(', '87', ')', '}', 'mm', '##hg', 'rr', ':', '22', '(', '19', '-', '27', ')', 'ins', '##p', '/', 'min', 'sp', '##o', '##2', ':', '96', '%', 'heart', 'rhythm', ':', 'st', '(', 'sin', '##us', 'ta', '##chy', '##card', '##ia', ')', 'total', 'in', ':', '230', 'ml', 'po', ':', 't', '##f', ':', 'iv', '##f', ':', '230', 'ml', 'blood', 'products', ':', 'total', 'out', ':', '0', 'ml', '0', 'ml', 'urine', ':', 'ng', ':', 'stool', ':', 'drains', ':', 'balance', ':', '0', 'ml', '230', 'ml', 'respiratory', 'sp', '##o', '##2', ':', '96', '%', 'ab', '##g', ':', '39', '/', '41', '/', '/', '26', '/', '0', 'physical', 'examination', 'general', ':', 'alert', ',', 'oriented', ',', 'in', 'respiratory', 'distress', 'hee', '##nt', ':', 'sc', '##ler', '##a', 'an', '##ic', '##ter', '##ic', ',', 'mmm', ',', 'oro', '##pha', '##ryn', '##x', 'clear', 'neck', ':', 'su', '##pp', '##le', ',', ',', 'no', 'lad', 'lungs', ':', 'st', '##rid', '##orus', ',', 'no', 'w', '##hee', '##zes', ',', 'ra', '##les', ',', 'ron', '##chi', ',', 'occasional', 'large', 'gasps', 'with', 'good', 'air', '##flow', ',', 'intermittent', 'dry', 'coughing', 'cv', ':', 'ta', '##chy', ',', 'reg', ',', 'rate', 'and', 'rhythm', ',', 'normal', 's', '##1', '+', 's', '##2', ',', 'no', 'murmurs', ',', 'rubs', ',', 'gallo', '##ps', 'abdomen', ':', 'soft', ',', 'non', '-', 'tender', ',', 'non', '-', 'di', '##sten', '##ded', ',', 'bow', '##el', 'sounds', 'present', ',', 'no', 'rebound', 'tenderness', 'or', 'guarding', ',', 'no', 'organ', '##ome', '##gal', '##y', 'ex', '##t', ':', 'warm', ',', 'well', 'per', '##fus', '##ed', ',', '2', '+', 'pulses', ',', 'no', 'club', '##bing', ',', 'cy', '##ano', '##sis', 'or', 'ed', '##ema', 'labs', '/', 'radio', '##logy', '150', 'k', '/', 'ul', '5', 'g', '/', 'dl', '234', 'mg', '/', 'dl', '6', 'mg', '/', 'dl', '10', 'mg', '/', 'dl', '26', 'me', '##q', '/', 'l', '103', 'me', '##q', '/', 'l', '8', 'me', '##q', '/', 'l', '140', 'me', '##q', '/', 'l', '3', '%', '5', 'k', '/', 'ul', '2', ':', '33', 'a', '##6', '/', '28', '/', '08', ':', '10', 'pm', '10', ':', '20', 'p', '##6', '/', '28', '/', '08', ':', '13', 'pm', '1', ':', '20', 'p', '11', ':', '50', 'p', '1', ':', '20', 'a', '7', ':', '20', 'p', '1', '/', '/', '11', '/', '00', '##6', '1', ':', '23', 'p', '1', ':', '20', 'p', '11', ':', '20', 'p', '4', ':', '20', 'p', 'wb', '##c', '5', 'hc', '##t', '3', 'pl', '##t', '150', 'cr', '6', 'tr', '##op', '##t', '<', '01', 'tc', '##0', '##2', '26', 'glucose', '234', 'other', 'labs', ':', 'pt', '/', 'pt', '##t', '/', 'in', '##r', ':', '1', '/', '7', '/', '9', ',', 'ck', '/', 'ck', '##mb', '/', 'tr', '##op', '##oni', '##n', '-', 't', ':', '139', '/', '4', '/', '<', '01', ',', 'alt', '/', 'as', '##t', ':', '64', '/', '42', ',', 'al', '##k', 'ph', '##os', '/', 't', 'bi', '##li', ':', '108', '/', '2', ',', 'amy', '##lase', '/', 'lip', '##ase', ':', '/', '75', ',', 'album', '##in', ':', '8', 'g', '/', 'dl', ',', 'ld', '##h', ':', '301', 'i', '##u', '/', 'l', ',', 'ca', '+', '+', ':', '9', 'mg', '/', 'dl', ',', 'mg', '+', '+', ':', '9', 'mg', '/', 'dl', ',', 'po', '##4', ':', '6', 'mg', '/', 'dl', 'imaging', ':', 'c', '##x', '##r', '-', 'poor', 'ins', '##pi', '##rator', '##y', 'effort', ',', 'no', 'airspace', 'disease', '-', 'read', 'pending', 'micro', '##biology', ':', 'none', 'assessment', 'and', 'plan', 'this', 'is', 'a', '53', 'yo', 'f', 'w', '/', 'd', '##m', ',', 'so', '##mat', '##ization', 'd', '/', 'o', ',', 'border', '##line', 'personality', 'd', '/', 'o', ',', 'asthma', ',', 'and', 'history', 'of', 'psycho', '##genic', 'la', '##ryn', '##ge', '##al', 'spa', '##sm', 's', '/', 'p', 'tr', '##ache', 'who', 'developed', 'st', '##rid', '##or', 'while', 'on', '4', 'for', 'recent', 'overdose', '.', '.', '#', 'st', '##rid', '##or', '-', 'differential', 'for', 'la', '##ryn', '##ge', '##al', 'spa', '##sm', 'allergic', 'r', '##x', '##n', 'w', '/', 'la', '##ryn', '##ge', '##al', 'ed', '##ema', 'vs', 'vocal', 'cord', 'dysfunction', 'vs', 'psycho', '##genic', 'spa', '##sm', 'vs', '.', 'tr', '##ache', '##oma', '##la', '##cia', 'vs', '.', 'asthma', 'flare', '.', 'stable', 'vital', 'signs', 'and', 'wax', '##ing', '/', 'nature', 'of', 'symptoms', 'most', 'likely', 'consistent', 'w', '/', 'psycho', '##genic', 'cause', 'or', 'vocal', 'cord', 'dysfunction', '.', 'did', 'start', 'z', '##yp', '##re', '##x', 'during', 'this', 'admission', '.', 'coughing', 'episodes', 'appeared', 'to', 'be', 'trigger', '.', 'improved', 'dramatically', 'with', 'he', '##lio', '##x', 'and', 'at', '##iva', '##n', '2', '##mg', 'iv', 'x', '-', 'continue', 'at', '##iva', '##n', 'pr', '##n', 'for', 'anxiety', 'component', '-', 'stop', 'he', '##lio', '##x', 'once', 'st', '##rid', '##or', 'resolve', '##s', '-', 'pr', '##n', 'race', '##mic', 'ep', '##i', 'if', 'deco', '##mp', '##ens', '##ates', '-', 'int', '##uba', '##tion', 'kit', 'and', 'emergency', 'tr', '##ach', 'kit', 'at', 'bedside', '-', 'continue', 'w', '/', 'ne', '##bs', 'pr', '##n', 'for', 'any', 'bro', '##nch', '##os', '##pas', '##m', 'component', '-', 'ti', '##tra', '##te', 'o', '##2', 'as', 'tolerated', '.', '#', 'overdose', '/', 'multiple', 'suicide', 'attempts', '-', 'original', 'reason', 'for', 'admit', 'to', 'hospital', ',', 'was', 'then', 'medical', '##ly', 'cleared', 'prior', 'to', 'in', '##pt', 'ps', '##ych', 'admit', '.', 'while', 'on', 'medicine', 'floor', 'had', 'event', 'of', 'tying', 'telephone', 'cord', 'around', 'her', 'neck', '.', '-', 'continue', 'suicide', 'precautions', '-', 'will', 'require', 'further', 'in', '##pt', 'ps', '##ych', 'treatment', 'once', 'medical', '##ly', 'stabilized', '-', 'continue', 'ps', '##ych', 'med', '##s', 'as', 'prior', 'to', 'transfer', '-', 'appreciate', 'ps', '##ych', 'rec', '##s', 'in', 'am', '.', '#', 'l', '##ft', 'elevation', '-', 'on', 'review', 'of', 'labs', 'dating', 'back', 'to', ',', 'has', 'intermittent', 'l', '##ft', 'elevation', '.', 'is', 'on', 'stat', '##in', 'at', 'baseline', '.', '-', 'continue', 'to', 'trend', '.', '#', 'an', '##emia', '-', 'baseline', 'around', '30', ',', 'just', 'below', 'baseline', 'on', 'transfer', '.', '-', 'continue', 'to', 'trend', 'daily', '.', '#', 'h', '/', 'o', 'seizures', '-', '?', 'of', 'ps', '##y', '##co', '##genic', 'seizures', '.', '-', 'continue', 'out', '##pt', 'regime', '##n', '.', '#', 'd', '##m', '-', 'home', 'act', '##os', 'and', 'met', '##form', '##in', 'were', 'held', 'during', 'her', 'recent', 'medical', 'in', '##pt', 'stay', 'because', 'she', 'was', 'not', 'eating', ',', 'insulin', 'sliding', 'scale', 'started', 'and', 'continued', 'on', '4', '-', 'continue', 'insulin', 'ss', 'overnight', '-', 'transition', 'to', 'act', '##os', ',', 'met', '##form', '##in', 'in', 'am', 'once', 'to', '##ler', '##ating', 'po', '.', '#', 'chronic', 'back', 'pain', '-', 'continue', 'lid', '##oca', '##ine', 'patch', '.', '#', 'fen', '-', 'no', 'iv', '##f', ',', 'rep', '##lete', 'electro', '##ly', '##tes', ',', 'np', '##o', 'until', 'am', '.', '#', 'prop', '##hyl', '##ax', '##is', '-', 'sub', '##cut', '##aneous', 'he', '##par', '##in', '.', '#', 'access', '-', 'peripheral', 'x', '##1', '.', '#', 'code', '-', 'full', '.', '#', 'communication', '-', 'patient', ',', ';', '.', '#', 'disposition', '-', 'pending', 'above', ',', 'likely', 'back', 'to', '4', 'ps', '##ych', 'unit', '.', 'ic', '##u', 'care', 'nutrition', ':', 'g', '##ly', '##ce', '##mic', 'control', ':', 'regular', 'insulin', 'sliding', 'scale', 'lines', ':', '20', 'gauge', '-', '08', ':', '45', 'pm', 'prop', '##hyl', '##ax', '##is', ':', 'd', '##v', '##t', ':', 'sq', 'u', '##f', 'he', '##par', '##in', 'stress', 'ul', '##cer', ':', 'pp', '##i', 'va', '##p', ':', 'comments', ':', 'communication', ':', 'comments', ':', 'code', 'status', ':', 'full', 'code', 'disposition', ':', 'ic', '##u']\n","chunk 56 tokenize start!\n","First sentence tokenized\n","['neon', '##ato', '##logy', 'attending', 'progress', 'note', ':', 'do', '##l', '#', '111', '40', '2', '/', '7', 'weeks', 'pm', '##a', 'remains', 'in', 'nc', ',', '100', '%', ',', '25', '-', '30', '##cc', ',', '(', 'increased', 'to', '75', '##cc', 'with', 'po', 'feeding', '##s', ')', '4', 'with', 'bottle', 'feeding', 'last', 'night', '.', '5', '/', '24', 'hours', '.', 'des', '##at', 'to', '57', '%', 'hr', '=', '150', '-', '170', \"'\", 's', ',', 'soft', 'murmur', 'w', '##t', '=', '325', '##5', '##g', '(', 'inc', '55', '##g', ')', ',', 't', '##f', '=', '140', '##cc', '/', 'kg', '/', 'd', 'e', '##20', 'void', '##ing', ',', 'no', 'stool', 'overnight', 'some', 'po', 'feeding', '##s', 'imp', '/', 'plan', ':', 'prem', '##ie', 'infant', 'with', 'cl', '##d', ',', 'ro', '##p', ',', 'respiratory', 'im', '##mat', '##urity', 'particularly', 'with', 'feeding', '##s', ',', 'learning', 'to', 'po', 'feed', 'monitor', 'respiratory', 'status', ',', 'we', '##an', 'oxygen', 'as', 'tolerated', 'monitor', 'for', 'spells', ',', 'consider', 'trying', 'a', 'different', 'nipple', 'bottle', 'monitor', 'weight', 'on', 'current', 'regime', '##n', 'op', '##ht', '##ho', 'exam', 'next', 'week', 'continue', 'rest', 'of', 'present', 'management']\n","chunk 57 tokenize start!\n","First sentence tokenized\n","['sin', '##us', 'rhythm', 'with', 'first', 'degree', 'a', '-', 'v', 'block', '.', 'no', 'diagnostic', 'change', 'compared', 'to', 'the', 'previous', 'tracing', 'of', '.', 'tracing', '#', '2']\n","chunk 58 tokenize start!\n","First sentence tokenized\n","['nursing', 'progress', 'note', '.', 'cv', ':', 'the', 'pt', 'is', '.', 'sin', '##us', 'brady', '##card', '##ia', 'o', '/', 'n', 'c', 'no', 'ec', '##top', '##y', '.', 'pt', 'denies', 'cp', '/', 'pal', '##pit', '##ations', '.', 'r', 'fe', '##m', 'cat', '##h', 'site', 'is', 'c', '/', 'd', '/', 'i', 'c', 'no', 'bleeding', 'o', '/', 'n', '.', 'good', 'dorsal', '##is', 'pe', '##dial', 'pulses', 'appreciated', 'in', 'feet', '/', 'poor', 'symmetric', 'posterior', 'ti', '##bial', '##is', 'pulses', 'noted', '.', 'pt', 'now', 'able', 'to', 'flex', 'r', '##le', 'since', 'mn', '.', 'am', 'cp', '##k', 'bumped', 'c', 'a', '299', 'value', ',', '22', ':', '0', 'cp', '##k', 'value', '=', 'am', 'hc', '##t', 'fairly', 'stable', 'c', 'a', 'lab', 'value', 'of', 'iv', 'ni', '##tro', '##gly', '##cer', '##ine', 'gt', '##t', 'we', '##ane', '##d', 'off', 'by', '24', ':', '00', 'c', 'the', 'introduction', 'of', 'po', 'an', '##it', '-', 'h', '##t', '##n', 'med', '##s', 'per', 'ho', '.', 'am', 'lo', '##press', '##or', 'dose', 'will', 'probably', 'need', 'to', 'be', 'held', '2nd', 'brady', '##card', '##ia', 'down', 'to', 'the', 'mid', '40', \"'\", 's', '.', 'blood', 'cl', '##ot', 'drawn', '/', 'sent', 'c', 'am', 'labs', 'to', 'bb', 'for', 'routine', 'type', '/', 'cross', '.', 'two', 'rue', \"'\", 's', 'pi', '##v', 'in', 'place', 'and', 'both', 'are', 'operational', '.', 'norm', '##og', '##ly', '##ce', '##mic', 'f', '##s', 'values', 'o', '/', 'n', '.', 'pt', 'will', 'need', 'a', 'repeat', 'echo', 'during', 'this', 'hospital', '##ization', '.', 'ms', ':', 'pt', 'c', '/', 'o', 'r', 'knee', 'art', '##hri', '##tic', 'pain', 'and', 'med', 'c', '2', '#', 'per', '##co', '##ce', '##t', 'tab', '##s', '@', '22', ':', '00', 'c', 'excellent', 'pain', 'cn', '##tl', 'noted', 'o', '/', 'n', 'and', 'pt', 'presently', 'denying', 'c', '/', 'o', 'pain', '.', 'pt', 'is', 'times', 'three', ',', 'mae', ',', 'follows', 'commands', '/', 'cooperative', '/', 'friendly', '.', 'res', '##p', ':', 'l', '##sc', '##ta', 'b', '/', 'l', 'c', 'decreased', 'bs', '@', 'bases', '(', 'r', 'more', 'diminished', 'than', 'l', ')', '.', '2', '##ln', '##co', '##2', 'in', 'place', 'c', 'sat', '##s', 'in', 'the', 'mid', '90', \"'\", 's', '.', 'no', 'cough', '/', 'd', '##ys', '##p', '##nea', '.', 'gu', ':', 'cr', 'stable', ',', 'bun', 'trend', '##ing', 'down', 'c', 'am', 'labs', '(', '7', '/', '22', 'respectively', ')', '.', 'urine', 'is', 'yellow', 'and', 'clear', '.', 'gi', ':', 'np', '##o', '.', 'taking', 'po', 'med', '##s', 'c', 'h', '##20', 's', 'di', '##ff', '.', 'family', ':', 'no', 'family', '/', 'friends', 'called', '/', 'visited', 'o', '/', 'n', '.', 'the', 'pt', 'is', 'a', 'full', 'code', '.', 'other', ':', 'please', 'see', 'care', '##vu', '##e', 'for', 'additional', 'pt', 'care', 'data', '/', 'comments', '.', 'un', '##iv', 'isolation', 'practices', 'in', 'place', '.']\n","chunk 59 tokenize start!\n","First sentence tokenized\n","['4', ':', '44', 'pm', 'ct', 'c', '-', 'spine', 'w', '/', 'o', 'contrast', ';', 'ct', 'reconstruction', 'clip', '#', 'reason', ':', 'r', '/', 'o', 'fx', 'medical', 'condition', ':', '80', '##m', 's', '/', 'p', 'fall', 'reason', 'for', 'this', 'examination', ':', 'r', '/', 'o', 'fx', 'no', 'contra', '##ind', '##ication', '##s', 'for', 'iv', 'contrast', 'wet', 'read', ':', 'd', '##f', '##d', '##k', '##q', 'sat', '6', ':', '34', 'pm', 'no', 'fracture', 'or', 'mala', '##li', '##gn', '##ment', ';', 'multi', '##lev', '##el', 'dj', '##d', 'final', 'report', 'history', ':', '80', '-', 'year', '-', 'old', 'man', 'who', 'was', 'lifting', 'a', 'mattress', 'and', 'fell', 'down', '14', 'stairs', '.', 'int', '##uba', '##ted', 'for', 'intra', '##cr', '##anial', 'hem', '##or', '##rh', '##age', '.', 'comparison', ':', 'no', 'previous', 'studies', '.', 'technique', ':', 'axial', 'non', '##con', '##tra', '##st', 'multi', '##de', '##tec', '##tor', 'ct', 'images', 'of', 'the', 'cervical', 'spine', 'were', 'obtained', 'from', 'posterior', 'f', '##ossa', 'to', 'upper', 't', 'sa', '##git', '##tal', 'and', 'corona', '##l', 'reconstruction', '##s', 'were', 'performed', '.', 'findings', ':', 'the', 'bones', 'appear', 'demi', '##ner', '##ali', '##zed', '.', 'no', 'fractures', 'are', 'identified', '.', 'alignment', 'is', 'normal', '.', 'multi', '##lev', '##el', 'de', '##gen', '##erative', 'changes', 'are', 'present', '.', 'there', 'is', 'inter', '##vert', '##eb', '##ral', 'disc', 'space', 'narrowing', 'at', 'c', '##5', '-', 'c', '##6', 'and', 'c', '##6', '-', 'c', 'the', 'outline', 'of', 'the', 'the', '##cal', 'sac', 'appears', 'un', '##rem', '##ark', '##able', '.', 'there', 'is', 'no', 'pre', '##vert', '##eb', '##ral', 'soft', 'tissue', 'swelling', '.', 'there', 'is', 'an', 'end', '##ot', '##rac', '##hea', '##l', 'tube', 'in', 'the', 'tr', '##ache', '##a', 'and', 'a', 'feeding', 'tube', 'in', 'the', 'es', '##op', '##ha', '##gus', '.', 'there', 'is', 'mu', '##cos', '##al', 'thick', '##ening', 'in', 'the', 'visual', '##ized', 'portion', 'of', 'the', 'sp', '##hen', '##oid', 'sin', '##us', '.', 'os', '##si', '##fication', 'is', 'seen', 'at', 'in', 'the', 'posterior', 'soft', '-', 'tissues', 'near', 'the', 'spin', '##ous', 'processes', 'of', 't', '##4', 'to', 't', '##7', 'which', 'could', 'be', 'due', 'to', 'previous', 'trauma', '.', 'impression', ':', '1', ')', 'no', 'fracture', 'or', 'mala', '##li', '##gn', '##ment', '.', '2', ')', 'multi', '##lev', '##el', 'de', '##gen', '##erative', 'changes', '.']\n","chunk 60 tokenize start!\n","First sentence tokenized\n","['respiratory', 'care', 'baby', 'continues', 'on', 'pro', '##ng', 'cp', '##ap', '5', 'with', '02', 're', '##q', '21', '-', '26', '%', 'this', 'shift', '.', 'bs', 'clear', '.', 'rr', 'mostly', '30', \"'\", 's', '-', '60', \"'\", 's', 'with', 'mild', 'baseline', 're', '##tra', '##ctions', '.', 'no', 'brady', '##s', 'noted', ',', 'o', '##cc', 'sat', 'drift', '##s', '.', 'on', 'caf', '##fe', '##ine', '.', 'will', 'con', '##t', 'cp', '##ap', ',', 'monitor', 'closely', '.']\n","chunk 61 tokenize start!\n","First sentence tokenized\n","['nursing', 'progress', 'note', '83', '##yo', 'women', 'with', 'h', '/', 'o', 'as', ',', 'h', '##t', '##n', ',', 'ch', '##f', 'and', 'cad', ',', 's', '/', 'p', 'av', '##r', 'cab', '##g', 'x', \"'\", 's', '1', 'on', 'course', 'complicated', 'by', 'respiratory', 'failure', 'and', 'episodes', 'of', 'pu', '##l', 'ed', '##ema', '.', 'e', '##f', '60', '%', 'by', 'echo', 'post', 'op', '.', 'c', '##x', '##r', 'bile', '##ral', 'pl', '##uer', '##al', 'e', '##ff', '##usions', 'l', '>', 'r', '.', 'pt', 'has', 'gone', 'out', 'to', 'the', 'floor', 'twice', 'and', 'returned', 'to', 'd', '/', 't', 'h', '##t', '##n', 'followed', 'by', 'pu', '##l', 'ed', '##ema', '.', 'o', ':', 'please', 'see', 'flow', 'sheet', 'for', 'objective', 'data', '.', 'sb', '##p', '100', \"'\", 's', '-', '120', \"'\", 's', 'since', 'arrival', 'via', 'l', 'radial', 'a', 'line', '.', 'iv', 'ni', '##tro', 'we', '##ane', '##d', 'off', 'prior', 'to', 'transfer', '.', 'lo', '##press', '##or', '^', 'to', '25', '##mg', 'ti', '##d', 'and', 'pt', 'to', 'be', 'started', 'on', 'ni', '##fed', '##ip', '##ine', 'xl', 'at', 'hs', '.', 'res', '##p', ':', 'lungs', 'dim', '##ins', '##hed', 'at', 'bases', 'otherwise', 'clear', '.', 'ct', \"'\", 's', 'intact', 'with', 'minimal', 'output', '.', 'ds', '##g', 'is', 'c', '&', 'd', '.', 'pt', 'encouraged', 'to', 'c', '&', 'db', 'and', 'use', 'incentive', 'sp', '##iro', '##metry', '.', 'o', '##2', 'at', '4', '##l', '.', 'o', '##2', 'sat', '##s', '96', '-', '99', '%', '.', 'ne', '##uro', ':', 'pt', 'is', 'alert', 'and', 'oriented', 'x', \"'\", 's', 'able', 'to', 'mae', '.', 'gu', '/', 'gi', ':', 'pt', 'to', '##ler', '##ating', 'sip', '##s', 'of', 'clear', 'liquids', '.', 'abd', 'is', 'soft', 'with', 'bow', '##el', 'sounds', '.', 'no', 'b', '##m', 'x', \"'\", 's', 'several', 'days', '.', 'foley', 'draining', 'cy', '##u', '.', 'pt', 'received', 'las', '##ix', '20', '##mg', 'today', 'with', 'unit', 'of', 'b', '##ld', '.', 'cr', '##ea', '##t', '^', 'social', ':', 'pt', 'lives', 'with', 'her', 'husband', 'and', 'has', '3', 'children', '.', 'a', '&', 'p', ':', '83', '##yo', 'women', 's', '/', 'p', 'av', '##r', 'with', 'rec', '##urrent', 'episodes', 'of', 'pu', '##l', 'ed', '##ema', 'in', 'setting', 'of', 'h', '##t', '##n', '.', 'ti', '##tra', '##te', 'med', '##s', 'as', 'tolerated', '.', 'ni', '##fed', '##ip', '##ine', 'started', 'today', '.', 'con', '##t', 'to', 'monitor', 'hem', '##od', '##yna', '##mics', '.', 'encourage', 'res', '##p', 'toilet', '.', 'monitor', 'i', '&', 'o', '.']\n","chunk 62 tokenize start!\n","First sentence tokenized\n","['respiratory', 'care', ':', 'patient', 'remains', 'on', 'a', '/', 'c', 'vent', '##ila', '##tory', 'support', 'with', 'only', 'a', 'decrease', 'from', '21', 'to', '18', 'for', 'the', 'rr', 'made', '.', 'morning', 'ab', '##g', 'results', 'determined', 'a', 'metabolic', 'al', '##kal', '##emia', 'with', 'good', 'oxygen', '##ation', 'on', 'the', 'current', 'settings', '(', 'see', 'care', '##vu', '##e', ')', '.', 'no', 'rs', '##bi', 'measured', 'per', 'physician', \"'\", 's', 'instructions', '.']\n","chunk 63 tokenize start!\n","First sentence tokenized\n","['pt', '.', 'remains', 'on', 'ac', 'ventilation', ',', 's', '##x', 'for', 'thick', 'tan', 'secret', '##ion', ',', 'rs', '##bi', '-', '8', ',', 'md', '##i', 'al', '##bu', '##terol', ',', 'at', '##rov', '##net', 'given', 'q', '##4', '##h', ',', 'bs', 'coarse', ',', 'ab', '##g', 'denotes', 'a', 'res', '##p', '.', 'acid', '##osis', ',', 'will', 'most', 'likely', 'remain', 'as', 'is', '.']\n","chunk 64 tokenize start!\n","First sentence tokenized\n","['respiratory', 'care', 'note', 'pt', 'remains', 'on', '+', '6', 'np', 'cp', '##ap', ',', 'fi', '##o', '##2', '25', '-', '27', '%', '.', 'bs', 'clear', '.', 'su', '##ction', '##ed', 'for', 'mod', 'amount', 'cloudy', 'secret', '##ions', '.', 'np', 'tube', 'changed', '.', 'l', '##ge', 'plug', '.', 'rr', '40', '-', '60', \"'\", 's', '.', 'on', 'caf', '##fe', '##ine', '.', 'no', 'brady', '##s', 'noted', 'this', 'shift', 'as', 'of', 'this', 'writing', '.']\n","chunk 65 tokenize start!\n","First sentence tokenized\n","['respiratory', 'care', ':', 'pt', '.', 'being', 'monitored', 'for', 'acute', 'respiratory', 'failure', 'and', 'possible', 'need', 'for', 'non', '-', 'invasive', 'mask', 'ventilation', '.', 'ab', '##g', \"'\", 's', 'to', 'this', 'point', ',', 'showing', 'adequate', 'oxygen', '##ation', 'with', 'a', 'fully', 'compensated', 'respiratory', 'ac', '##iso', '##sis', '.', 'b', '/', 's', 'dim', '##ins', '##hed', 'all', 'fields', 'with', 'course', 'crack', '##les', '~', '1', '/', '3', 'up', '.', 'pt', '.', 'r', '##x', 'with', '5', '##mg', 'al', '##bu', '##terol', 'and', '5', '##mg', 'at', '##rove', '##nt', 'via', 'sv', '##n', '~', 'q', '##4', 'hours', 'this', 'shift', '.', 'rr', 'remains', 'mid', '20', \"'\", 's', 'to', 'low', '30', \"'\", 's', ',', 'hr', 'high', '80', \"'\", 's', 'to', '90', \"'\", 's', '.', 'will', 'continue', 'to', 'monitor', 'and', 'apply', 'mask', 'ventilation', 'if', 'required', '.']\n","chunk 66 tokenize start!\n","First sentence tokenized\n","['nursing', 'progress', 'note', 'res', '##p', '/', 'cv', ':', 'remains', 'in', 'ra', 'with', 'no', 'a', '&', 'b', \"'\", 's', 'or', 'des', '##ats', 'noted', 'so', 'far', 'this', 'shift', '.', 'bs', 'cl', '&', '=', ',', 'no', 'audible', 'mu', '##rm', '##er', '.', 'vs', '##s', 'in', 'open', 'cr', '##ib', '.', 'fen', ':', 'weight', 'up', '75', '##gm', '##s', 'to', '221', '##5', '##gm', '##s', '.', 'approaching', 'birth', 'weight', '.', 'total', 'fluids', 'of', 'b', '##m', '/', 'sc', '##24', '##cal', 'maintained', 'at', '150', '##cc', '/', 'kg', '/', 'd', '.', 'sucking', 'vigorously', 'on', 'pac', '##ifier', '.', 'beginning', 'to', 'wake', 'for', 'feeds', '.', 'void', '##ing', 'and', ',', 'hem', '##e', '-', '.', 'no', 'em', '##esis', 'or', 'significant', 'residual', '##s', '.', 'social', ':', 'updated', 'mom', 'by', 'phone', '.', 'will', 'encourage', 'breast', 'feeding', 'since', 'infant', 'showing', 'interest', 'and', 'maturity', '.']\n","chunk 67 tokenize start!\n","First sentence tokenized\n","['np', '##n', '7', '##a', '-', '7', '##p', '#', '2', ':', 'con', '##ts', 'on', 'settings', 'of', '16', '/', '5', '##x', 'fi', '##o', '##2', '25', '-', '32', '%', '.', 'bs', 'are', 'clear', 'and', 'equal', 'with', 'mild', 'ic', '/', 'sc', '##r', '.', 'color', 'is', 'pink', 'and', 'well', 'per', '##fus', '##ed', '.', 's', '##x', \"'\", 'd', 'pr', '##n', 'for', 'w', '##ht', 'secret', '##ions', '.', 'has', 'occasional', 'drift', '##s', 'in', 'sat', '##s', ',', 'but', 'no', 'true', 'des', '##ats', 'or', 'brady', '##s', '.', 'on', 'caf', '##fi', '##ene', '.', 'a', ':', 'stable', 'on', 'current', 'settings', '.', 'p', ':', 'con', '##t', 'to', 'monitor', '.', '#', '3', ':', 'te', '##mp', 'stable', ',', 'sw', '##ad', '##dled', 'in', 'air', 'iso', '##lette', '.', 'font', '##ane', '##lles', 'are', 'soft', 'and', 'flat', '.', 'alert', 'and', 'active', 'with', 'cares', ',', 'sl', '##ee', '##ep', '##ing', 'well', '.', 'infant', 'brings', 'hands', 'to', 'face', '.', 'a', ':', 'ag', '##a', '.', 'p', ':', 'con', '##t', 'to', 'support', '.', '#', '4', ':', 'dad', 'in', 'the', 'am', ',', 'held', 'infant', 'for', 'about', '5', 'hr', '##s', '.', 'mom', 'in', 'later', 'with', 'aunt', 'and', 'sibling', '.', 'family', 'is', 'very', 'invested', 'and', '.', 'a', '/', 'p', ':', 'con', '##t', 'to', 'support', '.', '#', '5', ':', 't', '##f', '##13', '##0', '##cc', '/', 'kg', '/', 'd', '.', 'cal', '##s', 'increased', 'today', 'to', '24', ',', 'vi', '##t', 'e', 'fe', 'read', '##ded', '.', 'abd', '##ome', 'in', 'benign', ',', 'void', '##ing', 'and', 'stool', '##ing', '.', 'no', 'spit', '##s', ',', 'min', 'as', '##pi', '##rates', '.', 'a', ':', 'to', '##lea', '##rting', 'feeds', '.', 'p', ':', 'con', '##t', 'with', 'plan', 'as', 'tolerated', '.', '#', '10', ':', 'no', 'spells', 'at', 'this', 'point', 'in', 'shift', '.', '#', '11', ':', 'con', '##ts', 'on', 'men', '##op', '##ren', '##em', ',', 'gen', '##t', '-', 'day', '.', 'a', '/', 'p', ':', 'con', '##t', 'with', 'plan', '.', 'primary', 'pe', '##di', 'also', 'called', 'today', 'for', 'an', 'update', '.']\n","chunk 68 tokenize start!\n","First sentence tokenized\n","['nic', '##u', 'nursing', 'note', '7', '##p', '-', '7', '##a', '5', 'g', '&', 'd', 'res', '##p', '=', 'o', '/', 'remains', 'on', 'nc', '##o', '##2', ',', 'fi', '##o', '##2', '100', '%', ',', 'currently', 'on', '500', '##cc', 'flow', '.', 'baby', 'had', 'increase', 'drift', '##s', 'to', 'low', '90', \"'\", 's', 'high', '80', \"'\", 's', 'therefore', 'placed', 'on', 'high', 'flow', 'nc', '##o', '##2', '@', '750', '##cc', 'from', '200', '##cc', '.', 'we', '##ane', '##d', 'to', 'present', 'flow', 'rate', '.', 'bs', 'clear', '/', '=', ',', 'moderate', 'sc', 're', '##tra', '##ctions', '.', 'grunt', '##ing', 'with', 'cares', ',', 'minimal', 'at', 'rest', '.', 'oral', '##ly', 's', '##x', '##n', \"'\", 'd', 'small', 'clear', 'secret', '##ions', '.', 'no', 'brady', \"'\", 's', 'or', 'des', '##ats', '.', 'a', '/', 'stable', 'on', 'nc', '##o', 'p', '/', 'con', '##t', 'to', 'monitor', 'for', 'res', '##p', 'distress', '.', '2', 'fen', '=', 'o', '/', 'w', '##gt', '=', '335', '##0', '##g', '(', '-', '30', ')', '.', 'con', '##t', 'on', 't', '##f', '=', '60', '##cc', '/', 'kg', '/', 'd', 'of', 'd', '##10', '2', ':', '1', '##me', '##q', 'na', ':', 'k', 'via', 'l', '##hand', 'pi', '##v', ',', 'in', '##fus', '##ing', 'without', 'difficulty', '.', 'abd', 'soft', ',', '+', 'bow', '##el', 'sounds', '.', 'no', 'loops', '.', 'void', '##ing', ',', 'no', 'stool', 'thus', 'far', '.', 'd', '-', 'stick', '=', 'p', '/', 'np', '##o', 'until', 'stable', 'res', '##p', 'status', '.', 'id', '=', 'o', '/', 'con', '##t', 'on', '48', '##h', 'r', '/', 'o', 'amp', '##i', '/', 'gen', '##t', '.', 'no', 's', '/', 's', '##x', 'of', 'sep', '##sis', '.', 'p', '/', 'con', '##t', 'to', 'monitor', '.', 'parents', '=', 'o', '/', 'mom', 'visited', 'for', 'cares', ',', 'also', 'called', 'x', 'updated', 'on', 'condition', 'and', 'plan', 'by', 'this', 'rn', '.', 'a', '/', 'appropriate', 'and', 'loving', '.', 'p', '/', 'con', '##t', 'to', 'support', 'and', 'educate', '.', 'g', '&', 'd', '=', 'o', '/', 'te', '##mp', 'stable', 'sw', '##ad', '##dled', 'under', 'off', 'open', 'warmer', '.', 'alert', 'and', 'active', '.', 'mae', '##w', '.', 'af', '##of', '.', 'a', '/', 'ag', '##a', '.', 'p', '/', 'con', '##t', 'to', 'support', 'g', '&', 'd', 'needs', '.', 'revisions', 'to', 'pathway', ':', '5', 'g', '&', 'd', ';', 'added', 'start', 'date', ':']\n","chunk 69 tokenize start!\n","First sentence tokenized\n","['56', 'y', '.', 'o', '.', 'f', 's', '/', 'p', 'failed', 'kidney', 'transplant', 'on', 'pd', 'with', 'low', 'dose', 'im', '##mun', '##os', '##up', '##press', '##ion', 'presented', 'with', '3', 'days', 'of', 'worse', '##ning', 'dry', 'cough', 'associated', 'with', 'short', '##ness', 'of', 'breath', 'and', 'post', '-', 'tu', '##ssi', '##ve', 'n', '/', 'v', '.', 'last', 'night', 'she', 'missed', 'some', 'of', 'her', 'dial', '##ysis', 'because', 'of', 'weakness', 'and', 'sob', '.', 'today', 'she', 'presented', 'to', 'the', 'ed', 'for', 'headache', '.', 'of', 'note', ',', 'had', '2', 'weeks', 'of', 'sob', 'diagnosed', 'with', 'asthma', 'this', 'past', 'week', ',', 'seen', 'by', 'pu', '##lm', '##ono', '##logist', 'who', 'put', 'her', 'on', 'sy', '##mb', '##ico', '##rt', '.', '3', 'days', 'ago', 'developed', 'ha', ',', 'mig', '##raine', 'with', 'n', '/', 'v', '.', 'no', 'cp', 'but', 'cough', 'non', '##pro', '##ductive', '.', 'in', 'the', 'ed', ',', 'initial', 'vs', ':', 'vs', '4', '76', '247', '/', '116', '20', '98', '%', 'on', '2', '##l', '.', 'c', '##x', '##r', 'with', 'volume', 'over', '##load', ',', 'pu', '##lm', 'ed', '##ema', ',', 'll', '##l', 'consolidation', '.', 'she', 'was', 'given', 'lev', '##o', '/', 'van', '##c', '/', 'ce', '##ft', '##ria', '##xon', '##e', '.', 'did', 'not', 'draw', 'bc', '##x', '.', 'bp', '200', '/', '100', '##s', '.', 'started', 'on', 'ni', '##tro', '##pr', '##uss', '##ide', 'drip', '.', 'lab', '##eto', '##lo', '##l', '20', '##x', '##2', 'dropped', 'hr', '60s', '.', 'renal', 'will', 'do', 'per', '##ito', '##nea', '##l', 'dial', '##ysis', 'tonight', '.', 'on', 'cell', '##ce', '##pt', 'and', 'pre', '##d', '##nis', '##one', '.', 'given', 'dil', '##aud', '##id', 'for', 'headache', 'and', 'it', 'has', 'improved', '.', 'ek', '##g', 'w', '##nl', '.', 'ct', 'head', 'negative', '.', 'dial', '##ysis', 'fluid', 'cultures', 'sent', '.', 'she', 'was', 'then', 'transferred', 'to', 'mic', '##u', 'for', 'further', 'management', '.', 'di', '##sp', '##o', ':', 'full', 'code', 'all', '##er', '##gies', ':', 'as', '##pi', '##rin', ',', 'pt', 'was', 'told', ',', 'al', '##oe', ',', 'rash', ';', 'access', ':', '2', 'pi', '##v', 'renal', 'failure', ',', 'end', 'stage', '(', 'end', 'stage', 'renal', 'disease', ',', 'es', '##rd', ')', 'assessment', ':', 'es', '##rd', 'on', 'pd', 'since', '.', 'pt', 'unable', 'to', 'complete', 'exchange', 'at', 'home', 'feeling', 'un', '##well', '.', 'action', ':', 'pd', 'exchanged', 'with', '5', '%', 'dex', '##tro', '##se', '.', 'bun', ':', '87', ',', 'cr', '##ea', '##t', ':', 'blood', 'culture', 'sent', 'last', 'night', '.', 'ua', 'sent', 'o', '/', 'n', '.', 'response', ':', 'ongoing', '.', 'today', 'am', 'patient', 'denies', 'any', 'nausea', '.', 'plan', ':', 'plan', 'for', '5', 'pd', 'exchanges', 'over', '24', '##hr', '##s', 'with', '5', '%', 'dex', '##tro', '##se', '.', 'con', '##t', 'f', '/', 'u', 'with', 'renal', '.', 'hyper', '##tension', ',', 'mali', '##gnant', '(', 'hyper', '##tens', '##ive', 'crisis', ',', 'hyper', '##tens', '##ive', 'emergency', ')', 'assessment', ':', 'rec', 'd', 'pt', 'on', 'ni', '##pr', '##ide', 'gt', '##t', 'at', '1', 'mc', '##g', '/', 'kg', '/', 'min', ',', 'lab', '##eto', '##lo', '##l', '2', '##mg', '/', 'min', '.', 'sb', '##p', 'ranging', '140', '##s', '-', '160', 's', '.', 'hr', '58', '-', '70s', 'sr', '/', 'sb', 'with', 'no', 'ec', '##top', '##y', '.', 'denies', 'ha', '.', 'action', ':', 'able', 'to', 'ti', '##tra', '##te', 'ni', '##pr', '##ide', 'gt', '##t', 'to', 'off', 'since', 'pt', 'able', 'to', 'to', '##l', '.', 'po', 'medications', '-', 'on', 'lab', '##eto', '##lo', '##l', 'and', 'nor', '##vas', '##c', 'po', '.', 'able', 'to', 'ti', '##tra', '##te', 'lab', '##eto', '##lo', '##l', 'gt', '##t', 'off', 'since', 'pt', 'on', 'cl', '##oni', '##dine', 'patch', '.', 'rec', 'd', '5', '##mg', 'iv', '##p', 'at', '##iva', '##n', 'in', 'am', 'to', 'control', 'n', '/', 'v', 'and', 'tolerate', 'po', '##s', '.', 'response', ':', 'sb', '##p', 'ranging', '140', '##s', '-', '160', '##s', '.', 'off', 'lab', '##eto', '##lo', '##l', 'and', 'ni', '##pr', '##ide', 'gt', '##t', '.', 'pt', 'to', '##ler', '##ating', 'po', 'med', '##s', 'so', 'far', '.', 'plan', ':', 'con', '##t', '.', 'to', 'encourage', 'po', '##s', ',', 'given', 'pr', '##n', 'at', '##iva', '##n', 'for', 'n', '/', 'v', '.', '.', 'goal', 'sb', '##p', ':', '150', '-', '160', 's', '.', 'f', '/', 'u', 'on', 'all', 'labs', '.']\n","chunk 70 tokenize start!\n","First sentence tokenized\n","['admission', 'note', 'b', '##g', 'is', 'estimated', '27', 'w', '##k', 'ga', '(', 'based', 'on', 'fe', '##mur', 'length', ')', ',', 'b', '##w', '82', '##6', 'gm', '.', 'infant', 'was', 'delivered', 'by', 'emergency', 'c', '/', 's', 'at', '09', '##43', 'today', 'due', 'to', 'severe', 'maternal', 'ec', '##lam', '##ps', '##ia', 'and', 'fetal', 'distress', '.', 'the', 'following', 'is', 'the', 'extent', 'of', 'mat', 'h', '##x', 'available', 'at', 'this', 'time', '.', '24', 'y', '##r', 'black', 'female', 'g', '##1', '(', '?', ')', 'p', 'is', 'at', 'least', '1', 'now', '.', 'mother', 'is', 'a', 'ne', '##g', '/', 'ab', 'ne', '##g', '.', 'mother', 'did', 'not', 'realize', 'that', 'she', 'was', 'pregnant', 'from', 'iv', '##f', '.', 'mother', 'presented', 'to', 'ed', 'with', 'c', '/', 'o', 'abd', 'pain', ',', 'n', '/', 'v', ',', 'va', '##g', 'd', '/', 'c', ',', 'and', 'fever', '.', 'abd', 'pain', 'apparently', 'had', 'increased', '.', 'in', ',', 'mother', 'had', 'bp', '200', '/', '135', 'and', 'had', 'seizure', '.', 'f', '##hr', 'was', '40', '##s', 'upon', 'initial', 'assessment', 'in', 'ed', '.', 'f', '##hr', 'decreased', 'to', '20s', 'just', 'prior', 'to', 'delivery', '.', 'there', 'was', 'no', 'apparent', 'am', '##nio', '##tic', 'fluid', 'around', 'fe', '##tus', 'on', 'ultrasound', '.', 'neon', '##atal', 'team', 'and', 'ob', 'team', 'emerge', '##ntly', 'ran', 'to', 'for', 'emergency', 'delivery', '.', 'neon', '##atal', 'preparation', 'and', 'team', 'were', 'complete', 'at', 'time', 'of', 'delivery', '.', 'infant', 'emerged', 'limp', ',', 'dusk', '##y', ',', 'extremely', 'premature', ',', 'no', 'res', '##pr', '.', 'initial', 'hr', '=', '0', ',', 'b', '##m', '##v', 'hr', '<', '20', ',', 'int', '##uba', '##tion', 'with', '5', 'et', '##t', 'hr', '>', 'no', 'other', 'res', '##us', '##cit', '##ation', 'other', 'than', 'et', '##t', '/', 'b', '##m', '##v', 'with', '100', '%', 'o', 'infant', 'pink', '##ed', 'quickly', '.', 'at', 'most', 'occasional', 'gasping', ',', 'some', 'movements', 'after', '5', 'min', '.', 'infant', 'required', 'pip', '28', '-', '50', 'to', 'hear', 'bs', '.', 'bs', '=', 'tight', 'bi', '##lat', '.', 'ap', '##gar', '##s', '1', ',', '4', ',', '5', 'at', '1', ',', '5', ',', 'and', '10', 'min', '.', 'infant', \"'\", 's', 'face', 'and', 'head', 'were', 'bruised', '.', 'infant', 'was', 'stabilized', 'and', 'transferred', 'by', 'ambulance', 'to', 'nic', '##u', 'on', '.', 'born', 'at', '09', '##43', ',', 'arrived', 'at', 'nic', '##u', 'surf', 'given', 'by', 'upon', 'admission', 'to', 'nic', '##u', ':', 't', '8', 'p', '##14', '##9', 'r', 'with', 'vent', '##ila', '##tor', '.', 'sp', '##o', '##2', '100', '%', 'on', 'fi', '##o', '##2', '100', '%', ',', 'fi', '##o', '##2', 'we', '##ane', '##d', 'to', 'ra', '.', 'sp', '##o', '##2', 'still', 'high', '90s', '.', 'bp', '43', '/', '16', '(', 'mean', '26', ')', ',', 'then', '40', '##s', '/', '30', '##s', '.', 'g', '##lu', 'infant', 'appeared', 'pink', ',', 'well', 'per', '##fus', '##ed', ',', 'spontaneous', 'movements', '.', 'hee', '##nt', ':', 'mold', '##ing', 'of', 'head', '.', 'br', '##uising', '.', 'eyes', 'closed', ',', 'ears', ',', 'nose', ',', 'mouth', 'w', '##nl', '.', 'neck', 'w', '##nl', '.', 'chest', ':', 'bs', '=', ',', 'easier', 'air', 'movement', 'after', 'surf', '(', '5', 'cc', '/', 'kg', ')', '.', 'cv', ':', 'nl', 'heart', 'sounds', ',', 'no', 'murmur', ',', 'well', 'per', '##fus', '##ed', '.', 'bp', 'w', '##nl', 'as', 'noted', '.', 'per', '##ip', '##h', 'pulses', 'pal', '##pa', '##ble', '.', 'abd', ':', 'soft', ',', 'non', '##dis', '##ten', '##ded', ',', 'no', 'masses', ',', 'no', 'h', '/', 's', 'mega', '##ly', '.', 'um', '##b', '3', 'vessels', '.', 'gu', ':', 'premature', 'female', '.', 'an', '##us', ':', 'patent', '.', 'back', 'w', '##nl', '.', 'skin', ':', 'br', '##uising', 'as', 'noted', 'above', '.', 'ne', '##uro', ':', 'depressed', 'initially', ',', 'became', 'active', 'within', '10', 'minutes', 'and', 'has', 'continued', 'to', 'have', 'sp', '##on', 'movements', 'intermittent', '##ly', 'in', 'afternoon', '.', 'c', '##x', '##r', ':', 'clear', 'lung', ',', 'et', '##t', 'bit', 'high', '.', 'uv', '##c', 'above', 'dia', '##ph', '##rag', '##m', 'in', 'ra', '(', 'pulled', 'back', ')', '.', 'et', '##t', 'and', 'uv', '##c', 'rep', '##osition', '##ed', '.', 'uv', '##c', 'placed', 'by', ',', 'using', 'sterile', 'technique', '.', 'ua', '##c', 'was', 'not', 'able', 'to', 'be', 'placed', 'by', 'p', '.', 'glass', 'or', ',', 'md', '.', 'will', 'continue', 'later', '.', '-']\n","chunk 71 tokenize start!\n","First sentence tokenized\n","['cc', '##u', 'nursing', 'note', '06', '##00', '-', 'pt', 'difficult', 'to', 'ar', '##ouse', '.', 'responsive', 'only', 'to', 'stern', '##al', 'rub', '.', 'ab', '##g', 'attempts', 'unsuccessful', '.', 'v', '##b', '##g', 'drawn', 'on', 'bi', '##pa', '##p', 'c', '5', '##l', 'o', 'ph', '30', ',', 'pv', '##co', '##2', '92', ',', 'pv', '##o', '##2', '40', ',', 'cal', '##c', 'co', '##2', 'pt', 'slowly', 'awakening', '-', 'to', 'com', '##ple', '##lty', 'alert', '/', 'responsive', 'by', 'pt', 'taken', 'off', 'bi', '##pa', '##p', 'and', 'put', 'on', '.', '75', 'face', 'tent', '.', 'v', '##b', '##g', 'to', 'be', 'drawn', 'between', '07', '##30', '-', '08', '##00', '##am', '.', 'continue', 'to', 'monitor', 'res', '##p', 'status', 'closely', '.']\n","chunk 72 tokenize start!\n","First sentence tokenized\n","['t', '/', 'sic', '##u', 'ns', '##g', 'progress', 'note', '07', '##00', '-', 'ne', '##uro', '-', 'alert', ',', 'oriented', ',', 'interactive', '.', 'no', 'issues', '.', 'c', '/', 'o', 'left', 'chest', 'aching', 'after', 'activities', 'today', '.', 'received', 'ty', '##len', '##ol', '650', '##mg', 'given', 'with', 'effect', '.', 'cv', '##s', '-', 'baseline', 'vs', \"'\", 's', 'see', 'care', '##view', 'flows', '##hee', '##t', '.', 'light', 'drop', 'in', 'map', 'to', '55', 'after', 'las', '##ix', 'today', 'when', 'asleep', '.', 'renal', '-', 'effective', 'response', 'to', 'am', 'las', '##ix', 'but', 'now', 'u', '/', 'o', 'border', '##line', 'and', 'i', '&', 'o', 'slightly', 'positive', 'for', 'the', 'day', '.', 'to', 'discuss', 'add', '##tion', '##al', 'options', 'for', 'di', '##ures', '##is', '.', 'res', '##p', '-', 'tr', '##ach', 'mask', 'x', '~', '5', '/', 'hr', '##s', 'well', '.', 'rr', '25', '-', '40', 'with', 'tidal', 'volumes', '280', '-', '360', '##cc', 'on', 'vent', '.', 'sat', '##s', '93', '-', 'secret', '##ions', ':', 'small', 'am', '##ts', 'ten', '##acious', 'yellow', 'decreased', 'breath', 'sounds', 'on', 'left', '.', 'ex', '##p', 'w', '##hee', '##zing', 'after', 'physical', 'activity', '.', 'persistent', 'air', 'leak', 'in', 'left', 'ct', '(', 'remains', 'on', 'water', 'seal', '.', ')', 'scan', '##t', 'ser', '##ous', 'drainage', '.', 'end', '##o', '-', 'no', 'issues', 'id', '-', 't', 'max', '8', 'van', '##co', 'and', 'ce', '##ft', '##azi', '##dine', 'con', '##t', 'gi', '-', 'res', '##pi', '##lor', 'tube', 'feeds', 'at', 'goal', '.', 'b', '##m', 'today', '.', 'some', 'po', 'diet', 'ing', '##ested', ',', 'but', 'no', 'appetite', 'and', 'c', '/', 'o', 'exhaustion', 'just', 'trying', 'to', 'consume', 'po', 'diet', '.', 'act', '##vity', '-', 'transferring', 'bed', 'to', 'ca', '##hir', 'and', 'reverse', 'with', 'minimal', 'ass', '##iss', '##tance', '.', 'becomes', 'ex', '##ert', '##ional', 'quickly', ',', 'but', 'has', 'determined', 'will', 'and', 'persist', '##s', '.', 'a', '/', 'p', '-', 'tr', '##ach', 'mask', 'slightly', 'longer', 'today', '.', 'con', '##t', 'with', 'current', 'care', 'plan', 'what', 'to', 'do', 'about', 'ct', 'air', 'leak', '?', '?']\n","chunk 73 tokenize start!\n","First sentence tokenized\n","['4', 'hyper', '##bil', '##ir', '##ub', '##ine', '##mia', 'revisions', 'to', 'pathway', ':', '4', 'hyper', '##bil', '##ir', '##ub', '##ine', '##mia', ';', 'added', 'start', 'date', ':']\n","chunk 74 tokenize start!\n","First sentence tokenized\n","['8', ':', '15', 'am', 'chest', '(', 'portable', 'ap', ')', 'clip', '#', 'reason', ':', 'respiratory', 'distress', 'admitting', 'diagnosis', ':', 'brain', 'tumor', '/', 'sd', '##a', 'medical', 'condition', ':', '80', 'year', 'old', 'man', 's', '/', 'p', 'cr', '##ani', '##oto', '##my', 'for', 'meta', '##static', 'tumor', ',', 'remained', 'int', '##uba', '##ted', '.', 'reason', 'for', 'this', 'examination', ':', 'respiratory', 'distress', 'final', 'report', 'indications', ':', 'respiratory', 'distress', '.', 'su', '##pine', 'portable', 'ap', 'chest', 'at', '8', ':', '33', ':', 'comparison', 'is', 'made', 'with', 'study', 'from', '1', ':', '21', 'a', '.', 'm', '.', '1', 'day', 'earlier', '.', 'the', 'end', '##ot', '##rac', '##hea', '##l', 'tube', 'remains', 'in', 'size', 'in', 'unchanged', 'position', 'in', 'the', 'superior', 'tr', '##ache', '##a', '.', 'ng', 'tube', 'tip', 'and', 'side', 'port', 'are', 'in', 'unchanged', 'location', 'with', 'the', 'side', 'port', 'at', 'or', 'still', 'above', 'the', 'ge', 'junction', '.', 'there', 'is', 'stable', 'moderate', 'card', '##iom', '##ega', '##ly', '.', 'the', 'moderate', 'left', 'pl', '##eur', '##al', 'e', '##ff', '##usion', 'likely', 'has', 'a', 'sub', '##pu', '##lm', '##onic', 'component', ',', 'and', 'may', 'be', 'slightly', 'larger', '.', 'there', 'is', 'left', 'lower', 'lobe', 'ate', '##le', '##cta', '##sis', '.', 'a', 'small', 'right', 'pl', '##eur', '##al', 'e', '##ff', '##usion', 'is', 'likely', 'unchanged', '.', 'mild', 'pulmonary', 'vascular', 'eng', '##org', '##ement', 'is', 'stable', '.']\n","chunk 75 tokenize start!\n","First sentence tokenized\n","['nursing', 'progress', 'note', '1', '-', 'res', '##p', '-', 'pt', 'remains', 'on', 'o', '##2', '##nc', '75', '##cc', ',', '100', '%', '.', 'bsc', '/', '=', ',', 'w', '/', 'o', '##cc', 'ua', '##c', '.', 'sat', '##s', '>', '93', '%', '.', 'prolonged', 'to', '82', '%', 'one', 'hour', 'into', 'car', 'seat', 'test', '-', 'pt', 'failing', 'test', 'at', '75', '##cc', 'flow', '.', '?', 'if', 'pt', 'needs', 'increased', 'o', '##2', '##in', 'car', 'seat', 'or', 'different', 'cars', '##ea', '##t', '?', '2', '-', 'fen', '-', 't', '##f', '=', '123', '##cc', '/', 'k', 'yesterday', 'of', 'b', '##m', 'pt', 'feeds', ',', 'ad', 'li', '##b', 'feeding', ',', 'no', 'spit', '##s', '.', 'abd', 'benign', '.', 'pt', 'void', '##ing', ',', '.', 'w', '##t', '=', '06', '##0', '(', '-', '5', ')', '3', '-', 'dev', '-', 'te', '##mp', 'stable', 'in', 'open', 'cr', '##ib', '.', 'pt', 'waking', 'for', 'feeds', '.', 'a', ';', 'le', '##rt', 'and', 'active', '.', 'failed', 'car', 'seat', 'test', 'for', 'prolonged', '4', '-', 'social', '-', 'mom', 'x', '##34', '-', 'updated', '.', 'aware', 'of', 'car', 'seat', 'test', '-', 'discussing', 'possible', 'options', 'w', '/', 'mom', '.', 'preparing', 'for', 'discharge', 'on', 'wed', '.']\n","chunk 76 tokenize start!\n","First sentence tokenized\n","['sin', '##us', 'rhythm', '.', 'diffuse', 'non', '-', 'diagnostic', 'rep', '##olar', '##ization', 'abnormalities', '.', 'compared', 'to', 'the', 'previous', 'tracing', 'of', 'multiple', 'abnormalities', 'as', 'previously', 'noted', 'persist', 'without', 'major', 'change', '.', 'tracing', '#', '1']\n","chunk 77 tokenize start!\n","First sentence tokenized\n","['altered', 'respiratory', 'status', 's', ':', '\"', 'how', 'am', 'i', 'doing', ',', 'i', 'feel', 'awful', '\"', 'o', ':', 'cardiac', ':', 'sr', 'without', 've', '##a', '.', 'k', '7', 'this', 'am']\n","chunk 78 tokenize start!\n","First sentence tokenized\n","['np', '##n', '7', '##p', '-', '7', '##a', 'res', '##p', ':', 'infant', 'remains', 'in', 'ra', '.', 'l', '##s', 'cl', '##r', '/', '=', '.', 'rr', '30', '-', '60', \"'\", 's', '.', 'pe', '##ct', '##is', '.', 'sub', '##cos', '##tal', 're', '##tra', '##ctions', 'noted', '.', 'con', '##ts', 'on', 'caf', '##fe', '##ine', '.', 'no', 'spells', 'or', 'des', '##ats', 'so', 'far', 'this', 'shift', '.', 'con', '##t', 'to', 'monitor', '.', 'fen', ':', 'w', '##t', '850', '##k', '##g', '(', '-', '45', '##gm', '##s', ')', '.', 'con', '##ts', 'on', 't', '##f', '100', '##cc', '/', 'kg', '.', 'iv', '##f', 'of', 'd', '##10', '##w', 'with', '2', ':', '1', 'in', '##fus', '##ing', 'at', '40', '##cc', '/', 'kg', 'via', 'pi', '##v', '.', 'enter', '##al', 'feeds', 'at', '60', '##cc', '/', 'kg', 'of', 'b', '##m', 'increasing', '10', '##cc', '/', 'kg', 'at', '01', '&', '13', 'as', 'ordered', '.', 'abd', 'soft', '.', 'active', 'bs', '.', 'l', '##g', 'me', '##c', 'stool', '.', 'void', '##ing', 'with', 'each', 'dia', '##per', 'change', '.', 'ag', '22', '##cm', '.', 'ds', '##tick', 'no', 'spit', '##s', 'minimal', 'as', '##pi', '##rates', '.', 'con', '##t', 'to', 'advance', 'feeds', 'as', 'to', '##l', '.', 'g', '&', 'd', ':', 'te', '##mp', 'in', 'ser', '##vo', 'iso', '##lette', '.', 'nest', '##ed', 'in', 'sheep', '##skin', 'with', 'bound', '##ries', 'in', 'place', '.', 'likes', 'pac', '##ifier', '.', 'sleeps', 'well', 'between', 'cares', '.', 'con', '##t', 'to', 'support', 'developmental', 'milestone', '##s', '.', 'parenting', ':', 'no', 'contact', 'from', 'so', 'far', 'this', 'shift', '.', 'bi', '##li', ':', 'infant', 'con', '##ts', 'under', 'double', 'photo', '##t', '##x', '.', 'eyes', 'covered', '.', 'bi', '##li', 'to', 'be', 'checked', '.']\n","chunk 79 tokenize start!\n","First sentence tokenized\n","['np', '##n', 'nights', 'alt', 'in', 'nutrition', 'r', '/', ':', 'full', 'volume', 'feeds', 'well', 'on', '150', '##cc', '/', 'k', '/', 'd', 'b', '##m', '##26', 'w', '/', 'neo', '##sure', ',', '37', '##cc', 'q', '##3', '##hr', '##s', '.', 'abd', 'exam', 'benign', '.', 'no', 'loops', ',', 'no', 'spit', '##s', '.', 'gi', '##rth', '27', ',', 'as', '##p', '.', '0', '-', '2', '##cc', '.', 'right', 'ing', '##uin', '##al', 'her', '##nia', 'small', 'and', 'soft', '.', 'void', '##ing', 'and', 'well', '.', 'stool', 'gui', '##ac', 'positive', ',', 'but', 'no', 'visible', 'blood', '.', 'no', 'anal', 'fis', '##sure', 'noted', '.', 'des', '##iti', '##n', 'applied', 'with', 'each', 'dia', '##per', 'change', '.', 'continued', 'to', 'feed', 'due', 'to', 'no', 'changes', 'in', 'abd', 'exam', '.', 'will', 'not', '##ify', 'md', 'in', 'the', 'morning', 'about', 'gui', '##ac', 'positive', 'stool', '.', 'w', '##gt', 'up', '50', 'to', 'tonight', '.', 'baby', 'examined', 'by', 'surgical', 'consult', 'tonight', 'for', 'repair', 'of', 'her', '##nia', '.', 'probable', 'o', '.', 'r', '.', 'date', 'friday', '.', 'd', '/', 's', 'tonight', 'bottled', 'full', 'feed', 'at', '9', '##pm', 'and', '12', '##am', '.', 'will', 'continue', 'to', 'offer', 'bottle', 'q', '##3', '##hr', '##s', 'if', 'baby', ',', 'but', 'if', 'appears', 'tired', 'will', 'ga', '##va', '##ge', 'feeding', '.', 'continue', 'current', 'feeding', 'plan', '.', 'gu', '##ai', '##c', 'all', 'stool', '.', 'assess', 'for', 'any', 'changes', 'in', 'abd', 'exam', '.', 'alt', 'in', 'growth', 'and', 'development', 'd', '/', ':', 'and', 'active', 'with', 'cares', '.', 'sleeps', 'well', 'bt', '##w', 'cares', '.', 'ir', '##rit', '##bal', '##e', 'at', 'times', 'but', 'calm', '##s', 'with', 'pac', '##ifer', '.', 'no', 'let', '##har', '##gy', '.', 'maintains', 'te', '##mp', 'in', 'open', 'cr', '##ib', ',', 'co', 'bed', '##ding', 'with', 'twin', 'sister', '.', 'hc', '##t', 'tonight', 'p', '##ku', 'sent', '.', 'continues', 'to', 'have', 'small', 'skin', 'tag', 'on', 'right', 'ear', '.', 'con', '##it', '##nu', '##e', 'developmental', 'cares', '.', 'alt', 'in', 'parenting', ':', 'called', 'once', 'during', 'the', 'evening', 'to', 'ask', 'if', 'surgical', 'consult', 'had', 'been', 'by', 'yet', '.', 'continue', 'to', 'support', 'and', 'update', '.']\n","chunk 80 tokenize start!\n","First sentence tokenized\n","['7', '##am', '-', '7', '##pm', 'ud', '##ap', '##te', 'ne', '##uro', '\"', ':', 'pt', 'alert', 'and', 'or', '##ie', '##ante', '##d', 'x', 'mae', 'and', 'able', 'to', 'follow', 'commands', 'cv', ':', 'pt', 'remains', 'ns', '##r', ',', 'no', 'ec', '##top', '##y', 'noted', '.', 'hr', '80', '-', '90', \"'\", 's', '.', 'sb', '##p', '100', '-', '130', \"'\", 's', '.', 'neo', 'gt', '##t', 'ti', '##tra', '##ted', 'to', 'keep', 'sb', '##p', '120', '-', '140', \"'\", 's', '(', 'bp', 'goal', ')', '.', 'neo', 'gt', '##t', 'currently', 'at', '25', 'mc', '##g', '/', 'kg', '/', 'min', '.', 'pt', 'o', '##ob', 'to', 'chi', '##ar', 'this', 'am', '-', '>', 'hem', '##od', '##yna', '##mic', '##ally', 'stable', '.', 'pt', 'into', 'work', 'with', 'the', 'patient', 'this', 'am', '-', '>', 'and', 'when', 'the', 'pt', 'stood', 'up', 'to', 'walk', 'sb', '##p', 'down', 'to', 'the', '70', \"'\", 's', '-', '>', 'pt', 'c', '/', 'o', '\"', 'do', '##zziness', '\"', 'and', 'became', 'dia', '##ph', '##ore', '##tic', '.', 'pt', 'placed', 'back', 'in', 'chair', 'and', 'feet', 'raised', ',', 'neo', 'gt', '##t', 'increased', '-', '>', 'sb', '##p', 'back', 'up', 'to', '>', '120', \"'\", 's', '.', 'pp', 'by', 'do', '##pp', '##ler', 'res', '##p', ':', 'l', '##s', 'clear', 'throughout', '.', 'pt', 'on', '1', 'l', 'nc', '-', '>', 'o', '##2', 'sat', '##s', '95', '-', '97', '%', '.', 'pt', 'placed', 'on', 'ra', 'this', 'am', '-', '>', 'o', '##2', 'sat', '##s', 'down', 'to', '90', '-', '91', '%', '-', '>', 'pt', 'placed', 'back', 'on', '1', 'l', 'nc', '.', 'pt', 'using', 'is', 'ct', 'dc', \"'\", 'd', 'this', 'am', 'gi', '/', 'gu', ':', 'pt', 'with', '+', 'bs', '.', '+', 'flat', '##us', '.', 'no', 'stool', '.', 'foley', 'dc', \"'\", 'd', 'at', '10', '##am', '.', 'pt', 'void', '##ing', 'clear', 'yellow', 'urine', 'in', 'ur', '##inal', 'end', '##o', ':', 'el', '##vate', '##d', 'bs', 'treated', 'with', 'ss', 'reg', 'insulin', 'plan', ':', 'we', '##an', 'neo', 'gt', '##t', 'as', 'tolerated', ',', 'keep', 'sb', '##p', '120', '-', '140', \"'\", 's', '.', 'pu', '##lm', 'to', '##lie', '##t', ',', 'pain', 'control']\n","chunk 81 tokenize start!\n","First sentence tokenized\n","['nursing', 'progress', 'note', '07', '##00', '-', '1900', 'hours', ':', '(', 'continued', ')', 'per', 'ne', '##uro', 'suggestion', '-', 'attempt', 'to', 'get', 'pt', 'up', 'to', 'therapeutic', 'level', 'of', 'anti', '-', 's', '##z', 'med', '##s', 'to', 'prevent', 'any', 'further', 'activity', '.', 'once', 'pt', 'there', '##ape', '##uti', '##c', '-', 'will', 'attempt', 'we', '##ani', '##ng', 'of', 'vent', 'and', 'we', '##ani', '##ng', 'of', 'se', '##dation', '.', 'con', '##t', 'current', 'med', 'regime', '##n', 'and', 'ic', '##u', 'care', '/', 'q', '1', 'hour', 'ne', '##uro', '##s', '.']\n","chunk 82 tokenize start!\n","First sentence tokenized\n","['8', ':', '29', 'am', 'chest', '(', 'portable', 'ap', ')', 'clip', '#', 'reason', ':', 'ch', '##f', 'vs', 'p', '##na', '.', '.', '.', 'please', 'sit', 'patient', 'up', 'medical', 'condition', ':', '60', 'year', 'old', 'man', 'with', 'ch', '##f', 'in', 'context', 'of', 'mi', 'now', 's', '/', 'p', 'cat', '##h', ',', 'and', 'with', 'ch', '##f', 'getting', 'di', '##ures', '##ed', 'reason', 'for', 'this', 'examination', ':', 'ch', '##f', 'vs', 'p', '##na', '.', '.', '.', 'please', 'sit', 'patient', 'up', 'final', 'report', 'chest', ',', 'single', 'view', ',', 'history', ':', 'ch', '##f', ',', 'getting', 'di', '##ures', '##ed', '.', 'reference', 'exam', '.', 'there', 'is', 'an', 'ap', 'upright', 'film', '.', 'again', 'seen', 'is', 'moderate', 'card', '##iom', '##ega', '##ly', 'with', 'hazy', 'ind', '##ist', '##in', '##ct', 'vascular', '##ity', 'and', 'patch', '##y', 'bilateral', 'lower', 'lobe', 'infiltrate', '##s', '.', 'the', 'overall', 'appearance', 'is', 'that', 'of', 'ch', '##f', '.', 'a', 'focal', 'underlying', 'infiltrate', 'cannot', 'be', 'excluded', '.', 'again', 'seen', 'are', 'multiple', 'dil', '##ated', 'loops', 'of', 'bow', '##el', 'up', 'to', '7', 'cm', ',', 'likely', 'representing', 'dil', '##ated', 'colon', 'consistent', 'with', 'an', 'ile', '##us', '.']\n","chunk 83 tokenize start!\n","First sentence tokenized\n","['2', ':', '13', 'pm', 'pic', '##c', 'line', 'pl', '##ac', '##ment', 'sc', '##h', 'clip', '#', 'reason', ':', 'please', 'eva', '##l', 'and', 'place', 'pic', '##c', 'admitting', 'diagnosis', ':', 'sep', '##sis', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', 'cp', '##t', 'codes', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', 'pic', '##c', 'w', '/', 'o', 'flu', '##or', 'gui', '##d', 'plc', '##t', '/', 'rep', '##lc', '##t', '/', 'remove', '*', '*', 'us', 'gui', '##d', 'for', 'va', '##s', '.', 'access', 'c1', '##75', '##1', 'cat', '##h', ',', '/', 'cent', '/', 'mid', '(', 'not', 'd', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', 'medical', 'condition', ':', '62', 'year', 'old', 'woman', 'with', 'ec', '##f', 'iv', 'cas', '##po', '##fu', '##ng', '##in', 'course', 'for', 'di', '##sse', '##minated', 'yeast', '.', 'reason', 'for', 'this', 'examination', ':', 'please', 'eva', '##l', 'and', 'place', 'pic', '##c', 'final', 'report', 'pic', '##c', 'line', 'placement', ':', 'indication', ':', 'infection', ',', 'needs', 'iv', 'access', 'for', 'anti', '##biotic', 'treatment', '.', 'details', 'of', 'the', 'procedure', 'were', 'explained', 'to', 'the', 'patient', '.', 'radio', '##logist', ':', 'doctor', 'was', 'performing', 'the', 'procedure', '.', 'technique', ':', 'using', 'sterile', 'technique', 'and', 'local', 'an', '##esthesia', ',', 'the', 'left', 'bra', '##chia', '##l', 'vein', 'was', 'localized', 'with', 'ultrasound', 'and', 'pun', '##cture', '##d', 'under', 'direct', 'ultrasound', 'guidance', 'using', 'a', 'micro', '##pu', '##nc', '##ture', 'set', '.', 'a', 'peel', '-', 'away', 'sheath', 'was', 'then', 'placed', 'over', 'the', 'wire', '.', 'ultrasound', 'images', 'were', 'obtained', 'before', 'and', 'immediately', 'after', 'obtaining', 'intra', '##ven', '##ous', 'access', '.', 'a', 'dual', '-', 'lu', '##men', 'pic', '##c', 'line', 'was', 'then', 'placed', 'through', 'the', 'sheath', 'over', 'the', 'wire', 'and', 'its', 'tip', 'positioned', 'in', 'the', 'sv', '##c', 'under', 'flu', '##oro', '##scopic', 'guidance', '.', 'position', 'of', 'the', 'cat', '##het', '##er', 'was', 'confirmed', 'by', 'chest', 'x', '-', 'ray', 'in', 'one', 'view', '.', 'the', 'guide', '##wire', 'and', 'peel', '-', 'away', 'sheath', 'were', 'then', 'removed', '.', 'the', 'cat', '##het', '##er', 'was', 'secured', 'to', 'the', 'skin', '.', 'the', 'patient', 'tolerated', 'the', 'procedure', 'reasonably', 'well', '.', 'there', 'were', 'no', 'immediate', 'complications', '.', 'impression', ':', 'un', '##com', '##pl', '##icated', 'ultrasound', 'and', 'flu', '##oro', '##scopic', '##ally', 'guided', 'dual', '-', 'lu', '##men', 'pic', '##c', 'line', 'placement', 'via', 'the', 'left', 'bra', '##chia', '##l', 've', '##nous', 'approach', 'with', 'the', 'tip', 'positioned', 'in', 'sv', '##c', '.']\n","chunk 84 tokenize start!\n","First sentence tokenized\n","['res', '##p', 'care', 'note', 'pt', '.', 'was', 'ex', '##tub', '##ated', 'today', 'and', 'placed', 'on', 'np', '##cp', '##ap', '6', ',', 'o', '##2', '.', 'a', '#', '5', 'tube', 'was', 'placed', 'in', 'l', 'na', '##re', 'without', 'incident', '.', 'pt', '.', 'to', '##l', '.', 'change', 'well', 'with', 'no', 'des', '##at', \"'\", 's', 'or', 'spells', 't', '/', 'o', 'shift', 'to', 'this', 'point', '.']\n","chunk 85 tokenize start!\n","First sentence tokenized\n","['7', ':', '21', 'am', 'chest', '(', 'portable', 'ap', ')', 'clip', '#', 'reason', ':', 'please', 'eva', '##l', 'for', 'interval', 'change', 'in', 'volume', 'over', '##load', 'admitting', 'diagnosis', ':', 'chest', 'pain', 'medical', 'condition', ':', '83', 'year', 'old', 'man', 's', '/', 'p', 'stem', '##i', 'with', 'ch', '##f', 'and', 'persistent', 'o', '##2', 'requirement', '.', 'reason', 'for', 'this', 'examination', ':', 'please', 'eva', '##l', 'for', 'interval', 'change', 'in', 'volume', 'over', '##load', 'final', 'report', 'examination', ':', 'chest', 'x', '-', 'ray', '.', 'indication', ':', 'volume', 'over', '##load', '.', 'comparison', ':', 'comparison', 'was', 'made', 'with', 'the', 'previous', 'study', 'from', '.', 'findings', ':', 'the', 'patient', 'is', 'status', 'post', 'stern', '##oto', '##my', '.', 'surgical', 'clips', 'are', 'seen', 'in', 'the', 'right', 'hi', '##lar', 'area', '.', 'note', 'is', 'made', 'of', 'a', 'right', 'pl', '##eur', '##al', 'e', '##ff', '##usion', '.', 'there', 'is', 'card', '##iom', '##ega', '##ly', 'noted', '.', 'note', 'is', 'also', 'made', 'of', 'left', 'pl', '##eur', '##al', 'e', '##ff', '##usion', '.', 'there', 'is', 'a', 'left', 'retro', '##card', '##iac', 'density', 'which', 'may', 'represent', 'ate', '##le', '##cta', '##sis', 'or', 'consolidation', '.', 'some', 'mild', 'persistent', 'pulmonary', 'ed', '##ema', 'is', 'also', 'noted', '.', 'impression', ':', 'left', 'retro', '##card', '##iac', 'density', 'which', 'may', 'represent', 'consolidation', 'or', 'ate', '##le', '##cta', '##sis', '.', 'pulmonary', 'ed', '##ema', 'with', 'bilateral', 'pl', '##eur', '##al', 'e', '##ff', '##usion', 'in', 'patient', 'status', 'post', 'stern', '##oto', '##my', '.']\n","chunk 86 tokenize start!\n","First sentence tokenized\n","['sm', '##ic', '##u', 'ns', '##g', 'progress', 'note', 'ne', '##uro', '-', 'no', 'change', '.', 'remains', 'un', '##res', '##pon', '##sive', 'without', 'spontaneous', 'movement', '.', 'cardiac', '-', 'vs', '##s', '.', 'con', '##t', 'on', 'd', '##5', '##w', 'at', '125', '/', 'hr', 'and', 'h', '##2', '##o', 'bo', '##lus', '##es', 'ng', '250', 'q', '##6', '##hr', '##s', 'to', 'tx', 'hyper', '##nat', '##rem', '##ia', '.', 'rec', '##ieving', 'intermittent', 'k', 'and', 'cal', 'replacements', '.', 'con', '##t', 'with', 'adequate', 'u', '##o', '.', 'res', '##p', '-', 'int', '##uba', '##ted', '/', 'vent', '##ed', 'on', 'ps', '##10', '5', '##pee', '##p', '40', '%', 'with', 'tv', '400', \"'\", 's', 'rr', '30', \"'\", 's', '.', 'sat', '##s', '96', '-', '98', '%', '.', 'su', '##ction', '##ed', 'for', 'sm', 'am', '##ts', 'brown', 'to', 'clear', 'secret', '##ions', 'somewhat', 'decreased', 'from', 'yesterday', '.', 'gi', '-', 'rec', '##ieving', 'tube', 'feeds', '(', 'f', '##s', 'critic', '##are', ')', 'increased', 'to', '30', '##cc', '/', 'hr', 'with', 'goal', '80', '##cc', '/', 'hr', '.', 'con', '##t', 'with', 'di', '##sten', '##ded', 'abdomen', 'h', '##yp', '##oa', '##ctive', 'bs', '.', 'passing', '100', '##cc', 'loose', 'stool', '.', 'con', '##t', 'on', 'insulin', 'gt', '##t', 'at', 'var', '##ing', 'rates', 'with', 'varying', 'f', '##s', '(', 'see', 'flow', 'sheet', ')', 'id', '-', 'af', '##eb', '##ril', '##e', 'without', 'change', 'in', 'antibiotics', '.', 'following', 'random', 'van', '##co', 'levels', 'and', 'dos', '##ing', 'as', 'needed', '.', 'plan', '-', 'con', '##t', 'to', 'follow', '.', '?', 'tr', '##ach', '/', 'peg', 'on', 'friday', '.', 'con', '##t', 'to', 'support', 'family', '.']\n","chunk 87 tokenize start!\n","First sentence tokenized\n","['8', ':', '12', 'pm', 'ct', 'head', 'w', '/', 'o', 'contrast', 'clip', '#', 'reason', ':', 'found', 'poorly', 'un', '##res', '##pon', '##sive', ',', 'facial', 'trauma', ',', 'recent', 'sd', '##h', 'dia', '##gno', '##s', 'medical', 'condition', ':', '50', 'year', 'old', 'man', 'with', '?', 's', '##z', 'disorder', 'reason', 'for', 'this', 'examination', ':', 'found', 'poorly', 'un', '##res', '##pon', '##sive', 'facial', 'trauma', 'recent', 'sd', '##h', 'diagnosed', 'pl', '##s', 'compare', 'with', 'previous', 'study', 'no', 'contra', '##ind', '##ication', '##s', 'for', 'iv', 'contrast', 'wet', 'read', ':', 'dew', '##d', '10', ':', '09', 'pm', 'increase', 'left', 'sub', '##dur', '##al', 'hem', '##ato', '##ma', 'with', 'new', 'mass', 'effect', 'and', 'e', '##ffa', '##ce', '##ment', '(', 'lateral', 'vent', ',', 'and', 'su', '##pr', '##ase', '##llar', 'cy', '##ster', '##n', ')', 'final', 'report', 'indication', ':', '50', 'year', 'old', 'man', 'with', 'question', 'of', 'seizure', 'disorder', 'and', 'recent', 'trauma', 'with', 'sub', '##dur', '##al', 'hem', '##ato', '##ma', '.', 'poorly', 'responsive', '/', 'un', '##res', '##pon', '##sive', '.', 'ct', 'of', 'the', 'head', 'without', 'contrast', ':', 'comparison', ':', 'ct', 'of', 'the', 'head', 'performed', '.', 'technique', ':', 'ct', 'of', 'the', 'head', 'without', 'contrast', '.', 'findings', ':', 'there', 'has', 'been', 'interval', 'increase', 'in', 'size', 'in', 'the', 'left', 'frontal', ',', 'par', '##ie', '##tal', ',', 'temporal', ',', 'sub', '##dur', '##al', 'hem', '##ato', '##ma', '.', 'there', 'is', 'new', 'left', 'to', 'right', 'mass', 'effect', 'with', 'associated', 'e', '##ffa', '##ce', '##ment', 'of', 'the', 'left', 'lateral', 'vent', '##ric', '##le', '.', 'there', 'is', 'e', '##ffa', '##ce', '##ment', 'of', 'the', 'su', '##pr', '##ase', '##llar', 'cis', '##tern', 'and', 'slight', 'interval', 'en', '##lar', '##gement', 'of', 'the', 'temporal', 'of', 'the', 'right', 'lateral', 'vent', '##ric', '##le', '.', 'the', 'prep', '##ont', '##ine', 'cis', '##tern', 'is', 'preserved', '.', 'no', 'intra', '##par', '##en', '##chy', '##mal', 'hem', '##or', '##rh', '##age', 'or', 'other', 'new', 'areas', 'of', 'hem', '##or', '##rh', '##age', 'are', 'identified', '.', 'there', 'is', 'preservation', 'of', 'the', '-', 'white', 'matter', 'differentiation', '.', 'the', 'visual', '##ized', 'parana', '##sal', 'sin', '##uses', 'demonstrate', 'poly', '##po', '##id', 'mu', '##cos', '##al', 'thick', '##ening', 'in', 'the', 'left', 'lateral', 'maxi', '##llary', 'sin', '##us', 'as', 'well', 'as', 'minimal', 'mu', '##cos', '##al', 'thick', '##ening', 'within', 'the', 'inferior', 'aspect', 'of', 'the', 'right', 'lateral', 'maxi', '##llary', 'sin', '##us', '.', 'the', 'mast', '##oid', 'air', 'cells', 'are', 'well', 'ae', '##rated', '.', 'impression', ':', 'interval', 'increase', 'in', 'size', 'in', 'the', 'left', 'frontal', ',', 'par', '##ie', '##tal', ',', 'temporal', 'sub', '##dur', '##al', 'hem', '##ato', '##ma', 'now', 'measuring', 'approximately', '3', 'cm', 'in', 'greatest', 'dimension', '.', 'there', 'is', 'new', 'left', 'to', 'right', 'mass', 'effect', 'with', 'e', '##ffa', '##ce', '##ment', 'of', 'the', 'su', '##pr', '##ase', '##lla', 'cis', '##tern', 'and', 'left', 'lateral', 'vent', '##ric', '##le', '.', 'the', 'findings', 'were', 'discussed', 'with', 'er', 'resident', 'at', 'time', 'of', 'study', '.']\n","chunk 88 tokenize start!\n","First sentence tokenized\n","['8', ':', '53', 'am', 'chest', '(', 'portable', 'ap', ')', ';', '-', '77', 'by', 'different', 'physician', '#', 'reason', ':', 'pleas', 'ee', '##val', 'et', '##t', 'placement', 'admitting', 'diagnosis', ':', 'pneumonia', 'medical', 'condition', ':', '48', 'year', 'old', 'man', 'with', 'et', '##t', 'rep', '##osition', '##ing', 'reason', 'for', 'this', 'examination', ':', 'pleas', 'ee', '##val', 'et', '##t', 'placement', 'provisional', 'findings', 'impression', '(', 'p', '##fi', ')', ':', 'lc', '##pc', 'tu', '##e', '12', ':', '18', 'pm', 'p', '##fi', ':', 'et', '##t', 'tip', 'is', '9', 'cm', 'above', 'the', 'car', '##ina', 'in', 'good', 'position', '.', 'bi', '##bas', '##ila', '##r', 'ate', '##le', '##cta', '##sis', 'improved', '.', 'no', 'e', '##ff', '##usion', '.', 'final', 'report', 'chest', 'portable', ',', 'ap', ':', 'reason', 'for', 'exam', ':', '48', '-', 'year', '-', 'old', 'man', 'with', 'et', 'tube', 'positioning', '.', 'please', 'evaluate', 'et', '##t', 'placement', '.', 'since', 'earlier', 'today', ',', 'the', 'et', '##t', 'tube', 'was', 'pulled', 'back', ',', 'now', '9', 'cm', 'above', 'the', 'car', '##ina', '.', 'the', 'nas', '##oga', '##st', '##ric', 'tube', 'passes', 'below', 'the', 'dia', '##ph', '##rag', '##m', '.', 'bi', '##bas', '##ila', '##r', 'ate', '##le', '##cta', '##sis', 'improved', ',', 'especially', 'on', 'the', 'left', '.', 'there', 'is', 'no', 'pl', '##eur', '##al', 'e', '##ff', '##usion', ',', 'but', 'note', 'that', 'the', 'lateral', 'left', 'cost', '##op', '##hre', '##nic', 'angle', 'was', 'excluded', '.', 'no', 'volume', 'over', '##load', '.']\n","chunk 89 tokenize start!\n","First sentence tokenized\n","['4', ':', '26', 'pm', 'chest', '(', 'portable', 'ap', ')', 'clip', '#', 'reason', ':', 'eva', '##l', 'for', 'p', '##nem', '##ome', '##dia', '##sti', '##num', 'admitting', 'diagnosis', ':', 'poly', '##chon', '##dr', '##itis', 'with', 'air', '##way', 'mani', '##sf', '##est', '##ation', '\\\\', 'stern', '##ato', '##my', 'card', '##io', '##pu', '##lm', '##ona', '##ry', ';', 'bypass', ';', 'anterior', 'tr', '##ache', '##al', 'splitting', ';', 'ste', '##nt', 'placement', ';', 'lap', '##aro', '##tom', '##y', '/', 'sd', '##a', 'medical', 'condition', ':', '64', 'year', 'old', 'woman', 'with', 'tr', '##ache', '##oma', '##la', '##cia', 's', '/', 'p', 'bro', '##nch', 'reason', 'for', 'this', 'examination', ':', 'eva', '##l', 'for', 'p', '##nem', '##ome', '##dia', '##sti', '##num', 'final', 'report', 'ap', 'portable', 'chest', '.', 'indication', ':', 'tr', '##ache', '##oma', '##la', '##cia', 'status', 'post', 'bro', '##nch', '##os', '##co', '##py', '.', 'evaluate', 'for', 'p', '##ne', '##um', '##ome', '##dia', '##sti', '##num', '.', 'comparison', 'is', 'made', 'to', 'the', 'prior', 'examination', 'of', '.', 'findings', ':', 'heart', 'size', 'and', 'pulmonary', 'va', '##scu', '##lat', '##ure', 'are', 'normal', '.', 'a', 'tr', '##ache', '##ost', '##omy', 'tube', 'is', 'seen', 'in', 'good', 'position', 'in', 'the', 'upper', 'tr', '##ache', '##a', '.', 'luce', '##ncy', 'is', 'seen', 'to', 'outline', 'the', 'ascending', 'ao', '##rti', '##c', 'con', '##tour', ',', 'but', 'this', 'is', 'similar', 'to', 'seen', 'on', 'previous', 'exams', '.', 'there', 'is', 'no', 'p', '##ne', '##um', '##otho', '##ra', '##x', 'or', 'pl', '##eur', '##al', 'e', '##ff', '##usions', '.', 'the', 'lungs', 'are', 'clear', '.', 'there', 'is', 'no', 'significant', 'change', 'from', 'previous', 'examination', '.', 'impression', ':', 'no', 'change', 'from', 'previous', 'exam', '.', 'no', 'definitive', 'evidence', 'for', 'p', '##ne', '##um', '##ome', '##dia', '##sti', '##num', '.', 'no', 'p', '##ne', '##um', '##otho', '##ra', '##x', '.']\n","chunk 90 tokenize start!\n","First sentence tokenized\n","['neon', '##ato', '##logy', 'np', 'note', 'pe', ':', 'small', 'infant', 'kangaroo', '##ing', 'with', 'dad', ',', ',', 'quiet', '.', 'pink', 'well', 'per', '##fus', '##ed', ',', 'on', 'pro', '##ng', 'cp', '##ap', ',', 'af', '##of', ',', 'eyes', 'clear', ',', 'na', '##res', 'ina', '##ct', ',', 'mmm', '##p', 'chest', 'is', 'clear', 'with', 'fair', 'exchange', ',', 'periodic', 'breathing', 'noted', '.', 'cv', ':', 'rr', '##r', ',', 'mo', 'murmur', ',', 'pulses', '+', '2', '=', 'abd', 'soft', ',', 'active', 'bs', 'ex', '##t', ':', ',', ',', 'w', '##w', '##p', 'ne', '##uro', ':', 'active', ',', 'responsive', ',', 'normal', 'tone', 'for', 'ga', 'ud', '##ated', 'at', 'bedside', ',', 'questions', 'encouraged', 'and', 'answered', '.']\n","chunk 91 tokenize start!\n","First sentence tokenized\n","['np', '##n', '07', '##00', '-', '1900', 'res', '##p', ':', 'infant', 'remains', 'in', 'ra', ',', 'sat', '##s', '>', '97', '%', '.', 'rr', '30', '-', '50', \"'\", 's', ',', 'lung', 'sounds', 'are', 'clear', '/', '=', 'with', 'mild', 'sub', '##cos', '##tal', 're', '##tra', '##ctions', '.', 'infant', 'has', 'had', 'no', 'spells', 'thus', 'far', 'this', 'shift', '.', 'p', ':', 'continue', 'to', 'monitor', 'respiratory', 'status', '.', 'fen', ':', 't', '##f', '150', '##cc', '/', 'kg', 'of', 'b', '##m', '##26', 'or', 'sc', '##26', 'with', 'prop', '##ass', '(', '51', 'cc', 'ga', '##va', '##ged', 'over', '2', '##hr', '##s', ')', '.', 'at', '8', '&', '12', 'infant', 'was', 'ga', '##va', '##ged', 'and', 'was', 'breast', '##fed', 'at', '16', ';', 'very', 'passive', ',', 'un', '##co', '##ord', '##inated', 'and', 'tired', 'easily', '.', 'infant', 'is', 'to', '##ler', '##ating', 'feeds', 'well', ';', 'abd', 'exam', 'benign', ',', 'no', 'spit', '##s', 'and', 'max', 'as', '##p', 'of', '2', '##cc', '.', 'infant', 'is', 'void', '##ing', 'q', '##s', 'and', 'stool', '##ing', 'hem', '##e', 'negative', ',', 'des', '##iti', '##n', 'is', 'being', 'applied', 'to', 'bottom', 'with', 'each', 'care', '.', 'infant', 'remains', 'on', 'fe', '##rin', '##sol', '.', 'p', ':', 'continue', 'to', 'support', 'nutritional', 'needs', '.', ':', 'came', 'in', 'for', '16', 'cares', 'and', 'were', 'updated', 'on', 'infant', \"'\", 's', 'condition', 'and', 'plan', 'of', 'care', '.', 'they', 'are', 'very', 'loving', 'who', 'are', 'ind', '##ep', '##end', '##ant', 'with', 'infant', \"'\", 's', 'cares', ',', 'asking', 'appropriate', 'questions', '.', 'they', 'plan', 'to', 'bring', 'in', 'bottles', 'tomorrow', '(', '/', 'soo', '##thi', '##e', ')', 'to', 'help', 'with', 'bot', '##tling', '.', 'p', ':', 'continue', 'to', 'update', 'and', 'support', '.', 'g', '/', 'd', ':', 'temps', 'remain', 'stable', 'co', '##bed', '##ding', 'sw', '##ad', '##dled', 'in', 'an', 'open', 'air', 'cr', '##ib', '.', 'infant', 'is', 'quietly', 'alert', 'during', 'cares', 'and', 'has', 'been', 'sleeping', 'very', 'well', 'in', '##bet', '##wee', '##n', ',', 'uses', 'pac', '##ifier', 'for', 'como', '##fort', '.', 'right', 'hydro', '##cel', '##e', 'remains', 'soft', 'and', 'pink', '.', 'p', ':', 'continue', 'to', 'support', 'growth', 'and', 'development', '.']\n","chunk 92 tokenize start!\n","First sentence tokenized\n","['at', '213', '##0', 'became', 'hyper', '##tens', '##ive', 'to', '180', '##s', ',', 'dr', 'notified', ',', 'hydra', '##la', '##zine', '5', 'mg', 'iv', 'ordered', 'and', 'given', ',', 'sb', '##p', 'dropped', 'to', '150', '##s', '.', 'at', '##iva', '##n', 'given', 'for', 'restless', '##ness', '.', 'then', 'noted', 'to', 'be', 'in', 'and', 'out', 'of', 'afi', '##b', ',', 'rate', '100', '-', '115', ',', 'rare', 'pv', '##cs', ',', 'then', 'consistently', 'in', 'afi', '##b', '.', 'doctor', 'notified', ',', 'ami', '##oda', '##rone', 'bo', '##lus', 'ordered', 'and', 'given', ',', 'mg', 'and', 'k', 'rep', '##lete', '##d', '.', 'remains', 'in', 'afi', '##b', '.']\n","chunk 93 tokenize start!\n","First sentence tokenized\n","['nursing', 'note', '7', '##a', '-', '7', '##p', 'ne', '##uro', '-', 'a', '+', 'ox', '##3', ',', 'cooperative', 'w', '/', 'care', '.', 'no', 'c', '/', 'o', 'sob', 'or', 'c', '-', 'pain', '.', 'cv', '-', 'sr', 'no', 've', '##a', ',', 'hr', '70s', '-', '80s', '.', 'n', '##b', '##ps', '84', '-', '>', '107', '/', '40', '##s', '-', '50', '##s', '(', 'baseline', ')', '.', 'dl', 'pic', '##c', 'ds', '##g', 'changed', ',', 'he', '##p', 'flushed', '.', 'res', '##p', '-', 'l', '##s', 'diminished', 'in', 'bases', ',', 'o', '##cc', 'ins', '##p', '/', 'ex', '##p', 'w', '##hee', '##zing', '.', 'sat', '##s', 'on', '2', '##l', 'nc', '94', '-', '98', '%', '.', 'con', '##ts', 'on', 'las', '##ix', 'gt', '##t', '@', '5', '##mg', '/', 'hr', ',', 'di', '##ures', '##ing', '>', '120', '##cc', '/', 'hr', '(', 'goal', ')', '.', 'gi', '/', 'gu', '-', 'obe', '##se', '+', 'bs', 'no', 'b', '##m', ',', 'appetite', 'good', '.', 'void', '##ing', 'q', '##s', 'cy', '##u', 'via', 'foley', '.', 'skin', '-', 'intact', ',', 'no', 'issues', '.', 'using', 'a', 'shuttle', 'bed', '@', 'bedside', '.', 'a', '/', 'p', '-', '56', '##yo', 'female', 'w', '/', 'ch', '##f', 'ex', '##ace', '##rba', '##tion', '.', 'tn', '##sf', 'to', 'cc', '##u', 'p', 'having', 'periods', 'of', 'so', '##m', '##nu', '##lence', 'on', '3', 'd', '/', 't', '?', 'las', '##ix', 'bo', '##lus', '##es', '-', '>', 'h', '##yp', '##ote', '##ns', '##ion', '.', 'con', '##t', 'las', '##ix', 'gt', '##t', ',', 'monitor', 'hem', '##od', '##yna', '##mics', '&', 'ms', '.', 'daughter', '@', 'bedside', ',', 'is', 'a', 'call', '-', 'out', 'when', 'bed', 'available', '.']\n","chunk 94 tokenize start!\n","First sentence tokenized\n","['sin', '##us', 'rhythm', 'border', '##line', 'first', 'degree', 'a', '-', 'v', 'delay', 'ant', '##eros', '##ept', '##al', 'my', '##oca', '##rdial', 'in', '##far', '##ct', ',', 'age', 'ind', '##eter', '##minate', '-', 'possibly', 'acute', 'clinical', 'correlation', 'is', 'suggested', 'since', 'previous', 'tracing', 'of', ',', 'lateral', 't', 'wave', 'amplitude', 'more', 'prominent']\n","chunk 95 tokenize start!\n","First sentence tokenized\n","['neon', '##ato', '##logy', '-', 'n', '##np', 'progress', 'note', 'infant', 'is', 'active', 'with', 'good', 'tone', '.', 'af', '##of', '.', 'she', 'is', 'pink', ',', 'well', 'per', '##fus', '##ed', ',', 'no', 'murmur', 'aus', '##cu', '##lta', '##ted', '.', 'she', 'is', 'comfortable', 'in', 'room', 'air', ',', 'breath', 'sounds', 'clear', 'and', 'equal', '.', 'she', 'is', 'to', '##ler', '##ating', 'enter', '##al', 'feeds', ',', 'abd', 'soft', ',', 'active', 'bow', '##el', 'sounds', '.', 'stable', 'te', '##mp', 'in', 'open', 'cr', '##ib', '.', 'please', 'refer', 'to', 'neon', '##ato', '##logy', 'attending', 'note', 'for', 'detailed', 'plan', '.']\n","chunk 96 tokenize start!\n","First sentence tokenized\n","['respiratory', 'care', 'pt', 'remains', 'int', '##uba', '##ted', 'and', 'mechanically', 'vent', '##ila', '##ted', ',', 'settings', 'changed', 'to', 'cp', '##ap', '/', 'ps', '##v', 'secondary', 'to', 'cm', '##o', '.', 'please', 'see', 'care', '##vu', '##e', 'flows', '##hee', '##t', 'for', 'specific', 'information', '.', 'plan', 'to', 'continue', 'with', 'mechanical', 'support', ',', '?', 'ex', '##tub', '##ation', 'if', 'pt', 'continues', 'to', 'tolerate', 'current', 'settings', '.']\n","chunk 97 tokenize start!\n","First sentence tokenized\n","['d', '##nr', '75', 'year', 'old', 'f', 'with', 'h', '/', 'o', 'rec', '##urrent', ',', 'drug', '-', 'resistant', 'ut', '##is', ',', 'es', '##rd', 'on', 'hd', ',', 'cad', ',', 'h', '##t', '##n', 'and', 'chronic', 'st', '##asi', '##s', 'der', '##mat', '##itis', '/', 'cell', '##uli', '##tis', 'admitted', 'from', 'an', 'os', '##h', 'with', 'altered', 'mental', 'status', ',', 'h', '##yp', '##oth', '##er', '##mia', 'and', 'presumed', 'sep', '##sis', '.', 'no', 'major', 'changes', 'over', '##no', '##c', ',', 'has', 'been', 'comfortable', 'on', 'cp', '##ap', '5', '/', '5', 'renal', 'failure', ',', 'chronic', '(', 'chronic', 'renal', 'failure', ',', 'cr', '##f', ',', 'chronic', 'kidney', 'disease', ')', 'assessment', ':', 'bun', '15', ',', 'cr', '##e', '2', 'in', 'pt', 'w', '/', 'es', '##rd', 'who', 'makes', 'small', 'am', '##ts', 'of', 'yellow', 'urine', 'notable', 'for', 'sediment', '.', 'action', ':', 'am', 'labs', 'drawn', 'response', ':', 'plan', ':', 'hd', 'today', '.', 'van', '##c', 'level', 'due', 'altered', 'mental', 'status', '(', 'not', 'del', '##iri', '##um', ')', 'assessment', ':', 'pt', 'on', '12', 'mc', '##g', '/', 'kg', 'prop', '##of', '##ol', ';', '+', 'gag', ',', '+', 'cough', 'but', 'frequent', 'ya', '##wn', '##ing', ',', 'not', 'tracking', ',', 'not', 'following', 'any', 'commands', ',', 'not', 'responding', 'to', 'threat', ',', 'pupils', 'equal', ',', 'round', 'and', 'non', '-', 'reactive', ',', 'minimal', 'movement', 'of', 'ex', '##tre', '##mit', '##ies', '.', 'pt', 'does', 'move', 'her', 'head', 'around', 'on', 'the', 'bed', ',', 'at', 'times', 'vigorously', '.', 'previous', 'ee', '##g', 'negative', 'action', ':', 'daily', 'wake', 'up', 'response', ':', 'hr', 'increased', 'from', '99', 'to', '120', ',', 'increased', 'moving', 'of', 'her', 'head', 'but', 'no', 'improvement', 'in', 'ne', '##uro', 'status', '.', 'restarted', 'prop', '##of', '##ol', 'at', '6', '##mc', '##g', '/', 'kg', 'but', 'remained', 'somewhat', 'agitated', '.', 'currently', 'at', '10', '##mc', '##g', '.', 'plan', ':', 'continue', 'to', 'check', 'ne', '##uro', 'status', ',', 'se', '##dation', 'off', 'as', 'to', '##l', '.', 'probable', 'tr', '##ach', '.']\n","chunk 98 tokenize start!\n","First sentence tokenized\n","['focus', 'update', 'note', 't', 'max', '2', '-', 'pt', 'alert', '-', 'opens', 'eyes', 'sp', '##ont', '##ae', '##ously', ',', 'mouth', '##ing', 'words', 'at', '##ho', '##ugh', 'not', 'answering', 'orientation', 'questions', ',', 'follows', 'commands', 'consistently', ',', 'pu', '##rp', '##os', '##ful', 'with', 'left', 'side', ',', 'right', 'sided', 'neglect', '-', 'some', 'movement', 'in', 'left', 'fingers', ',', 'pupils', 'une', '##qual', 'with', 'brisk', 'reaction', 'left', '5', 'mm', 'and', 'right', '2', '-', '3', 'mm', 'this', 'has', 'been', 'since', 'pt', 'initial', 'ne', '##uro', 'event', '.', 'pt', 'continues', 'on', 'triple', 'h', 'therapy', '(', 'hyper', '##vo', '##lem', '##ia', '/', 'hyper', '##tension', ',', '/', 'hem', '##od', '##il', '##ution', ')', '-', 'goal', 'sb', '##p', '140', '-', '160', 'maintained', 'with', 'neo', 'gt', '##t', ',', 'pt', 'ali', '##ne', 'dame', '##ned', 'at', 'times', 'ic', '##u', 'team', 'aware', 'may', 'ti', '##tra', '##te', 'gt', '##t', 'by', 'blood', 'pressure', 'cuff', 'q', '10', 'mini', '##tes', 'per', 'dr', '.', 'cr', '##ain', '##iec', '##tom', '##y', 'on', 'left', 'no', 'prolonged', 'turning', 'to', 'left', 'side', ',', 'pt', 'continues', 'to', 'require', 'left', 'soft', 'arm', 'restraint', 'secondary', 'to', 'pulling', 'at', 'tr', '##ache', '##ost', '##omy', 'goal', 'cv', '##p', '>', '8', '-', 'at', '1200', 'pt', 'cv', '##p', '4', 'and', 'urine', 'output', '15', '##cc', 'for', 'the', 'hour', '-', 'pt', 'given', '500', 'cc', 'ns', 'bo', '##lus', ',', 'pt', 'continues', 'on', 'album', '##in', 'q', '6', 'hours', 'and', 'has', 'started', 'on', '300', 'cc', 'tube', 'feeding', 'bo', '##lus', \"'\", 'qi', '##d', '.', 'minimal', 'residual', '##s', '5', '-', '30', '##cc', '.', 'bow', '##el', 'sounds', 'present', ',', 'last', 'b', '##m', 'on', 'night', 'shift', '.', 'urine', 'clear', 'and', 'amber', 'via', 'foley', 'cat', '##h', '.', 'plan', ':', 'awaiting', 'helmut', 'fitting', 'so', 'that', 'pt', 'may', 'get', 'o', '##ob', 'to', 'chair', ',', '?', 'rehab', 'screen', ',', 'speech', 'and', 'swallow', 'consult', 'for', 'pass', '##ey', 'muir', 'valve', 'needed', ',', 'continue', 'to', 'monitor', 'ne', '##uro', 'signs', 'q', '2', 'hours', ',', 'keep', 'cv', '##p', '>', '8', ',', 'keep', 'sb', '##p', '140', '-', '160', 'with', 'neo', 'gt', '##t']\n","chunk 99 tokenize start!\n","First sentence tokenized\n","['res', '##p', 'care', 'pt', 'remains', 'on', 'vent', '.', 'su', '##ction', '##ed', 'large', 'am', '##t', 'of', 'cop', '##ious', 'am', '##t', 'of', 'ten', '##acious', 'b', '##lo', '##d', '-', 'tinged', 'secret', '##ions', '.', 'md', '##is', 'given', '.', 'rr', 'settings', 'increased', 'to', 'bring', 'ph', 'to', 'normal', ',', 'following', 'ab', '##gs', 'w', '##nl', '.', 'will', 'continue', 'to', 'monitor', '.']\n","chunk 100 tokenize start!\n","First sentence tokenized\n","['t', '/', 'sic', '##u', 'nursing', 'progress', 'note', 's', ':', 'o', ':', 'review', 'of', 'systems', 'ne', '##uro', ':', 'has', 'continuous', 'ee', '##g', 'monitor', 'with', 'video', 'input', '.', 'continues', 'on', 'pen', '##to', '##bar', '##b', 'gt', '##t', 'at', '5', 'mg', '/', 'kg', '/', 'hr', '.', 'also', 'receiving', 'ph', '##eno', '##bar', '##b', '(', 'level', 'this', 'am', '47', ')', ',', 'dil', '##ant', '##in', '(', 'measured', 'level', '8', ',', 'corrected', '4', ')', ',', 'and', 'ke', '##pr', '##a', '.', 'ee', '##g', 'with', 'about', '1', 'burst', 'q', '10', 'seconds', '.', 'no', 'obvious', 'seizing', 'noted', '.', 'pt', 'with', 'weak', 'cough', ',', 'no', 'gag', ',', '+', 'corn', '##eal', '##s', '.', 'no', 'other', 'movement', 'noted', '.', 'cv', '##s', ':', 'heart', 'rate', '98', '-', '110', ',', 'bp', '100', '-', '130', '/', '50', '-', 'peripheral', 'pulses', 'pal', '##pa', '##ble', '.', 'cv', '##p', '##2', '-', '5', 'res', '##p', ':', 'remains', 'oral', '##ly', 'int', '##uba', '##ted', 'on', 'a', '/', 'c', '14', '##x', '600', '40', '%', 'with', '5', 'pee', '##p', '.', '136', '/', '43', '/', '43', '/', '32', '/', '+', 'coarse', 'breath', 'sounds', 'in', 'all', 'fields', '.', 'su', '##ction', '##ed', 'for', 'thick', 'yellow', 'secret', '##ions', '.', 'r', 'sided', 'chest', 'tube', 'sites', 'open', 'to', 'air', ',', 'l', 'chest', 'tube', 'site', 'covered', 'with', 'ds', '##d', '.', 'rs', '##bi', 'this', 'am', 'renal', ':', '+', '350', '##0', '##cc', 'yesterday', '.', 'weight', 'up', 'to', '7', 'today', '(', '75', ')', '.', '680', '##cc', 'urine', 'since', 'midnight', '.', 'l', '##yte', '##s', 'w', '##nl', '.', 'sodium', 'down', 'to', '141', 'this', 'am', '.', 'receiving', '250', 'free', 'water', 'q', '6', 'hours', 'per', 'og', '.', 'maintenance', 'fluids', 'dc', \"'\", 'd', 'as', 'tube', 'feeding', '##s', 'increased', '.', 'gi', ':', 'restarted', 'on', 'tube', 'feeds', '(', 'f', '##s', 'rep', '##lete', 'with', 'fiber', ')', '.', 'to', '##ler', '##ating', 'well', ',', 'able', 'to', 'progress', 'to', '60', '##cc', '/', 'hr', '(', 'goal', '80', '##cc', '/', 'hr', ')', '.', 'duc', '##olo', '##x', 'su', '##pp', 'given', 'and', 'pt', 'had', 'medium', 'semi', '##so', '##ft', 'bow', '##el', 'movement', '.', 'on', 'pep', '##ci', '##d', 'for', 'prop', '##hyl', '##ax', '##is', '.', 'hem', '##e', ':', 'hc', '##t', 'on', 'love', '##no', '##x', '.', 'cl', '##ot', 'sent', 'to', 'blood', 'bank', 'id', ':', 'continues', 'to', 'be', 'feb', '##ril', '##e', 'to', 'wb', '##c', 'remains', 'elevated', 'at', 'on', 'van', '##com', '##y', '##cin', 'and', 'z', '##os', '##yn', '.', 'van', '##co', 'trough', 'to', 'be', 'red', '##ra', '##wn', 'this', 'am', '.', 'on', 'contact', 'precautions', 'for', '+', 'mrs', '##a', 'sw', '##ab', '.', '+', 'cultures', 'ac', '##ino', '##to', '##ba', '##cter', 'in', 'leg', 'wound', 'sw', '##ab', 'and', 'sp', '##ut', '##um', '.', 'last', 'culture', '##d', '@', '5', '##am', '.', 'end', '##o', ':', 'ssr', '##i', ',', 'last', 'finger', 'stick', 'skin', ':', '4', 'fa', '##sc', '##iot', '##omy', 'leg', 'va', '##cs', 'removed', 'by', 'vascular', 'and', 'wet', 'to', 'dry', 'dressing', '##s', 'applied', 'and', 'wrapped', 'with', 'k', '##ling', '.', 'vascular', 'will', 'change', 'dressing', '##s', 'again', 'this', 'morning', 'and', 'then', 'will', 'be', 'changed', 'by', 'nursing', ',', 'wet', 'to', 'dry', '.', 'all', 'wounds', 'are', 'pink', 'with', 'ser', '##osa', '##ng', '##ino', '##us', 'drainage', '.', 'upper', 'leg', 'donor', 'sites', 'o', '##oz', '##ing', 'ser', '##ous', 'liquid', '.', 'lines', ':', 'l', 'radial', 'art', 'line', ',', 'l', 'sc', 'triple', 'lu', '##men', 'in', 'place', 'social', ':', 'wife', 'and', 'family', 'here', 'on', 'evenings', '.', 'when', 'i', 'spoke', 'with', 'wife', 'she', 'said', 'she', 'was', 'hopeful', '.', 'when', 'i', 'asked', 'her', 'what', 'she', 'was', 'hoping', 'for', 'she', 'responded', '\"', 'i', 'don', \"'\", 't', 'know', '\"', '.', 'a', ':', 's', '/', 'p', 'pe', '##d', 'hit', 'by', 'car', 'with', 'an', '##ox', '##ic', 'brain', 'injury', 'with', 'ongoing', 'fever', 'and', 'elevated', 'wb', '##c', 'and', 'seizures', '.', 'p', ';', 'follow', 'cultures', ',', 'rec', '##ult', '##ure', 'as', 'indicated', '.', 'rec', '##he', '##ck', 'van', '##co', 'trough', 'this', 'am', '.', 'advance', 'tube', 'feeding', 'to', 'goal', '.', 'continue', 'to', 'closely', 'monitor', 'pt', 'and', 'support', 'family', '.']\n","chunk 101 tokenize start!\n","First sentence tokenized\n","['7', ':', '14', 'am', 'chest', '(', 'portable', 'ap', ')', 'clip', '#', 'reason', ':', 'infiltrate', 'improvement', 'admitting', 'diagnosis', ':', 'pneumonia', 'medical', 'condition', ':', '77', 'year', 'old', 'woman', 'with', 'pu', '##lm', 'process', 'reason', 'for', 'this', 'examination', ':', 'infiltrate', 'improvement', 'final', 'report', 'indication', ':', '77', '-', 'year', '-', 'old', 'female', 'with', 'pulmonary', 'process', '.', 'comparison', ':', 'and', 'ct', 'chest', '.', 'frontal', 'chest', 'radio', '##graph', ':', 'a', 'swan', '-', 'gan', '##z', 'cat', '##het', '##er', 'is', 'again', 'seen', 'with', 'tip', 'in', 'the', 'right', 'vent', '##ric', '##le', '.', 'this', 'is', 'unchanged', 'compared', 'to', 'the', 'chest', 'ct', 'of', '.', 'the', 'cardiac', 'silhouette', 'is', 'stab', '##ly', 'enlarged', '.', 'there', 'is', 'no', 'relevant', 'change', 'in', 'the', 'appearance', 'of', 'bilateral', 'par', '##en', '##chy', '##mal', 'op', '##ac', '##ities', '.', 'small', 'bilateral', 'pl', '##eur', '##al', 'e', '##ff', '##usions', 'have', 'increased', '.', 'impression', ':', 'no', 'relevant', 'change', 'in', 'appearance', 'of', 'bilateral', 'par', '##en', '##chy', '##mal', 'op', '##ac', '##ities', '.', 'swan', '-', 'gan', '##z', 'cat', '##het', '##er', 'tip', 'is', 'positioned', 'within', 'the', 'right', 'vent', '##ric', '##le', '.']\n","chunk 102 tokenize start!\n","First sentence tokenized\n","['respiratory', 'care', 'note', 'pt', 'r', '##x', '##d', 'q', '##4', 'hours', 'with', 'al', '##bu', '##terol', 'ne', '##bs', '.', 'pt', 'to', '##l', 'r', '##x', 'well', '.', 'bs', 'coarse', 'with', 'ex', '##p', 'w', '##hee', '##zes', 'that', 'persist', 'post', 'r', '##x', '.', 'encouraged', 'pt', 'to', 'db', '/', 'c', '.', 'pt', 'c', '/', 'r', 'thick', 'yellow', 'secret', '##ions', 'a', 'couple', 'of', 'times', 'today', '.', 'pt', 'needs', 'to', 'be', 'encouraged', 'to', 'db', '/', 'c', '.', 'will', 'follow']\n","chunk 103 tokenize start!\n","First sentence tokenized\n","['8', ':', '51', 'pm', 'chest', '(', 'portable', 'ap', ')', 'clip', '#', 'reason', ':', 'des', '##att', '##ing', 'admitting', 'diagnosis', ':', 'right', 'rib', 'fracture', 'medical', 'condition', ':', '75', 'year', 'old', 'woman', 'with', 'ar', '##ds', 'reason', 'for', 'this', 'examination', ':', 'des', '##att', '##ing', 'final', 'report', 'history', ':', 'ar', '##ds', ',', 'des', '##at', '##ura', '##ting', '.', 'chest', ',', 'single', 'ap', 'portable', 'view', '.', 'a', 'tr', '##ache', '##ost', '##omy', 'is', 'in', 'place', '.', 'a', 'left', 'sub', '##cl', '##avian', 'central', 'line', 'is', 'present', ',', 'tip', 'over', 'mid', 'sv', '##c', '.', 'there', 'are', 'diffuse', 'patch', '##y', 'con', '##fl', '##uen', '##t', 'op', '##ac', '##ities', ',', 'most', 'pronounced', 'in', 'both', 'upper', 'zones', 'and', 'at', 'both', 'bases', '.', 'allowing', 'for', 'technical', 'differences', '.', 'these', 'appear', 'worse', 'than', 'on', '.', 'probable', 'small', 'bilateral', 'e', '##ff', '##usions', '.', 'note', 'is', 'made', 'of', 'os', '##te', '##open', '##ia', ',', 'sc', '##olio', '##sis', ',', 'de', '##gen', '##erative', 'changes', ',', 'apparent', 've', '##rte', '##bra', '##l', 'body', 'compression', 'fractures', ',', 'and', 'a', 'balloon', 'from', 'a', 'g', '-', 'tube', 'in', 'the', 'left', 'upper', 'quadrant', '.', 'impression', ':', 'patch', '##y', 'somewhat', 'con', '##fl', '##uen', '##t', 'op', '##ac', '##ities', 'in', 'both', 'lungs', ',', 'slightly', 'worse', 'compared', 'with', '.', 'this', 'could', 'represent', 'ch', '##f', 'super', '##im', '##posed', 'on', 'ar', '##ds', 'versus', 'worse', '##ning', 'of', 'ar', '##ds', '.', 'small', 'e', '##ff', '##usions', 'which', 'appear', 'to', 'have', 'increased', ',', 'supporting', 'the', 'possibility', 'of', 'super', '##im', '##posed', 'ch', '##f', '.']\n","chunk 104 tokenize start!\n","First sentence tokenized\n","['2', ':', '01', 'pm', 'shoulder', 'views', 'non', 'trauma', 'in', 'o', '.', 'r', '.', 'right', ';', 'upper', 'ex', '##tre', '##mity', 'flu', '##oro', 'without', 'radio', '##logist', 'right', '##cl', '##ip', '#', 'reason', ':', 'or', '##if', 'right', 'shoulder', '.', 'admitting', 'diagnosis', ':', 'blunt', 'trauma', 'final', 'report', 'history', ':', 'fracture', '.', 'intra', '##oper', '##ative', 'flu', '##oro', '##scopic', 'views', 'of', 'the', 'right', 'shoulder', 'were', 'obtained', 'without', 'a', 'radio', '##logist', 'present', '.', 'these', 'demonstrate', 'the', 'placement', 'of', 'fix', '##ation', 'screw', '##s', 'projecting', 'over', 'the', 'hume', '##ral', 'head', 'and', 'greater', 'tube', '##ros', '##ity', '.', 'for', 'additional', 'details', ',', 'please', 'consult', 'the', 'operative', 'report', '.']\n","chunk 105 tokenize start!\n","First sentence tokenized\n","['clinical', 'nutrition', 'o', ':', '~', '31', 'w', '##k', 'c', '##ga', 'bb', 'on', 'do', '##l', 'w', '##t', ':', '112', '##5', 'g', '(', '+', '20', ')', '(', '<', '10th', '%', 'ile', ')', ';', 'birth', '##wt', ':', '108', '##0', 'g', '.', 'average', 'w', '##t', 'gain', 'over', 'past', 'w', '##k', '~', '20', 'g', '/', 'kg', '/', 'day', '.', 'hc', ':', '27', 'cm', '(', '~', '10th', '%', 'ile', ')', ';', 'last', ':', '26', 'cm', 'l', '##n', ':', '37', 'cm', '(', '~', '10th', '%', 'ile', ')', ';', 'last', ':', '34', 'cm', 'labs', 'noted', 'nutrition', ':', '150', 'cc', '/', 'kg', '/', 'day', 't', '##f', '.', 'feeds', 'currently', '@', '60', 'cc', '/', 'kg', '/', 'day', 'b', '##m', '10', ',', 'increasing', '10', 'cc', '/', 'kg', '/', '.', 'remain', '##dr', 'of', 'fluids', 'as', 'p', '##n', 'via', 'non', 'central', 'pic', '##c', 'line', ';', 'projected', 'intake', 'for', 'next', '24', '##hr', '##s', 'from', 'p', '##n', '~', '49', 'kc', '##al', '/', 'kg', '/', 'day', ',', '~', '1', 'g', 'pro', '/', 'kg', '/', 'day', 'and', '~', '7', 'g', 'fat', '/', 'kg', '/', 'day', '.', 'from', 'en', ':', '~', '47', 'kc', '##al', '/', 'kg', '/', 'day', ',', '~', '7', 'g', 'pro', '/', 'kg', '/', 'day', 'and', '~', '7', 'g', 'fat', '/', 'kg', '/', 'day', '.', 'gi', '##r', 'from', 'p', '##n', '~', '9', 'mg', '/', 'kg', '/', 'min', '.', 'gi', ':', 'abdomen', 'benign', '.', 'passing', 'small', 'me', '##con', '##ium', '.', 'a', '/', 'goals', ':', 'to', '##ler', '##ating', 'feeds', 'without', 'gi', 'problems', 'so', 'far', ';', 'advancing', 'slowly', 'and', 'monitoring', 'closely', 'for', 'tolerance', '.', 'to', '##ler', '##ating', 'p', '##n', 'with', 'good', 'bs', 'control', '.', 'labs', 'noted', 'and', 'p', '##n', 'adjusted', 'accordingly', '.', 'current', 'feeds', '+', 'p', '##n', 'meeting', 'rec', '##s', 'for', 'kc', '##als', '/', 'fat', 'and', 'vi', '##ts', '.', 'not', 'meeting', 'full', 'protein', 'or', 'mineral', 'rec', '##s', ',', 'related', 'to', 'limitations', 'of', 'non', 'central', 'iv', 'access', '.', 'expect', 'feeds', 'to', 'advance', 'to', 'initial', 'goal', 'soon', ',', 'when', 'full', 'nutrition', 'rec', '##s', 'will', 'be', 'met', '.', 'growth', 'is', 'meeting', 'rec', '##s', 'for', 'w', '##t', 'gain', 'and', 'hc', 'gain', '.', 'l', '##n', 'gain', 'is', 'exceeding', 'recommended', '~', '1', 'cm', '/', 'w', '##k', ';', 'represents', 'catch', 'up', 'growth', ',', 'although', 'question', 'accuracy', 'of', 'current', 'or', 'previous', 'w', '##k', \"'\", 's', 'l', '##n', 'measurement', '.', 'will', 'follow', 'long', 'term', 'trends', '.', 'will', 'continue', 'to', 'follow', 'w', '/', 'team', 'and', 'participate', 'in', 'nutrition', 'plans', '.']\n","chunk 106 tokenize start!\n","First sentence tokenized\n","['chief', 'complaint', ':', 'res', '##p', 'failure', 'i', 'saw', 'and', 'examined', 'the', 'patient', ',', 'and', 'was', 'physically', 'present', 'with', 'the', 'ic', '##u', 'resident', 'for', 'key', 'portions', 'of', 'the', 'services', 'provided', '.', 'i', 'agree', 'with', 'his', '/', 'her', 'note', 'above', ',', 'including', 'assessment', 'and', 'plan', '.', 'hp', '##i', ':', '24', 'hour', 'events', ':', 'dial', '##ysis', 'cat', '##het', '##er', '-', 'start', '03', ':', '18', 'pm', 'dial', '##ysis', 'cat', '##het', '##er', '-', 'stop', '12', ':', '00', 'am', 'did', 'not', 'get', 'hd', ',', 'did', 'not', 'get', 'ps', '##v', 'brief', 'burst', 'of', 'afi', '##b', 'with', 'rv', '##r', 'all', '##er', '##gies', ':', 'he', '##par', '##in', 'agents', 'unknown', ';', 'su', '##cci', '##ny', '##lch', '##olin', '##e', 'unknown', ';', 'last', 'dose', 'of', 'antibiotics', ':', 'ci', '##pro', '##fl', '##ox', '##ac', '##in', '-', '02', ':', '13', 'pm', 'van', '##com', '##y', '##cin', '-', '05', ':', '02', 'pm', 'ce', '##ft', '##azi', '##dim', '##e', '-', '08', ':', '08', 'am', 'in', '##fusion', '##s', ':', 'other', 'ic', '##u', 'medications', ':', 'other', 'medications', ':', 'changes', 'to', 'medical', 'and', 'family', 'history', ':', 'pm', '##h', ',', 'sh', ',', 'f', '##h', 'and', 'ro', '##s', 'are', 'unchanged', 'from', 'admission', 'except', 'where', 'noted', 'above', 'and', 'below', 'review', 'of', 'systems', 'is', 'unchanged', 'from', 'admission', 'except', 'as', 'noted', 'below', 'review', 'of', 'systems', ':', 'cardiovascular', ':', 'ta', '##chy', '##card', '##ia', 'flows', '##hee', '##t', 'data', 'as', 'of', '10', ':', '40', 'am', 'vital', 'signs', 'hem', '##od', '##yna', '##mic', 'monitoring', 'fluid', 'balance', '24', 'hours', 'since', '12', 'am', 't', '##max', ':', '7', 'c', '(', '8', 'tc', '##urrent', ':', '6', 'c', '(', '7', 'hr', ':', '108', '(', '106', '-', '126', ')', 'bp', '##m', 'bp', ':', '90', '/', '44', '(', '58', ')', '{', '90', '/', '43', '(', '58', ')', '-', '152', '/', '67', '(', '97', ')', '}', 'mm', '##hg', 'rr', ':', '23', '(', '19', '-', '37', ')', 'ins', '##p', '/', 'min', 'sp', '##o', '##2', ':', '98', '%', 'heart', 'rhythm', ':', 'af', '(', 'at', '##rial', 'fi', '##bri', '##llation', ')', 'w', '##gt', '(', 'current', ')', ':', '9', 'kg', '(', 'admission', ')', ':', '3', 'kg', 'height', ':', '66', 'inch', 'total', 'in', ':', '1', ',', '53', '##8', 'ml', '43', '##8', 'ml', 'po', ':', 't', '##f', ':', '81', '##3', 'ml', '100', 'ml', 'iv', '##f', ':', '404', 'ml', '247', 'ml', 'blood', 'products', ':', 'total', 'out', ':', '0', 'ml', '0', 'ml', 'urine', ':', 'ng', ':', 'stool', ':', 'drains', ':', 'balance', ':', '1', ',', '53', '##8', 'ml', '43', '##8', 'ml', 'respiratory', 'support', 'vent', '##ila', '##tor', 'mode', ':', 'cm', '##v', '/', 'assist', 'vt', '(', 'set', ')', ':', '400', '(', '400', '-', '400', ')', 'ml', 'rr', '(', 'set', ')', ':', '16', 'pee', '##p', ':', '8', 'cm', '##h', '##2', '##o', 'fi', '##o', '##2', ':', '30', '%', 'rs', '##bi', ':', '96', 'pip', ':', '29', 'cm', '##h', '##2', '##o', 'plateau', ':', '27', 'cm', '##h', '##2', '##o', 'sp', '##o', '##2', ':', '98', '%', 'ab', '##g', ':', '41', '/', '38', '/', '/', '23', '/', '0', 've', ':', '4', 'l', '/', 'min', 'pa', '##o', '##2', '/', 'fi', '##o', '##2', ':', '290', 'physical', 'examination', 'general', 'appearance', ':', 'lying', 'in', 'bed', ',', 'eyes', 'open', ',', 'not', 'responding', 'or', 'following', 'commands', 'cardiovascular', ':', '(', 's', '##1', ':', 'normal', ')', ',', '(', 's', '##2', ':', 'normal', ')', 'ir', '##re', '##g', 'ir', '##re', '##g', 'chest', 'fair', 'air', 'movement', 'no', 'w', '##hee', '##zes', 'bs', 'at', 'right', 'base', 'abd', ':', 'obe', '##se', 'soft', 'nt', '+', 'bs', 'eyes', 'open', ',', 'attends', 'son', 'at', 'bedside', 'but', 'not', 'team', ',', 'not', 'answering', 'questions', 'from', 'either', 'labs', '/', 'radio', '##logy', '2', 'g', '/', 'dl', '279', 'k', '/', 'ul', '161', 'mg', '/', 'dl', '4', 'mg', '/', 'dl', '23', 'me', '##q', '/', 'l', '0', 'me', '##q', '/', 'l', '66', 'mg', '/', 'dl', '108', 'me', '##q', '/', 'l', '141', 'me', '##q', '/', 'l', '4', '%', '9', 'k', '/', 'ul', '07', ':', '13', 'pm', '05', ':', '02', 'am', '05', ':', '16', 'am', '06', ':', '00', 'am', '04', ':', '57', 'am', '05', ':', '23', 'am', '09', ':', '53', 'pm', '04', ':', '22', 'am', '06', ':', '26', 'am', '06', ':', '38', 'am', 'wb', '##c', '2', '3', '8', '9', 'hc', '##t', '1', '5', '9', '4', 'pl', '##t', '157', '191', '281', '279', 'cr', '1', '4', '9', '4', 'tc', '##o', '##2', '26', '24', '28', '26', '25', 'glucose', '197', '259', '159', '91', '161', 'other', 'labs', ':', 'pt', '/', 'pt', '##t', '/', 'in', '##r', ':', '0', '/', '8', '/', '1', ',', 'ck', '/', 'ck', '##mb', '/', 'tr', '##op', '##oni', '##n', '-', 't', ':', '21', '/', '4', '/', '30', ',', 'alt', '/', 'as', '##t', ':', '32', '/', '40', ',', 'al', '##k', 'ph', '##os', '/', 't', 'bi', '##li', ':', '58', '##2', '/', '5', ',', 'amy', '##lase', '/', 'lip', '##ase', ':', '20', '/', '9', ',', 'differential', '-', 'ne', '##uts', ':', '0', '%', ',', 'band', ':', '0', '%', ',', 'l', '##ym', '##ph', ':', '0', '%', ',', 'mono', ':', '0', '%', ',', 'e', '##os', ':', '0', '%', ',', 'fi', '##bri', '##no', '##gen', ':', '34', '##8', 'mg', '/', 'dl', ',', 'lac', '##tic', 'acid', ':', '3', 'mm', '##ol', '/', 'l', ',', 'album', '##in', ':', '6', 'g', '/', 'dl', ',', 'ld', '##h', ':', '512', 'i', '##u', '/', 'l', ',', 'ca', '+', '+', ':', '9', 'mg', '/', 'dl', ',', 'mg', '+', '+', ':', '0', 'mg', '/', 'dl', ',', 'po', '##4', ':', '9', 'mg', '/', 'dl', 'micro', '##biology', ':', 'blood', 'c', '##x', 'no', 'growth', 'to', 'date', 'assessment', 'and', 'plan', '79', 'year', 'old', 'woman', 'with', 'complicated', 'recent', 'course', ',', 'including', 'ar', '##ds', ',', 'cm', '##v', 'vi', '##rem', '##ia', ',', 'and', 'vr', '##e', 'ba', '##cter', '##emia', '.', 'she', 'had', 'been', 'improving', 'but', 'last', 'week', 'deco', '##mp', '##ens', '##ated', 'at', '##tri', '##bu', '##table', 'to', 'va', '##p', 'acute', 'respiratory', 'failure', 's', '/', 'p', 'tr', '##ach', 'on', 'fever', ',', 'increased', 'sp', '##ut', '##um', ',', 'and', 'respiratory', 'deco', '##mp', '##ens', '##ation', 'due', 'to', 'pseudo', '##mona', '##s', 'va', '##p', 'sen', '##si', 'to', 'ce', '##ft', '##az', '#', '-', 'ps', '##v', 'trial', 'again', 'after', 'hd', 'sep', '##sis', '/', 'vr', '##e', 'ba', '##cter', '##emia', '-', 'completed', 'line', '##zo', '##lid', '14', '##d', 'course', '-', 'follow', 'cultures', 'afi', '##b', 'with', 'rv', '##r', '-', 'rate', 'control', 'adequate', 'at', 'present', 'an', '##uri', '##c', 'renal', 'failure', '-', 'now', 'on', 'hd', '-', 'tunnel', '##ed', 'line', 'placed', 'yesterday', 'diabetes', '-', 'on', 'sq', 'regime', '##n', 'and', 'working', 'with', 'end', '##oc', '##rine', 'to', 'maximize', 'g', '##ly', '##ce', '##mic', 'control', 'fen', '-', 'held', 'on', 'peg', 'given', 'recent', 'deco', '##mp', '##ens', '##ation', 'and', '?', 'cm', '##v', 'coli', '##tis', 'surgical', 'team', 'stated', 'will', 'read', '##dre', '##ss', 'when', 'setting', 'up', 'for', 'rehab', '-', 'will', 'email', 'with', 'dr', 'to', 'follow', 'up', 'an', '##emia', '-', 'stable', 'ic', '##u', 'care', 'nutrition', ':', 'tube', 'feeds', 'g', '##ly', '##ce', '##mic', 'control', ':', 'lines', ':', 'pic', '##c', 'line', '-', '05', ':', '00', 'pm', 'arterial', 'line', '-', '08', ':', '10', 'pm', 'dial', '##ysis', 'cat', '##het', '##er', '-', '03', ':', '18', 'pm', 'prop', '##hyl', '##ax', '##is', ':', 'd', '##v', '##t', ':', '(', 'none', 'hit', ')', 'stress', 'ul', '##cer', ':', 'pp', '##i', 'va', '##p', ':', 'ch', '##lor', '##he', '##x', ',', 'ho', '##b', 'comments', ':', 'communication', ':', 'spoke', 'with', 'son', 'today', 'status', ':', 'd', '##nr', '(', 'do', 'not', 'res', '##us', '##cit', '##ate', ')', 'disposition', ':', 'ic', '##u', 'total', 'time', 'spent', ':', '40']\n","chunk 107 tokenize start!\n","First sentence tokenized\n","['12', ':', '49', 'am', 'chest', '(', 'portable', 'ap', ')', 'clip', '#', 'reason', ':', 'eva', '##l', 'et', '##t', 'pl', '##ac', '##ment', 'medical', 'condition', ':', '27', 'year', 'old', 'woman', 'with', 'to', '##x', 'syndrome', '?', 'et', '##iology', 'int', '##uba', '##ted', 'at', 'os', '##h', 'reason', 'for', 'this', 'examination', ':', 'eva', '##l', 'et', '##t', 'pl', '##ac', '##ment', 'final', 'report', 'clinical', 'history', ':', '27', '-', 'year', '-', 'old', 'female', 'with', 'toxic', 'syndrome', '.', 'evaluate', 'et', 'tube', '.', 'comparison', ':', 'none', '.', 'findings', ':', 'ap', 'chest', 'radio', '##graph', '.', 'the', 'et', 'tube', 'is', 'low', 'and', 'terminates', '3', 'cm', 'above', 'the', 'car', '##ina', '.', 'recommend', 'partial', 'withdrawal', '.', 'tip', 'of', 'ng', 'tube', 'is', 'seen', 'within', 'the', 'stomach', '.', 'the', 'lungs', 'are', 'clear', '.', 'the', 'heart', ',', 'media', '##sti', '##num', ',', 'hi', '##la', ',', 'and', 'pulmonary', 'vascular', '##ity', 'are', 'within', 'normal', 'limits', '.', 'no', 'p', '##ne', '##um', '##otho', '##ra', '##x', 'or', 'pl', '##eur', '##al', 'e', '##ff', '##usion', '.', 'impression', ':', 'no', 'consolidation', '.', 'low', 'position', 'of', 'et', 'tube', ',', 'recommend', 'partial', 'withdrawal', '.']\n","chunk 108 tokenize start!\n","First sentence tokenized\n","['admission', 'note', 'ob', '-', 'pe', '##di', '-', 'asked', 'by', 'doctor', 'to', 'see', 'baby', 'boy', 'of', 'sep', '##sis', 'risk', '.', 'he', 'is', 'the', '283', '##0', 'gram', 'product', 'of', 'a', 'term', '(', 'ed', '##c', ')', 'ge', '##station', 'born', 'to', 'a', '23', 'yo', 'g', '##1', 'p', '0', 'mom', 'with', 'p', '##ns', 'blood', 'type', 'o', 'positive', ',', 'antibody', 'negative', ',', 'r', '##pr', 'nr', ',', 'rub', '##ella', 'immune', ',', 'gb', '##s', 'positive', '.', 'pregnancy', 'was', 'un', '##com', '##pl', '##icated', '.', 'labor', 'was', 'complicated', 'by', 'maternal', 'fever', 'to', 'rom', 'was', 'less', 'than', '24', 'hours', 'prior', 'to', 'delivery', '.', 'mom', 'was', 'treated', 'with', 'ab', '##x', 'more', 'than', '4', 'hours', 'prior', 'to', 'delivery', '.', 'this', 'infant', 'was', 'born', 'by', 'ns', '##vd', 'with', 'ab', '##gar', 'scores', 'of', '7', '(', '1', 'min', ')', '9', '(', '5', 'min', ')', '.', 'he', 'was', 'given', 'stimulation', ',', 'bulb', 'su', '##ction', ',', 'and', 'bb', '##o', '##2', 'in', 'the', 'delivery', '.', 'sh', '-', 'otherwise', 'non', '##con', '##tri', '##bu', '##tory', 'f', '##h', '-', 'otherwise', 'non', '##con', '##tri', '##bu', '##tory', 'ro', '##s', '-', 'all', 'other', 'sy', '##tem', '##s', 'unavailable', 'exam', '-', 'active', 'well', 'appearing', 'infant', 'in', 'no', 'distress', 'weight', '283', '##0', 'grams', 'length', '5', 'in', 'te', '##mp', '4', 'hr', '156', 'rr', '76', 'bp', '65', '/', '36', 'mean', '46', 'sat', '98', '%', 'in', 'room', 'air', 'd', 'stick', '103', 'hee', '##nt', 'norm', '##oc', '##ep', '##hal', '##ic', 'at', '##ra', '##umatic', 'ant', 'font', 'open', 'flat', 'pal', '##ate', 'intact', 'red', 'reflex', 'def', '##erre', '##d', 'neck', 'su', '##pp', '##le', 'lungs', 'clear', 'bi', '##lia', '##tera', '##lly', 'cv', 'regular', 'rate', 'and', 'rhythm', 'no', 'murmur', 'fe', '##moral', 'pulses', '2', '+', 'bilateral', '##ly', 'abd', 'soft', 'with', 'active', 'bow', '##el', 'sounds', 'no', 'masses', 'or', 'di', '##sten', '##tion', 'spine', 'mid', '##line', 'no', 'dim', '##ple', 'hips', 'stable', 'cl', '##avi', '##cles', 'intact', 'an', '##us', 'patent', 'skin', 'intact', 'mongol', '##ain', 'spot', 'on', 'butt', '##ock', 'ex', '##t', 'warm', 'well', 'per', '##fus', '##ed', 'brisk', 'cap', 'ref', '##ill', 'gu', 'normal', 'male', 'external', 'test', '##es', 'bilateral', '##ly', 'pal', '##pa', '##ble', 'ne', '##uro', 'good', 'tone', 'move', 'all', 'ex', '##tre', '##mit', '##ies', 'equally', 'imp', '-', 'infant', 'with', 'significant', 'risk', 'for', 'sep', '##sis', 'because', 'of', 'the', 'height', 'of', 'the', 'maternal', 'fever', 'and', 'the', 'positive', 'gb', '##s', 'status', 'despite', 'adequate', 'treat', '##met', '##n', 'will', 'plan', 'to', 'draw', 'cbc', 'and', 'blood', 'culture', 'will', 'plan', 'to', 'begin', 'amp', '/', 'gen', '##t', 'for', 'min', 'of', '48', 'hours', 'pending', 'clinical', 'course', 'and', 'blood', 'culture', 'results']\n","chunk 109 tokenize start!\n","First sentence tokenized\n","['focus', 'update', 'note', 't', '##max', '-', '99', 'heart', 'rate', 'irregular', 'with', 'pac', '##s', 'and', 'pv', '##cs', 'occasional', '-', 'l', '##yte', '##s', 'assessed', 'no', 'rep', '##lea', '##tion', 'needed', 'this', 'afternoon', '.', 'neo', 'gt', '##t', 'we', '##ane', '##d', 'off', ',', 'heart', 'rate', '90s', ',', '100', '-', '110', ',', 'sb', '##p', '130', '/', '60', 'res', '##p', ':', 'pt', 'c', '/', 'o', 'pain', 'with', 'coughing', 'and', 'deep', 'breathing', ',', 'pain', 'service', 'assessed', 'pt', 'at', 'bedside', 'x', '3', ',', 'ep', '##id', '##ural', 'now', 'at', '14', 'cc', 'hr', ',', 'pt', 'given', '2', 'doses', 'of', 'iv', 'dil', '##aud', '##id', '.', '25', 'mg', 'and', '.', '5', 'mg', 'po', 'hal', '##do', '##l', 'for', 'anxiety', 'per', 'pain', 'service', '.', 'thor', '##aco', '##tom', '##y', 'site', 'at', 'right', 'posterior', 'chest', 'clean', 'and', 'dry', 'well', 'approximate', '##d', 'with', 'some', 'ec', '##cy', '##mos', '##is', 'at', 'inc', '##ision', 'line', ',', 'right', 'lateral', 'chest', 'tube', 'with', 'cr', '##ep', '##it', '##us', 'at', 'site', ',', 'ser', '##osa', '##ng', 'drainage', ',', 'ds', '##d', 'clean', 'dry', 'and', 'intact', ',', 'lung', 'sounds', 'clear', 'to', 'coarse', 'with', 'occasional', 'w', '##hee', '##zes', '-', 'pt', 'given', 'mu', '##com', '##yst', '/', 'al', '##bu', '##terol', 'ne', '##bs', 'with', 'good', 'relief', 'of', 'w', '##hee', '##zing', 'and', 'inc', '##rase', '##d', 'ability', 'to', 'expect', '##ora', '##te', 'secret', '##ions', '.', 'o', '##ob', 'to', 'chair', 'with', 'minimal', 'assist', 'x', 'gu', '/', 'gi', ':', 'pt', 'to', '##ler', '##ating', 'sip', '##s', 'of', 'clear', 'liquid', 'well', ',', 'bow', '##el', 'sounds', 'positive', ',', 'no', 'b', '##m', ',', 'foley', 'cat', '##h', 'urine', 'marginal', '20', '-', '50', '##cc', 'hr', '-', 'ic', '##u', 'resident', 'aware', 'of', 'low', 'urine', 'output', '-', 'will', 'continue', 'to', 'monitor', '.', 'ne', '##uro', ':', 'pt', 'alert', 'x', '3', 'following', 'commands', ',', 'sleepy', 'due', 'to', 'sleep', 'deprivation', 'post', 'op', 'and', 'dil', '##aud', '##id', '.', 'social', ':', 'wife', 'and', 'daughter', 'into', 'visit', 'all', 'day', ',', 'thor', '##ac', '##ic', 'surgeon', 'at', 'bedside', 'to', 'update', 'pt', 'and', 'family', '.', 'plan', ':', 'transfer', 'to', 'floor', 'tomorrow', ',', 'encourage', 'pt', 'to', 'cough', 'deep', 'breath', 'and', 'use', 'incentive', 'sp', '##iro', '##no', '##meter', 'q', '1', 'hour', ',', 'mon', '##iot', '##r', 'pain', 'control', '##k', ',', 'provide', 'support', 'to', 'family', 'and', 'patient', 'as', 'needed']\n","chunk 110 tokenize start!\n","First sentence tokenized\n","['respiratory', 'care', 'pt', 'remains', 'int', '##uba', '##ted', ',', 'and', 'vent', '##ed', 'on', 'a', '/', 'c', 'mode', 'with', 'it', '##ime', 'of', '6', 's', 'per', 'attending', '.', 'acceptable', 'ab', '##g', 'results', '.', 'bs', 'coarse', 'and', 'diminished', '.', 'su', '##ction', '##ed', 'for', 'b', '##l', ';', 'o', '##od', 'tinged', 'th', '##k', 'sec', '##re', '##ions', '.', 'vent', 'cu', '##rc', '##uit', 'changed', 'to', 'heated', 'wire', 'cu', '##rc', '##uit', '.', 'plan', ':', 'con', '##t', 'vent', 'support', ',', 'we', '##an', 'vent', 'setting', 'as', 'tolerated', '/', 'confirm', 'w', 'team', '.']\n","chunk 111 tokenize start!\n","First sentence tokenized\n","['11', ':', '58', 'am', 'chest', '(', 'pa', '&', 'la', '##t', ')', 'clip', '#', 'reason', ':', 'please', 'evaluate', 'for', 'infiltrate', 'medical', 'condition', ':', '74', 'year', 'old', 'man', 'with', 'cough', 'and', 'fever', ',', 'ms', 'change', 'reason', 'for', 'this', 'examination', ':', 'please', 'evaluate', 'for', 'infiltrate', 'final', 'report', '(', 'revised', ')', 'indication', ':', 'cough', 'and', 'fever', ',', 'mental', 'status', 'change', ',', 'query', 'infiltrate', '.', 'comparison', ':', 'none', '.', 'chest', 'ap', 'and', 'lateral', ':', 'there', 'is', 'card', '##iom', '##ega', '##ly', 'and', 'media', '##sti', '##nal', 'and', 'hi', '##lar', 'con', '##tour', '##s', 'are', 'normal', '.', 'there', 'airspace', 'op', '##ac', '##ification', 'abu', '##tting', 'the', 'right', 'heart', 'border', 'that', 'the', 'lateral', 'local', '##izes', 'to', 'the', 'right', 'middle', 'lobe', 'but', 'no', 'pl', '##eur', '##al', 'e', '##ff', '##usion', 'or', 'p', '##ne', '##um', '##otho', '##ra', '##x', '.', 'there', 'is', 'mild', 'prominence', 'of', 'the', 'pulmonary', 'va', '##scu', '##lat', '##ure', '.', 'no', 'gross', 'os', '##se', '##ous', 'abnormal', '##ity', '.', 'impression', ':', 'likely', 'right', 'middle', 'lobe', 'ph', '##eum', '##onia', ';', 'follow', 'up', 'in', '6', 'weeks', 'recommended', 'comment', ':', 'these', 'results', 'were', 'transmitted', 'via', 'the', 'cr', '##itia', '##l', 'result', 'dashboard', 'for', 'com', '##mun', '##ica', '##ito', '##n', 'and', 'follow', '-', 'up']\n","chunk 112 tokenize start!\n","First sentence tokenized\n","['res', '##p', 'care', ':', 'pt', 'continues', 'on', 'mechanical', 'ventilation', ':', 'ac', '600', '##x', '##18', '50', '%', '+', 'no', 'changes', 'made', 'overnight', '.', 'l', '##s', 'coarse', 'bilateral', '##ly', '.', 'pt', 's', '##x', '##n', \"'\", 'd', 'for', 'moderate', 'amounts', 'of', 'thick', 'white', 'secret', '##ions', '.', 'tx', \"'\", 's', 'given', 'per', '.', 'ab', '##g', ':', '37', '/', '51', '/', '87', '/', '31', '/', 'plan', ':', 'continue', 'current', 'support']\n","chunk 113 tokenize start!\n","First sentence tokenized\n","['12', ':', '50', 'pm', 'chest', '(', 'portable', 'ap', ')', 'clip', '#', 'reason', ':', 'evaluate', 'for', 'infiltrate', ',', 'e', '##ff', '##usion', 'admitting', 'diagnosis', ':', 'hepatitis', 'c', ';', 'ci', '##rr', '##hosis', ';', 'renal', 'failure', 'medical', 'condition', ':', '57', 'year', 'old', 'woman', 'with', 'es', '##ld', 'hc', '##v', 'ci', '##rr', '##hosis', ',', 'with', 'l', '##g', 'volume', 'as', '##cite', '##s', ',', 'worse', '##ning', 'hr', '##s', ',', 'w', '##hee', '##zing', 'with', 'ex', '##ert', '##ion', '.', 'reason', 'for', 'this', 'examination', ':', 'evaluate', 'for', 'infiltrate', ',', 'e', '##ff', '##usion', 'final', 'report', 'single', 'ap', 'portable', 'view', 'of', 'the', 'chest', ':', 'reason', 'for', 'exam', ':', 'worse', '##ning', 'w', '##hee', '##zing', ',', 'history', 'of', 'es', '##ld', '.', 'comparison', 'is', 'made', 'with', 'prior', 'study', '.', 'this', 'is', 'a', 'limited', 'examination', ',', 'it', 'was', 'centered', 'in', 'the', 'thor', '##aco', '-', 'abdominal', 'junction', '.', 'allowing', 'for', 'this', ',', 'there', 'has', 'been', 'interval', 'worse', '##ning', 'of', 'bi', '##bas', '##ila', '##r', 'ate', '##le', '##cta', '##sis', ',', 'greater', 'in', 'the', 'left', 'side', '.', 'there', 'are', 'lower', 'lung', 'volumes', '.', 'card', '##iom', '##ed', '##ias', '##tina', '##l', 'con', '##tour', 'is', 'stable', '.', 'there', 'are', 'probably', 'small', 'bilateral', 'pl', '##eur', '##al', 'e', '##ff', '##usions', '.', 'doctor']\n","chunk 114 tokenize start!\n","First sentence tokenized\n","['np', '##note', '#', 'remains', 'on', 'nasal', 'pro', '##ng', 'cp', '##ap', '##5', '##cm', ',', 'fi', '##o', '##2', '24', '-', '26', '%', ',', 'bb', '##s', 'clear', ',', 'equal', ',', 'mild', 'sub', '##cos', '##tal', '/', 'inter', '##cos', '##tal', 're', '##tra', '##ctions', 'present', ',', 'no', 'spells', 'thus', 'af', '##r', 'this', 's', 'hi', '##ft', '.', 'on', 'caf', '##fine', 'given', 'a', 'so', '##rder', '##ed', '.', 'a', ';', 'required', 'cp', '##ap', 'support', '.', '#', 't', '##f', '=', '130', '##cc', '/', 'kg', '/', 'day', ',', 'b', '##m', '##26', 'with', 'ben', '##ep', '##rot', '##ien', ',', 'pg', 'fed', 'tolerated', ',', 'bs', '+', ',', 'no', 'loops', ',', 'void', '##ed', ',', 'no', 'stool', 'thus', 'far', 'this', 's', 'hi', '##ft', '.', 'a', ';', 'feeds', 'tolerated', '.', 'p', ';', 'con', '##t', 'current', 'feeding', 'plan', ',', 'l', '##yte', '##s', 'with', 'hc', '##t', 'on', 'tuesday', 'am', '.', '#', ',', 'active', 'with', 'care', ',', 'te', '##mp', 'stable', 'in', 'a', 'open', 'cr', '##ib', ',', 'sw', '##ad', '##dled', 'with', 'blanket', ',', 'mae', '.', 'a', ';', 'ag', '##a', 'p', ';', 'con', '##t', 'dev', 'support', '.', '#', 'mom', 'visited', 'with', 'sibling', ',', 'asking', 'questions', ',', 'held', 'the', 'baby', 'during', 'feed', '.', 'a', ';', 'p', ';', 'con', '##t', 'update', 'and', 'support', '.']\n","chunk 115 tokenize start!\n","First sentence tokenized\n","['sin', '##us', 'rhythm', 'with', 'vent', '##ric', '##ular', 'big', '##emi', '##ny', 'and', 'one', 'vent', '##ric', '##ular', 'couple', '##t', '.', 'compared', 'to', 'the', 'previous', 'tracing', 'the', 'vent', '##ric', '##ular', 'couple', '##t', 'is', 'new', '.', 'other', 'features', 'are', 'unchanged', '.', 'clinical', 'correlation', 'is', 'suggested', '.', 'tracing', '#', '3']\n","chunk 116 tokenize start!\n","First sentence tokenized\n","[',', 'w', '.', 'sic', '##u', '-', 'a', '1', ':', '18', 'pm', 'bi', '##lat', 'lower', 'ex', '##t', 'veins', 'clip', '#', 'reason', ':', 'eva', '##l', '.', 'for', 'd', '##v', '##t', 'admitting', 'diagnosis', ':', 'sep', '##sis', 'medical', 'condition', ':', '57', 'year', 'old', 'man', 'with', 'l', '>', 'r', 'le', 'ed', '##ema', ',', 'history', 'of', 'th', '##rom', '##bos', '##is', 'reason', 'for', 'this', 'examination', ':', 'eva', '##l', '.', 'for', 'd', '##v', '##t', 'p', '##fi', 'report', 'sub', '##to', '##tal', 'th', '##rom', '##bos', '##is', 'of', 'the', 'right', 'common', 'fe', '##moral', 'vein', ',', 'with', 'extension', 'into', 'the', 'upper', '##most', 'superficial', 'fe', '##moral', 'vein', 'and', 'one', 'of', 'its', 'branches', '.']\n","chunk 117 tokenize start!\n","First sentence tokenized\n","['respiratory', 'therapy', 'we', '##ane', '##d', 'pip', 'today', '.', 'currently', 'on', 'sim', '##v', '24', '/', '6', '-', '28', ',', '21', '-', '28', '%', '.', 'l', '##s', 'coarse', ',', 'su', '##ction', '##ing', 'thick', 'yellow', '.', 'o', '##cc', 'riding', 'vent', 'at', 'rate', '0', '##f', 'we', '##an', 'as', 'tolerated', '.']\n","chunk 118 tokenize start!\n","First sentence tokenized\n","['demographics', 'day', 'of', 'int', '##uba', '##tion', ':', 'day', 'of', 'mechanical', 'ventilation', ':', '4', 'ideal', 'body', 'weight', ':', '59', 'none', 'ideal', 'tidal', 'volume', ':', 'ml', '/', 'kg', 'air', '##way', 'air', '##way', 'placement', 'data', 'known', 'difficult', 'int', '##uba', '##tion', ':', 'no', 'procedure', 'location', ':', 'reason', ':', 'tube', 'type', 'et', '##t', ':', 'position', ':', 'cm', 'at', 'teeth', 'route', ':', 'type', ':', 'standard', 'size', ':', '5', '##mm', 'tr', '##ache', '##ost', '##omy', 'tube', ':', 'type', ':', 'manufacturer', ':', 'size', ':', 'pm', '##v', ':', 'cuff', 'management', ':', 'vol', '/', 'press', ':', 'cuff', 'pressure', ':', 'cm', '##h', '##2', '##o', 'cuff', 'volume', ':', 'ml', '/', 'air', '##way', 'problems', ':', 'comments', ':', 'lung', 'sounds', 'r', '##ll', 'lung', 'sounds', ':', 'diminished', 'ru', '##l', 'lung', 'sounds', ':', 'clear', 'lu', '##l', 'lung', 'sounds', ':', 'clear', 'll', '##l', 'lung', 'sounds', ':', 'clear', 'comments', ':', 'secret', '##ions', 'sp', '##ut', '##um', 'color', '/', 'consistency', ':', '/', 'sp', '##ut', '##um', 'source', '/', 'amount', ':', '/', 'comments', ':', 'ventilation', 'assessment', 'level', 'of', 'breathing', 'assistance', ':', 'visual', 'assessment', 'of', 'breathing', 'pattern', ':', 'assessment', 'of', 'breathing', 'comfort', ':', 'non', '-', 'invasive', 'ventilation', 'assessment', ':', 'invasive', 'ventilation', 'assessment', ':', 'trigger', 'work', 'assessment', ':', 'd', '##ys', '##yn', '##ch', '##ron', '##y', 'assessment', ':', 'comments', ':', 'plan', 'next', '24', '-', '48', 'hours', ':', 'reason', 'for', 'continuing', 'current', 'vent', '##ila', '##tory', 'support', ':', 'respiratory', 'care', 'shift', 'procedures', 'transports', ':', 'destination', '(', 'r', '/', 't', ')', 'time', 'complications', 'comments', 'ct', '1800', 'bedside', 'procedures', ':', 'comments', ':']\n","chunk 119 tokenize start!\n","First sentence tokenized\n","['nursing', 'progress', 'note', 'pt', 'in', 'a', 'fi', '##b', 'rate', '100', '-', '130', ',', 'competing', 'with', 'pace', '##r', ',', 'pace', '##r', 'rate', 'decreased', 'to', '60', ',', 'as', 'per', 'dr', '.', 'soon', 'converted', 'to', 'ns', '##r', 'again', '.', 'audible', 'w', '##hee', '##zes', 'treated', 'with', 'al', '##bu', '##terol', 'in', '##hale', '##r', '.', 'pt', 'takes', 'this', 'at', 'home', '.', 'pain', ':', 'pt', 'states', 'she', 'does', 'not', 'have', 'pain', ',', 'but', 'she', 'is', 'uncomfortable', '.', 'treated', 'with', 'ty', '##len', '##ol', '650', 'mg', 'po', 'with', 'some', 'relief', ',', 'and', 'she', 'is', 'able', 'to', 'sleep', '.']\n","chunk 120 tokenize start!\n","First sentence tokenized\n","['4', ':', '25', 'pm', 'chest', 'port', '.', 'line', 'placement', 'clip', '#', 'reason', ':', 'pt', '.', 'had', 'a', 'l', 'pic', '##c', 'line', 'placed', ',', '46', '##cm', 'and', 'needs', 'tip', 'confirmation', 'admitting', 'diagnosis', ':', 'pneumonia', 'medical', 'condition', ':', '75', 'year', 'old', 'woman', 'with', 'abdominal', 'fluid', 'collection', 'who', 'needs', 'pic', '##c', 'for', 't', '##p', '##n', 'and', 'anti', '##b', '##x', '.', 'reason', 'for', 'this', 'examination', ':', 'pt', '.', 'had', 'a', 'l', 'pic', '##c', 'line', 'placed', ',', '46', '##cm', 'and', 'needs', 'tip', 'confirmation', 'please', 'page', 'at', 'with', 'wet', 'read', ',', 'thanks', '.', 'final', 'report', 'portable', 'chest', 'on', 'at', '1623', 'indication', ':', 'pic', '##c', 'line', 'placement', '.', 'comparison', ':', '.', 'findings', ':', 'the', 'right', 'i', '##j', 'and', 'right', 'pic', '##c', 'have', 'been', 'removed', '.', 'a', 'left', 'pic', '##c', 'is', 'now', 'in', 'place', 'with', 'the', 'tip', 'in', 'the', 'sv', '##c', '.', 'other', 'features', 'remain', 'stable', 'with', 'retro', '##card', '##iac', 'density', 'and', 'some', 'pl', '##eur', '##al', 'fluid', 'layer', '##ing', 'out', 'on', 'the', 'left', '.', 'no', 'new', 'consolidation', '##s', 'and', 'no', 'pt', '##x', '.', 'stable', 'appearance', 'of', 'partial', 'res', '##ection', 'of', 'right', 'distal', 'cl', '##avi', '##cle', '.']\n","chunk 121 tokenize start!\n","First sentence tokenized\n","['neon', '##ato', '##logy', 'attending', 'do', '##l', '8', '/', 'pm', '##a', '31', '-', '5', '/', '7', 'weeks', 'in', 'room', 'air', 'with', 'no', 'distress', 'and', 'no', 'card', '##ior', '##es', '##pi', '##rator', '##y', 'events', '(', 'on', 'caf', '##fe', '##ine', ')', '.', 'no', 'murmur', '.', 'well', '-', 'per', '##fus', '##ed', '.', 'bp', '67', '/', '32', '(', '46', ')', '.', 'bi', '##li', '##ru', '##bin', '9', '/', '3', 'yesterday', ';', 'non', '-', 'ict', '##eric', 'clinical', '##ly', '.', 'w', '##t', '132', '##5', '(', '-', '35', ')', 'on', 't', '##fi', '150', 'ml', '/', 'kg', '/', 'day', 'b', '##m', '##20', ',', 'to', '##ler', '##ating', 'well', '.', 'some', 'transient', 'loops', 'noted', 'and', 'two', 'gui', '##ac', 'positive', 'stool', '##s', ',', 'but', 'abd', 'soft', ',', 'non', '-', 'disco', '##lore', '##d', 'and', 'with', 'good', 'bow', '##el', 'sounds', '.', 'te', '##mp', 'stable', 'in', 'iso', '##lette', '.', 'infant', 'active', ',', 'alert', 'and', 'responsive', 'to', 'st', '##im', 'on', 'exam', '.', 'a', '&', 'p', '30', '-', '4', '/', '7', 'week', 'ga', 'infant', 'with', 'feeding', 'im', '##mat', '##urity', '.', '-', 'trace', 'positive', 'stool', '##s', 'likely', 'secondary', 'to', 'gas', '##tric', 'mu', '##cos', '##al', 'irritation', 'by', 'ng', 'tube', ',', 'in', 'light', 'of', 'otherwise', 'entirely', 'reassuring', 'examination', '.', 'monitor', 'clinical', '##ly', 'and', 'proceed', 'to', 'further', 'investigation', 'if', 'any', 'further', 'symptoms', 'are', 'noted']\n","chunk 122 tokenize start!\n","First sentence tokenized\n","['at', '##rial', 'fi', '##bri', '##llation', '(', 'afi', '##b', ')', 'assessment', ':', 'action', ':', 'response', ':', 'plan', ':', 'c', '.', 'di', '##ffi', '##ci', '##le', 'infection', '(', 'c', 'di', '##ff', ',', 'cd', '##iff', 'coli', '##tis', ',', 'cl', '##ost', '##rid', '##ium', 'di', '##ffi', '##ci', '##le', ')', 'assessment', ':', 'action', ':', 'response', ':', 'plan', ':']\n","chunk 123 tokenize start!\n","First sentence tokenized\n","['sin', '##us', 'rhythm', 'with', 'at', '##rial', 'ec', '##top', '##y', '.', 'non', '-', 'specific', 'lateral', 'st', '-', 't', 'wave', 'changes', '.', 'compared', 'to', 'the', 'previous', 'tracing', 'of', 'pre', '##cor', '##dial', 'q', '##rs', 'voltage', 'is', 'less', 'prominent', '.', 'otherwise', ',', 'the', 'findings', 'are', 'similar', '.']\n","chunk 124 tokenize start!\n","First sentence tokenized\n","['pt', 'is', 'a', '67', 'year', 'old', 'man', 'with', 'es', '##rd', '(', 'hd', 'm', '-', 'w', '-', 'f', ')', ',', 'h', '##t', '##n', ',', 'cad', 'w', '/', 'interventions', 'in', 'past', ',', 's', '/', 'p', 'ns', '##tem', '##i', ',', 'card', '##iom', '##yo', '##pathy', 'with', 'e', '##f', '35', '%', ';', 'pt', 'is', 'also', 'blind', 'and', 'deaf', ';', 'initially', 'admitted', 'to', 'os', '##h', 'with', 'chest', 'pain', 'radiating', 'to', 'shoulders', 'treated', 'with', 'nt', '##g', ',', 'ms', '##o', '##4', '-', 'bumped', 'tr', '##op', '##oni', '##n', 'to', 'for', 'cat', '##h', 'cat', '##h', 'showed', 'right', 'dominant', 'system', 'with', 'diffuse', 'cad', '.', 'lad', 'w', '/', '3', 'sequential', 'ste', '##nts', 'placed', 'in', 'past', 'which', 'were', 'widely', 'patent', ';', 'des', 'placed', 'to', 'lad', 'distal', 'to', 'these', 'ste', '##nts', ';', '50', '%', 'ste', '##nosis', 'at', 'the', 'd', '##1', 'level', 'pro', '##xi', '##mal', 'to', 'the', 'ste', '##nts', 'w', '/', 'o', 'intervention', ';', 'pt', 'was', 'transferred', 'to', '3', 'and', 'continued', 'to', 'have', 'cp', 'overnight', ';', 'pt', 'returned', 'to', 'cat', '##h', 'lab', 'after', 'dial', '##ysis', 'on', ';', 'pc', '##i', 'to', 'd', '##1', 'les', '##ion', 'and', 'des', 'to', 'mid', 'lad', 'les', '##ion', 'complicated', 'by', 'di', '##sse', '##ction', 'of', 'l', '##mc', '##a', 'and', 'cardiac', 'arrest', ';', 'pt', 'received', 'brief', 'cp', '##r', ',', 'int', '##uba', '##ted', ',', 'ste', '##nt', 'to', 'l', '##mc', '##a', 'and', 'transferred', 'to', 'cc', '##u', 'int', '##uba', '##ted', 'on', 'do', '##pa', '##mine', 'gt', '##t', '.', 'cardiac', 'arrest', 'assessment', ':', 'to', '##ler', '##ating', 'ex', '##tub', '##ation', 'and', 'subsequent', 'rapid', 'we', '##an', 'of', 'do', '##pa', '##mine', 'this', 'am', 'continues', 'to', 'have', 'episodes', 'of', 'burning', 'chest', 'pain', '-', 'unable', 'to', 'score', 'secondary', 'to', 'communication', 'difficulty', 'action', ':', 'fen', '##tan', '##yl', '/', 'mid', '##az', '##ola', '##m', 'gt', '##ts', 'd', '/', 'c', 'd', 'and', 'pt', 'rapidly', 'ex', '##tub', '##ated', 'at', '~', '08', '##30', 'to', '70', '%', 'face', 'tent', ';', 'bp', 'improved', 'to', '120', '-', '130', 's', '/', 'immediately', 'upon', 'pt', 'wake', '##ning', 'do', '##pa', '##mine', 'rapidly', 'we', '##ane', '##d', 'from', '5', '##mc', '##gs', '/', 'kg', '/', 'min', 'to', 'off', 'at', '08', '##45', 'pt', 'ec', '##ei', '##ved', 'sl', 'nt', '##g', '3', '##mg', 'x', '##2', 'for', 'cp', 'pt', 'verbal', '##izing', 'pain', 'is', 'gone', ';', 'ec', '##g', 'during', 'episode', 'unchanged', ';', '2', '^', 'n', '##d', 'episode', 'w', '\\\\', 'relieved', 'w', '/', '1', 'sl', 'nt', '##g', 'response', ':', 'oxygen', 'we', '##ane', '##d', 'to', '2', '##l', 'n', '/', 'c', 'with', 'sat', '##s', '100', '%', ',', 'lungs', 'clear', 'to', 'few', 'crack', '##les', 'at', 'bases', ',', 'rr', '14', '-', '18', ';', 'cong', '##ested', 'cough', '-', 'expect', '##ora', '##ting', 'thin', 'd', '##k', 'blood', '-', 'tinged', 'secret', '##ions', '-', 'now', 'clearing', ';', 'ab', '##g', 'with', 'pa', '##o', '##2', 'of', '66', ',', 'n', '/', 'c', 'increased', 'to', '4', '##l', 'w', '/', 'sat', '##s', 'consistently', '100', '%', ',', 'ab', '##g', 'repeat', '44', '/', '35', '/', '98', ';', 'bp', 'remains', 'stable', 'off', 'do', '##pa', '##mine', '105', '-', '120', 's', '/', 'sy', '##sto', '##lic', ';', 'hr', '90', '-', '100', 's', 'sr', '-', 'st', 'w', '/', 'o', 'ec', '##top', '##y', ';', 'added', 'lo', '##press', '##or', '25', '##mg', 'received', 'x', '1', 'and', 'tolerated', 'well', ',', 'li', '##sin', '##op', '##ril', '5', '##mg', 'added', 'at', '1800', 'chest', 'pain', 'responsive', 'to', 'sl', 'nt', '##g', ';', 'tr', '##op', '##oni', '##n', 'level', 'continues', 'to', 'trend', 'down', 'plan', ':', 'monitor', 'vital', 'signs', 'and', 'assess', 'to', '##ler', '##ation', 'to', 'added', 'med', '##s', ';', 'assess', 'pain', 'sl', 'nt', '##g', 'pr', '##n', 'for', 'burning', 'chest', 'pain', ';', 'follow', 'cp', '##k', 's', 'and', 'tr', '##op', '##oni', '##n', 'levels', 'for', 'repeat', 'cp', '.', 'problem', 'potential', 'ineffective', 'communication', 'with', 'patient', 'assessment', ':', 'difficult', 'communication', 'with', 'patient', 'secondary', 'nearly', 'blind', 'and', 'deaf', ';', 'pt', 'communicate', '##s', 'with', 'as', '##l', ';', 'able', 'to', 'verbal', '##ly', 'communicate', 'needs', 'fairly', 'well', 'action', ':', 'as', '##l', 'interpreter', 'visited', ',', 'communicated', 'with', 'patient', ';', 'pt', 'wanted', 'to', 'call', 'girlfriend', ';', 'rn', 'left', 'message', 'on', 'one', 'of', '2', 'phone', 'numbers', 'for', ',', 'attempted', 'other', 'number', '-', 'no', 'answer', ';', 'is', 'also', 'hearing', 'impaired', '-', 'as', '##l', 'interpreter', 'instructed', 'rn', 'for', 'answering', 'service', 'interpretation', 'for', 'response', ':', 'awaiting', 'communication', 'with', ':', 'as', '##l', 'interpreter', '##s', 'will', 'visit', 'daily', 'to', 'keep', 'pt', 'updated', 'on', 'condition', ',', 'plan', 'of', 'care', ';', 'on', '-', 'call', 'interpreter', 'as', 'needed', '.']\n","chunk 125 tokenize start!\n","First sentence tokenized\n","['sic', '##u', 'hp', '##i', ':', 'date', ':', 'hd', '##2', 'pod', '2', 'ab', '##x', ':', 'pp', '##x', ':', 'boots', ',', 'proton', '##ix', 't', '##ld', ':', ',', ',', 'ng', '##t', 'admit', 'w', '##t', ':', '.', 'hp', '##i', ':', '86', 'y', '/', 'o', 'female', 'with', 'history', 'of', 'afi', '##b', 'on', 'co', '##uma', '##din', '.', 'ms', 'was', 'with', 'her', 'son', 'yesterday', 'and', 'fell', 'getting', 'bundles', 'out', 'of', 'her', 'car', '.', 'she', 'hit', 'her', 'head', 'on', 'the', 'pavement', 'and', 'did', 'not', 'have', 'a', 'loss', 'of', 'consciousness', '.', 'she', 'was', 'able', 'to', 'do', 'her', 'normal', 'activities', 'she', 'went', 'to', 'bed', 'last', 'night', 'and', 'her', 'son', 'attempted', 'to', 'ar', '##rous', '##e', 'her', 'at', '2a', '##m', 'for', 'which', 'he', 'stated', '\"', 'she', 'did', 'not', 'fully', 'awake', '\"', 'this', 'morning', 'when', 'his', 'mother', 'did', 'not', 'wake', 'up', 'he', 'found', 'her', 'in', 'her', 'room', 'and', 'was', 'able', 'to', 'minimal', '##ly', 'ar', '##rous', '##e', 'her', '.', 'she', 'was', 'brought', 'by', 'ambulance', 'here', 'found', 'to', 'have', 'sd', '##h', 'with', 'mid', '##line', 'shift', '.', '.', 'all', ':', 'sul', '##fo', '##nami', '##des', '/', 'ep', '##ine', '##ph', '##rine', '/', 'dil', '##tia', '##ze', '##m', '/', 'pl', '##eta', '##l', 'chief', 'complaint', ':', 'pm', '##h', '##x', ':', 'pm', '##h', ':', 'afi', '##b', ',', 'on', 'co', '##uma', '##din', ',', 'd', '##m', ',', 'frequent', 'falls', ',', 'ge', '##rd', 's', '/', 'p', 'ni', '##ssen', ',', 'h', '##x', 'of', 'frequent', 'falls', 'w', '/', 'l', 'ole', '##cre', '##non', 'and', 'radius', 'fx', ',', 'r', 'hume', '##rus', 'fx', '.', 'ps', '##h', ':', 'ni', '##ssen', '.', ':', 'ami', '##oda', '##rone', ',', 'carved', '##ilo', '##l', ',', 'li', '##sin', '##op', '##ril', ',', 'met', '##form', '##in', ',', 'pr', '##ava', '##sta', '##tin', ',', 'jan', '##u', '##via', ',', 'co', '##uma', '##din', 'current', 'medications', ':', 'ami', '##oda', '##rone', 'carved', '##ilo', '##l', 'ch', '##lor', '##he', '##xi', '##dine', 'g', '##lu', '##cona', '##te', '12', '%', 'oral', 'ri', '##nse', 'dex', '##tro', '##se', '50', '%', 'g', '##lu', '##ca', '##gon', 'hydra', '##la', '##zine', 'insulin', 'lab', '##eta', '##lo', '##l', 'li', '##sin', '##op', '##ril', 'magnesium', 'sulfate', 'pan', '##top', '##raz', '##ole', 'ph', '##yt', '##ona', '##dion', '##e', 'ph', '##en', '##yt', '##oin', 'pr', '##ava', '##sta', '##tin', '24', 'hour', 'events', ':', 'int', '##uba', '##tion', '-', 'at', '02', ':', '00', 'pm', 'invasive', 'ventilation', '-', 'start', '02', ':', '00', 'pm', 'arterial', 'line', '-', 'start', '02', ':', '01', 'pm', 'head', 'mri', ':', 'acute', 'multi', '##vas', '##cular', 'territorial', 'in', '##far', '##cts', ',', 'involving', 'the', 'left', 'ac', '##a', ',', 'pc', '##a', 'and', 'mca', 'territories', 'and', 'right', 'pc', '##a', 'and', 'ac', '##a', 'territories', 'all', '##er', '##gies', ':', 'sul', '##fo', '##nami', '##des', 'hem', '##at', '##uria', ';', 'ep', '##ine', '##ph', '##rine', 'seizure', ';', 'dil', '##tia', '##ze', '##m', 'tremor', ';', 'pl', '##eta', '##l', '(', 'oral', ')', '(', 'ci', '##los', '##ta', '##zo', '##l', ')', 'dia', '##rr', '##hea', ';', 'last', 'dose', 'of', 'antibiotics', ':', 'ce', '##ft', '##ria', '##xon', '##e', '-', '11', ':', '59', 'am', 'in', '##fusion', '##s', ':', 'other', 'ic', '##u', 'medications', ':', 'pan', '##top', '##raz', '##ole', '(', 'proton', '##ix', ')', '-', '08', ':', '00', 'pm', 'dil', '##ant', '##in', '-', '10', ':', '00', 'pm', 'other', 'medications', ':', 'flows', '##hee', '##t', 'data', 'as', 'of', '02', ':', '39', 'am', 'vital', 'signs', 'hem', '##od', '##yna', '##mic', 'monitoring', 'fluid', 'balance', '24', 'hours', 'since', 'a', '.', 'm', '.', 't', '##max', ':', '3', 'c', '(', '1', 't', 'current', ':', '7', 'c', '(', '98', 'hr', ':', '59', '(', '48', '-', '59', ')', 'bp', '##m', 'bp', ':', '118', '/', '34', '(', '61', ')', '{', '105', '/', '23', '(', '54', ')', '-', '160', '/', '53', '(', '85', ')', '}', 'mm', '##hg', 'rr', ':', '16', '(', '13', '-', '20', ')', 'ins', '##p', '/', 'min', 'sp', '##o', '##2', ':', '99', '%', 'heart', 'rhythm', ':', 'sr', '(', 'sin', '##us', 'rhythm', ')', 'total', 'in', ':', '3', ',', '460', 'ml', '138', 'ml', 'po', ':', 'tube', 'feeding', ':', 'iv', 'fluid', ':', '3', ',', '460', 'ml', '138', 'ml', 'blood', 'products', ':', 'total', 'out', ':', '375', 'ml', '43', 'ml', 'urine', ':', '350', 'ml', '43', 'ml', 'ng', ':', 'stool', ':', 'drains', ':', '25', 'ml', 'balance', ':', '3', ',', '08', '##5', 'ml', '95', 'ml', 'respiratory', 'support', 'o', '##2', 'delivery', 'device', ':', 'end', '##ot', '##rac', '##hea', '##l', 'tube', 'vent', '##ila', '##tor', 'mode', ':', 'cp', '##ap', '/', 'ps', '##v', 'vt', '(', 'set', ')', ':', '500', '(', '500', '-', '500', ')', 'ml', 'vt', '(', 'spontaneous', ')', ':', '39', '##2', '(', '337', '-', '39', '##3', ')', 'ml', 'ps', ':', '10', 'cm', '##h', '##2', '##o', 'rr', '(', 'set', ')', ':', '14', 'rr', '(', 'spontaneous', ')', ':', '17', 'pee', '##p', ':', '5', 'cm', '##h', '##2', '##o', 'fi', '##o', '##2', ':', '40', '%', 'rs', '##bi', 'def', '##erre', '##d', ':', 'no', 'sp', '##on', 'res', '##p', 'pip', ':', '15', 'cm', '##h', '##2', '##o', 'plateau', ':', '18', 'cm', '##h', '##2', '##o', 'sp', '##o', '##2', ':', '99', '%', 'ab', '##g', ':', '/', '/', '/', '23', '/', 've', ':', '7', 'l', '/', 'min', 'physical', 'examination', 'general', 'appearance', ':', 'no', 'acute', 'distress', 'hee', '##nt', ':', 'per', '##rl', 'cardiovascular', ':', '(', 'rhythm', ':', 'regular', ')', 'respiratory', '/', 'chest', ':', '(', 'expansion', ':', 'symmetric', ')', ',', '(', 'breath', 'sounds', ':', 'ct', '##a', 'bilateral', ':', ')', 'abdominal', ':', 'soft', ',', 'non', '-', 'di', '##sten', '##ded', ',', 'non', '-', 'tender', ',', 'bow', '##el', 'sounds', 'present', 'left', 'ex', '##tre', '##mit', '##ies', ':', '(', 'ed', '##ema', ':', 'trace', ')', 'right', 'ex', '##tre', '##mit', '##ies', ':', '(', 'ed', '##ema', ':', 'trace', ')', 'skin', ':', '(', 'inc', '##ision', ':', 'clean', '/', 'dry', '/', 'intact', ')', 'ne', '##uro', '##logic', ':', 'only', 'withdrawing', 'rue', 'and', 'r', '##le', 'to', 'pain', 'labs', '/', 'radio', '##logy', '290', 'k', '/', 'ul', '9', 'g', '/', 'dl', '182', 'mg', '/', 'dl', '9', 'mg', '/', 'dl', '23', 'me', '##q', '/', 'l', '9', 'me', '##q', '/', 'l', '18', 'mg', '/', 'dl', '109', 'me', '##q', '/', 'l', '142', 'me', '##q', '/', 'l', '9', '%', '8', 'k', '/', 'ul', '12', ':', '35', 'pm', '02', ':', '40', 'pm', '03', ':', '00', 'am', '12', ':', '52', 'am', 'wb', '##c', '0', '7', '8', 'hc', '##t', '38', '5', '2', '9', 'pl', '##t', 'cr', '##ea', '##tin', '##ine', '9', '9', 'tc', '##o', '##2', '22', 'glucose', '286', '156', '182', 'other', 'labs', ':', 'pt', '/', 'pt', '##t', '/', 'in', '##r', ':', '8', '/', '1', '/', '2', ',', 'fi', '##bri', '##no', '##gen', ':', '307', 'mg', '/', 'dl', ',', 'lac', '##tic', 'acid', ':', '1', 'mm', '##ol', '/', 'l', ',', 'ca', ':', '6', 'mg', '/', 'dl', ',', 'mg', ':', '7', 'mg', '/', 'dl', ',', 'po', '##4', ':', '0', 'mg', '/', 'dl', 'assessment', 'and', 'plan', 'sub', '##dur', '##al', 'hem', '##or', '##rh', '##age', '(', 'sd', '##h', ')', 'assessment', 'and', 'plan', ':', '87', 'yo', 'woman', 'with', 'afi', '##b', 'on', 'co', '##uma', '##din', 'with', 'sd', '##h', 'following', 'fall', 'on', 'sd', '##h', 'w', '/', '17', '##mm', 'mid', '##line', 'shift', 'and', 'slight', 'un', '##cal', 'her', '##nia', '##tion', 'and', 'mri', 'with', 'multiple', 'acute', 'in', '##far', '##cts', 'ne', '##uro', '##logic', ':', 'not', 'responsive', 'with', 'ex', '##tens', '##or', 'post', '##uring', 'in', 'bilateral', 'u', '##e', 'with', 'no', '##xious', 'stimuli', '.', 'slight', 're', '##tra', '##ction', 'from', 'pinch', 'in', 'le', ',', 'l', '>', 'r', '.', 'off', 'se', '##dation', '.', 'q', '##1', '##h', 'ne', '##uro', '##che', '##cks', ',', 'continue', 'ph', '##en', '##yt', '##oin', 'for', 'seizure', 'prop', '##hyl', '##ax', '##is', '.', 'drainage', 'cat', '##het', '##er', 'removed', 'by', 'ne', '##urs', '##urg', '.', 'mri', 'from', 'shows', 'acute', 'multi', '##vas', '##cular', 'territorial', 'in', '##far', '##cts', '.', 'goals', 'for', 'long', 'term', 'case', 'to', 'be', 'addressed', 'with', 'the', 'family', 'in', 'light', 'of', 'grim', 'pro', '##gno', '##sis', '.', 'cardiovascular', ':', 'hd', 'stable', '.', 'home', 'medication', 'to', 'be', 'started', 'through', 'do', '##bo', '##ff', '.', 'pulmonary', ':', 'int', '##uba', '##ted', ',', 'on', 'ps', '##v', '5', '/', '10', 'due', 'to', 'minimal', 'cough', 'reflex', ',', 'will', 'need', 'tr', '##ach', 'for', 'long', 'term', 'management', '.', 'gas', '##tro', '##int', '##estinal', '/', 'abdomen', ':', 'do', '##bo', '##ff', 'placed', ',', 'no', 'active', 'issues', 'nutrition', ':', 'tube', 'feeding', ',', 'np', '##o', 'for', 'now', '.', 'do', '##bo', '##ff', 'placed', '.', 'will', 'start', 't', '##f', 'renal', ':', 'foley', ',', 'drop', 'in', 'u', '##op', 'with', 'up', '##tre', '##nding', 'serum', 'sodium', '.', 'plan', 'to', 'continue', 'hydra', '##tion', 'with', 'iso', '##tonic', 'fluids', 'while', 'monitoring', 'labs', '.', 'hem', '##ato', '##logy', ':', 'hc', '##t', 'stable', ',', 'will', 'continue', 'to', 'trend', 'hc', '##t', '.', 'plate', '##lets', 'stable', 'end', '##oc', '##rine', ':', 'ri', '##ss', ',', 'ri', '##ss', ',', 'blood', 'glucose', 'better', 'controlled', 'after', 'last', 'adjustment', 'for', 'goal', 'level', '<', '150', '##mg', 'infectious', 'disease', ':', 'mild', 'le', '##uk', '##oc', '##yt', '##osis', ',', 'resolving', '.', 'possibly', 'due', 'to', 'the', 'surgical', 'stress', '.', 'lines', '/', 'tubes', '/', 'drains', ':', 'foley', ',', 'do', '##bh', '##off', ',', 'et', '##t', 'wounds', ':', 'dry', 'dressing', '##s', 'imaging', ':', 'c', '##x', '##r', 'today', 'fluids', ':', 'ns', ',', '75', 'cc', '/', 'hr', 'consult', '##s', ':', 'ne', '##uro', 'surgery', 'billing', 'diagnosis', ':', 'cv', '##a', 'ic', '##u', 'care', 'nutrition', ':', 'g', '##ly', '##ce', '##mic', 'control', ':', 'regular', 'insulin', 'sliding', 'scale', 'lines', ':', '18', 'gauge', '-', '02', ':', '00', 'pm', 'arterial', 'line', '-', '02', ':', '01', 'pm', '16', 'gauge', '-', '02', ':', '01', 'pm', 'prop', '##hyl', '##ax', '##is', ':', 'd', '##v', '##t', ':', 'boots', 'stress', 'ul', '##cer', ':', 'pp', '##i', 'va', '##p', 'bundle', ':', 'ho', '##b', 'elevation', ',', 'mouth', 'care', ',', 'daily', 'wake', 'up', ',', 'rs', '##bi', 'comments', ':', 'communication', ':', 'comments', ':', 'code', 'status', ':', 'full', 'code', 'disposition', ':', 'ic', '##u', 'total', 'time', 'spent', ':', '32', 'minutes']\n","chunk 126 tokenize start!\n","First sentence tokenized\n","['chief', 'complaint', ':', 'chief', 'complaint', ':', 'weakness', '&', 'confusion', 'reason', 'for', 'mic', '##u', 'transfer', ':', 'continued', 'altered', 'mental', 'status', ',', 'respiratory', 'failure', 'hp', '##i', ':', 'mr', '.', 'is', 'a', '63', 'year', 'old', 'gentleman', 'admitted', 'to', 'the', 'ne', '##uro', 'service', 'for', 'weakness', 'and', 'confusion', '.', 'please', 'see', 'doctor', 'note', 'for', 'full', 'hp', '##i', '.', 'in', 'brief', ',', 'per', 'the', 'patient', \"'\", 's', 'son', ',', 'the', 'patient', 'developed', 'right', 'facial', 'pal', '##sy', '5', 'weeks', 'prior', 'to', 'admission', 'and', 'was', 'diagnosed', 'as', 'bell', \"'\", 's', 'pal', '##sy', '.', 'he', 'also', 'developed', 'back', 'pain', 'and', 'was', 'given', 'anal', '##ges', '##ia', '.', 'mri', 'brain', 'was', 'ordered', 'with', 'demons', '##tated', 'a', 'possible', 'pont', '##ine', 'acute', 'in', '##far', '##ct', 'and', 'mid', '##bra', '##in', 'mass', '.', 'he', 'then', 'developed', 'r', 'sided', 'progressive', 'arm', 'and', 'leg', 'numb', '##ness', 'and', 'weakness', 'as', 'well', 'as', 'confusion', 'at', 'home', '.', 'there', 'is', 'also', 'report', 'of', 'previous', 'bulls', 'eye', 'rash', '.', '.', 'the', 'patient', 'was', 'admitted', 'to', 'the', 'sic', '##u', '/', 'ne', '##uro', 'ic', '##u', '.', 'he', 'was', 'diagnosed', 'with', 'probable', 'l', '##yme', 'en', '##ce', '##pha', '##lit', '##is', 'based', 'on', 'mri', ',', 'cs', '##f', 'l', '##ym', '##ph', '##oc', '##ytic', 'pl', '##eo', '##cy', '##tosis', ',', 'positive', 'serum', 'ser', '##ology', 'with', 'e', '##qui', '##vo', '##cal', 'cs', '##f', 'ser', '##ology', '.', 'started', 'on', 'ce', '##ft', '##ria', '##xon', '##e', '.', 'course', 'in', 'the', 'sic', '##u', 'has', 'also', 'included', 'failed', 'ex', '##tub', '##ation', 'with', 'subsequent', 'tr', '##ach', 'and', 'peg', 'placement', 'on', ',', 'continued', 'vent', 'dependence', ',', 'difficulties', 'with', 'se', '##dation', 'with', 'multiple', 'medication', 'trials', 'now', 'on', 'met', '##had', '##one', ',', 'intermittent', 'accelerated', 'id', '##io', '##vent', '##ric', '##ular', 'rhythm', 'with', 'cards', 'consult', '(', 'not', 'thought', 'to', 'represent', 'l', '##yme', 'card', '##itis', ')', ',', 'right', 'corn', '##eal', 'ul', '##cer', 's', '/', 'p', 'su', '##turing', 'of', 'his', 'lateral', 'eye', '##lid', 'on', 'complicated', 'by', 'some', 'post', '##op', 'h', '##yp', '##ote', '##ns', '##ion', '.', 'newer', 'issues', 'include', 'fever', 'spike', 'in', 'the', 'last', '24', 'hours', 'and', 'hyper', '##nat', '##rem', '##ia', '.', '.', 'on', 'transfer', 'to', 'the', 'mic', '##u', 'team', ',', 'patient', 'being', 'we', '##ane', '##d', 'from', 'ps', '##v', 'to', 't', '##m', '.', 'interactive', 'and', 'follows', 'commands', 'though', 'sleepy', '.', 'seems', 'to', 'deny', 'current', 'pain', 'or', 'short', '##ness', 'of', 'breath', '.', 'patient', 'admitted', 'from', ':', 'sic', '##u', 'history', 'obtained', 'from', 'medical', 'records', 'all', '##er', '##gies', ':', 'at', '##iva', '##n', '(', 'oral', ')', '(', 'lo', '##raz', '##ep', '##am', ')', 'confusion', '/', 'del', '##ir', 'ib', '##up', '##ro', '##fen', 'unknown', ';', 'last', 'dose', 'of', 'antibiotics', ':', 'van', '##com', '##y', '##cin', '-', '07', ':', '46', 'am', 'piper', '##ac', '##ill', '##in', '/', 'ta', '##zo', '##ba', '##cta', '##m', '(', 'z', '##os', '##yn', ')', '-', '07', ':', '47', 'am', 'ce', '##ft', '##ria', '##xon', '##e', '-', '06', ':', '00', 'pm', 'in', '##fusion', '##s', ':', 'other', 'ic', '##u', 'medications', ':', 'fa', '##mot', '##idi', '##ne', '(', 'pep', '##ci', '##d', ')', '-', '04', ':', '11', 'am', 'he', '##par', '##in', 'sodium', '(', 'prop', '##hyl', '##ax', '##is', ')', '-', '04', ':', '11', 'am', 'halo', '##per', '##ido', '##l', '(', 'hal', '##do', '##l', ')', '-', '11', ':', '25', 'am', 'other', 'medications', ':', 'transfer', 'medications', ':', 'ce', '##ft', '##ria', '##xon', '##e', '2', 'gm', 'iv', 'q', '##12', '##h', 'ace', '##ty', '##lc', '##yst', '##ein', '##e', '20', '%', '3', '-', '5', 'ml', 'ne', '##b', 'q', '##6', '##h', ':', 'pr', '##n', 'mu', '##cous', 'plug', 'ip', '##rat', '##rop', '##ium', 'bro', '##mide', 'md', '##i', '4', 'puff', 'i', '##h', 'qi', '##d', 'al', '##bu', '##terol', '08', '##3', '%', 'ne', '##b', 'sol', '##n', '1', 'ne', '##b', 'i', '##h', 'q', '##6', '##h', ':', 'pr', '##n', 'sob', 'al', '##bu', '##terol', 'in', '##hale', '##r', '4', 'puff', 'i', '##h', 'q', '##6', '##h', 'q', '##var', '*', 'n', '##f', '*', '80', 'mc', '##g', '/', 'act', '##uation', 'in', '##hala', '##tion', 'air', '##way', 'in', '##fl', '##ama', '##tion', 'ch', '##lor', '##he', '##xi', '##dine', 'g', '##lu', '##cona', '##te', '12', '%', 'oral', 'ri', '##nse', '15', 'ml', 'oral', 'ti', '##ot', '##rop', '##ium', 'bro', '##mide', '1', 'cap', 'i', '##h', 'daily', 'order', 'date', ':', '@', 'gu', '##ai', '##fen', '##es', '##in', 'ml', 'po', '/', 'ng', 'q', '##6', '##h', ':', 'pr', '##n', 'met', '##op', '##rol', '##ol', 'tar', '##tra', '##te', '75', 'mg', 'po', 'ti', '##d', 'lab', '##eta', '##lo', '##l', '10', 'mg', 'iv', 'q', '##2', '##h', ':', 'pr', '##n', 'sb', '##p', '>', '160', 'cl', '##oni', '##dine', '1', 'mg', 'ng', 'ti', '##d', 'hydra', '##la', '##zine', '10', 'mg', 'iv', 'q', '##6', '##h', ':', 'pr', '##n', 'h', '##t', '##n', 'met', '##had', '##one', '10', 'mg', 'po', '/', 'ng', 'ti', '##d', 'he', '##par', '##in', '5000', 'unit', 'sc', 'ti', '##d', 'ace', '##tam', '##ino', '##ph', '##en', '(', 'liquid', ')', '650', 'mg', 'po', 'q', '##4', '##h', ':', 'pr', '##n', 'pain', '/', 'fever', 'insulin', 'sc', 'sliding', 'scale', 'bis', '##aco', '##dy', '##l', '10', 'mg', 'pr', 'daily', ':', 'pr', '##n', 'con', '##sti', '##pati', '##on', 'multi', '##vita', '##mins', '1', 'tab', 'po', 'daily', 'calcium', 'g', '##lu', '##cona', '##te', 'iv', 'sliding', 'scale', 'potassium', 'chloride', 'iv', 'sliding', 'scale', 'sen', '##na', '1', 'tab', 'po', 'bid', ':', 'pr', '##n', 'con', '##sti', '##pati', '##on', 'th', '##iam', '##ine', '100', 'mg', 'po', 'daily', 'doc', '##usa', '##te', 'sodium', '100', 'mg', 'po', 'bid', 'fa', '##mot', '##idi', '##ne', '20', 'mg', 'po', 'bid', 'artificial', 'tear', 'o', '##int', '##ment', '1', 'app', '##l', 'right', 'eye', 'pr', '##n', 'dry', 'eye', 'ba', '##cit', '##rac', '##in', '/', 'poly', '##my', '##xin', 'b', 'sulfate', 'op', '##ht', '.', 'o', '##int', '1', 'app', '##l', 'both', 'eyes', 'q', '##6', '##h', 'vi', '##gam', '##ox', '*', 'n', '##f', '*', '1', 'drop', 'o', '##d', 'q', '##2', '##h', 'exposure', 'f', '##olic', 'acid', '1', 'mg', 'po', 'daily', '.', 'home', 'medications', ':', '-', 'ox', '##y', '##co', '##don', '##e', '5', '/', '325', 'mg', 'po', 'q', '4', '-', '6', '##h', 'pr', '##n', 'pain', '-', 'hydro', '##mo', '##rp', '##hone', '2', 'mg', 'po', 'q', '##4', '##h', 'pr', '##n', 'pain', '-', 'cy', '##cl', '##obe', '##nza', '##pr', '##ine', '10', 'mg', 'po', 'ti', '##d', 'pr', '##n', 'pain', '-', 'lo', '##raz', '##ep', '##am', '5', 'mg', 'po', 'q', '12', '##h', '-', 'ne', '##uron', '##tin', '300', 'mg', 'po', 'ti', '##d', '-', 'hc', '##tz', '25', 'mg', 'po', 'daily', '-', 'the', '##rate', '##ars', '-', 'mv', '##i', 'po', 'daily', 'past', 'medical', 'history', ':', 'family', 'history', ':', 'social', 'history', ':', '-', 'h', '##t', '##n', '-', 'it', '##p', '-', 'smoking', '-', '?', 'et', '##oh', 'abuse', 'mother', 'is', 'still', 'alive', ';', 'father', 'with', 'alcohol', 'dependence', 'occupation', ':', 'drugs', ':', 'tobacco', ':', 'alcohol', ':', 'other', ':', 'lives', 'with', 'his', 'wife', '.', 'son', 'is', 'his', 'father', \"'\", 's', 'hc', '##p', ',', 'and', 'his', 'number', 'is', ':', '35', 'y', 'pack', 'history', 'of', 'smoking', '6', '-', '12', 'beers', 'per', 'night', 'stopped', 'drinking', 'no', 'recreational', 'drugs', 'retired', 'general', 'manager', 'for', 'previously', 'highly', 'functioning', 'review', 'of', 'systems', ':', 'flows', '##hee', '##t', 'data', 'as', 'of', '05', ':', '28', 'pm', 'vital', 'signs', 'hem', '##od', '##yna', '##mic', 'monitoring', 'fluid', 'balance', '24', 'hours', 'since', '12', 'am', 't', '##max', ':', '9', 'c', '(', '3', 'tc', '##urrent', ':', '8', 'c', '(', '2', 'hr', ':', '76', '(', '69', '-', '106', ')', 'bp', '##m', 'bp', ':', '108', '/', '71', '(', '79', ')', '{', '93', '/', '56', '(', '57', ')', '-', '149', '/', '87', '(', '94', ')', '}', 'mm', '##hg', 'rr', ':', '9', '(', '8', '-', '23', ')', 'ins', '##p', '/', 'min', 'sp', '##o', '##2', ':', '100', '%', 'heart', 'rhythm', ':', 'sr', '(', 'sin', '##us', 'rhythm', ')', 'w', '##gt', '(', 'current', ')', ':', '9', 'kg', '(', 'admission', ')', ':', '1', 'kg', 'height', ':', '70', 'inch', 'total', 'in', ':', '3', ',', '09', '##8', 'ml', '3', ',', '91', '##9', 'ml', 'po', ':', 't', '##f', ':', '1', ',', '247', 'ml', '96', '##2', 'ml', 'iv', '##f', ':', '1', ',', '55', '##1', 'ml', '2', ',', '08', '##7', 'ml', 'blood', 'products', ':', 'total', 'out', ':', '1', ',', '141', 'ml', '78', '##4', 'ml', 'urine', ':', '1', ',', '141', 'ml', '78', '##4', 'ml', 'ng', ':', 'stool', ':', 'drains', ':', 'balance', ':', '1', ',', '95', '##7', 'ml', '3', ',', '135', 'ml', 'respiratory', 'o', '##2', 'delivery', 'device', ':', 'tr', '##ache', '##ost', '##omy', 'tube', 'vent', '##ila', '##tor', 'mode', ':', 'cp', '##ap', '/', 'ps', '##v', 'vt', '(', 'spontaneous', ')', ':', '530', '(', '530', '-', '710', ')', 'ml', 'ps', ':', '5', 'cm', '##h', '##2', '##o', 'rr', '(', 'spontaneous', ')', ':', '15', 'pee', '##p', ':', '5', 'cm', '##h', '##2', '##o', 'fi', '##o', '##2', ':', '100', '%', 'rs', '##bi', 'def', '##erre', '##d', ':', 'pee', '##p', '>', '10', 'pip', ':', '14', 'cm', '##h', '##2', '##o', 'sp', '##o', '##2', ':', '100', '%', 'ab', '##g', ':', '/', '/', '/', '38', '/', 've', ':', '7', 'l', '/', 'min', 'physical', 'examination', 'general', ':', 'alert', 'though', 'sleepy', ',', 'follows', 'most', 'commands', ',', 'does', 'not', 'appear', 'agitated', 'currently', '.', 'hee', '##nt', ':', 'r', 'eye', 'with', 'patch', ',', 'lateral', '##ly', 'su', '##ture', '##d', 'closed', ',', 'l', 'pupil', 'reactive', '3', '-', '>', 'sc', '##ler', '##a', 'an', '##ic', '##ter', '##ic', ',', 'mm', 'slightly', 'dry', ',', 'oro', '##pha', '##ryn', '##x', 'clear', 'neck', ':', 'tr', '##ache', '##d', 'on', 'vent', ',', 'su', '##pp', '##le', ',', 'j', '##v', '##p', 'not', 'elevated', ',', 'no', 'lad', 'lungs', ':', 'r', '##hon', '##cho', '##rous', 'bilateral', '##ly', '(', 'l', '>', 'r', ')', 'cv', ':', 'regular', 'rate', 'and', 'rhythm', ',', 'normal', 's', '##1', '+', 's', '##2', ',', 'no', 'murmurs', ',', 'rubs', ',', 'gallo', '##ps', 'abdomen', ':', 'peg', 'site', 'benign', '.', 'soft', ',', 'non', '-', 'tender', ',', 'non', '-', 'di', '##sten', '##ded', ',', 'bow', '##el', 'sounds', 'present', ',', 'no', 'rebound', 'tenderness', 'or', 'guarding', ',', 'no', 'organ', '##ome', '##gal', '##y', 'ex', '##t', ':', 'warm', ',', 'well', 'per', '##fus', '##ed', ',', '2', '+', 'pulses', ',', 'no', 'club', '##bing', ',', 'cy', '##ano', '##sis', 'or', 'ed', '##ema', 'ne', '##uro', ':', 'alert', 'though', 'somewhat', 'sleepy', '.', 'follows', 'commands', '.', 'r', 'facial', 'dr', '##oop', '(', 'central', 'with', 'reasonable', 'ability', 'to', 'raise', 'eyebrows', ')', '.', 'follows', 'simple', 'commands', ',', 'but', 'some', 'difficulty', 'following', 'commands', 'for', 'strength', 'exam', ',', 'but', '5', '/', '5', 'strength', 'in', 'lu', '##e', 'elbow', 'flex', '##ors', '/', 'ex', '##tens', '##ors', ',', 'in', 'rue', 'elbow', 'flex', '##ors', 'and', 'ex', '##tens', '##ors', ',', 'difficulty', 'with', 'intrinsic', 'hand', 'muscles', '.', 'can', 'lift', 'both', 'legs', 'off', 'bed', 'with', '4', '+', '/', '5', 'strength', 'bilateral', '##ly', ',', 'll', '##e', 'with', '5', '/', '5', 'do', '##rs', '##i', 'and', 'plant', '##ar', '##fle', '##x', '##ors', 'and', 'r', '##le', 'with', '4', '/', '5', 'do', '##rs', '##i', 'and', 'plant', '##ar', '##fle', '##x', '##ors', '.', 'unable', 'to', 'assess', 'sensation', '.', 'labs', '/', 'radio', '##logy', '38', '##7', 'k', '/', 'ul', '9', 'g', '/', 'dl', '121', 'mg', '/', 'dl', '5', 'mg', '/', 'dl', '22', 'mg', '/', 'dl', '38', 'me', '##q', '/', 'l', '114', 'me', '##q', '/', 'l', '8', 'me', '##q', '/', 'l', '156', 'me', '##q', '/', 'l', '7', '%', '2', 'k', '/', 'ul', '2', ':', '33', 'a1', '##1', '/', '4', '/', '11', ':', '09', 'pm', '10', ':', '20', 'p', '##11', '/', '5', '/', '03', ':', '27', 'am', '1', ':', '20', 'p', '##11', '/', '5', '/', '07', ':', '16', 'am', '11', ':', '50', 'p', '##11', '/', '5', '/', '03', ':', '30', 'pm', '1', ':', '20', 'a1', '##1', '/', '6', '/', '02', ':', '26', 'am', '7', ':', '20', 'p', '##11', '/', '7', '/', '01', ':', '54', 'am', '1', '/', '/', '11', '/', '00', '##6', '1', ':', '23', 'p', '##11', '/', '8', '/', '02', ':', '11', 'am', '1', ':', '20', 'p', '##11', '/', '8', '/', '07', ':', '27', 'am', '11', ':', '20', 'p', '##11', '/', '9', '/', '02', ':', '49', 'am', '4', ':', '20', 'p', '##11', '/', '10', '/', '02', ':', '31', 'am', 'wb', '##c', '8', '4', '1', '2', '5', '2', 'hc', '##t', '3', '3', '1', '0', '1', '7', 'pl', '##t', '297', '39', '##1', '41', '##9', '39', '##3', '44', '##8', '38', '##7', 'cr', '5', '5', '4', '6', '7', '6', '5', 'tr', '##op', '##t', '<', '01', '<', '01', 'tc', '##0', '##2', '36', 'glucose', '113', '125', '135', '127', '161', '142', '121', 'other', 'labs', ':', 'pt', '/', 'pt', '##t', '/', 'in', '##r', ':', '0', '/', '4', '/', '1', ',', 'ck', '/', 'ck', '##mb', '/', 'tr', '##op', '##oni', '##n', '-', 't', ':', '30', '/', '/', '<', '01', ',', 'alt', '/', 'as', '##t', ':', '55', '/', '45', ',', 'al', '##k', 'ph', '##os', '/', 't', 'bi', '##li', ':', '159', '/', '6', ',', 'amy', '##lase', '/', 'lip', '##ase', ':', '74', '/', '21', ',', 'differential', '-', 'ne', '##uts', ':', '9', '%', ',', 'band', ':', '0', '%', ',', 'l', '##ym', '##ph', ':', '7', '%', ',', 'mono', ':', '5', '%', ',', 'e', '##os', ':', '7', '%', ',', 'lac', '##tic', 'acid', ':', '7', 'mm', '##ol', '/', 'l', ',', 'ld', '##h', ':', '172', 'i', '##u', '/', 'l', ',', 'ca', '+', '+', ':', '9', 'mg', '/', 'dl', ',', 'mg', '+', '+', ':', '8', 'mg', '/', 'dl', ',', 'po', '##4', ':', '6', 'mg', '/', 'dl', 'fluid', 'analysis', '/', 'other', 'labs', ':', 'w', '##n', '##v', 'ser', '##ology', 'negative', 'cs', '##f', ':', 'wb', '##c', '45', 'and', '200', '(', 'l', '##ym', '##ph', ')', ',', 'rb', '##c', '145', '##0', 'and', '3', ',', 'protein', '246', ',', 'g', '##lu', '##c', '42', '.', '.', '.', '.', '.', 'e', '##qui', '##vo', '##cal', 'l', '##yme', '.', '.', '.', '.', '.', 'ne', '##g', 'v', '##dr', '##l', ',', 'h', '##h', '##v', '##6', ',', 'lister', '##ia', 'ab', ',', 'hs', '##v', ',', 'enter', '##ov', '##irus', 'cs', '##f', ':', 'wb', '##c', '195', 'and', '10', ',', 'rb', '##c', '55', 'and', '7', ',', 'protein', '73', ',', 'g', '##lu', '##c', '.', '.', '.', '.', '.', 'l', '##yme', 'pending', 'imaging', ':', 'c', '##x', '##r', ':', 'as', 'compared', 'to', 'the', 'previous', 'examination', ',', 'the', 'tr', '##ache', '##ost', '##omy', 'tube', 'is', 'in', 'unchanged', 'position', '.', 'the', 'lung', 'volumes', 'show', 'slightly', 'improved', 'ventilation', '.', 'however', ',', 'a', 'partial', 'left', 'lower', 'lobe', 'ate', '##le', '##cta', '##sis', 'is', 'newly', 'appeared', '.', 'there', 'is', 'mild', 'blunt', '##ing', 'of', 'the', 'left', 'cost', '##op', '##hre', '##nic', 'sin', '##us', ',', 'so', 'that', 'a', 'small', 'left', 'pl', '##eur', '##al', 'e', '##ff', '##usion', 'cannot', 'be', 'excluded', '.', 'normal', 'size', 'of', 'the', 'cardiac', 'silhouette', '.', 'no', 'evidence', 'of', 'pulmonary', 'ed', '##ema', '.', 'no', 'p', '##ne', '##um', '##otho', '##ra', '##x', '.', '.', 'tt', '##e', ':', 'the', 'left', 'atrium', 'is', 'mildly', 'dil', '##ated', '.', 'mild', 'symmetric', 'left', 'vent', '##ric', '##ular', 'hyper', '##tro', '##phy', 'and', 'normal', 'global', 'sy', '##sto', '##lic', 'function', '(', 'l', '##ve', '##f', '>', '55', '%', ')', '.', 'focal', 'wall', 'motion', 'abnormal', '##ity', 'cannot', 'be', 'fully', 'excluded', '.', 'the', 'ao', '##rti', '##c', 'root', 'is', 'mildly', 'dil', '##ated', 'at', 'the', 'sin', '##us', 'level', '.', 'trace', 'ao', '##rti', '##c', 'reg', '##urg', '##itation', 'is', 'seen', '.', 'the', 'mit', '##ral', 'valve', 'appears', 'structurally', 'normal', 'with', 'trivial', 'mit', '##ral', 'reg', '##urg', '##itation', '.', '.', 'mri', 'head', ':', 'abnormal', 'cr', '##anial', 'nerve', 'enhancement', 'most', 'likely', 'secondary', 'to', 'the', 'patient', \"'\", 's', 'diagnosis', 'of', 'l', '##yme', 'disease', '.', 'abnormal', 'signal', 'surrounding', 'the', 'obe', '##x', 'at', 'the', 'ce', '##r', '##vic', '##ome', '##du', '##llary', 'junction', 'may', 'also', 'relate', 'to', 'the', 'patient', \"'\", 's', 'l', '##yme', 'disease', 'but', 'is', 'of', 'unclear', 'et', '##iology', '.', 'thin', 'section', 'sa', '##git', '##tal', 't', '##2', 'weighted', 'images', 'may', 'be', 'useful', 'in', 'further', 'evaluation', '.', '.', 'ct', 'torso', ':', 'large', 'left', 'lower', 'lobe', 'ate', '##le', '##cta', '##sis', '.', 'an', 'ob', '##st', '##ru', '##ctive', 'end', '##ob', '##ron', '##chia', '##l', 'les', '##ion', 'cannot', 'be', 'excluded', '.', 'other', 'et', '##iol', '##og', '##ies', 'would', 'include', 'mu', '##cous', 'plug', '##ging', '.', 'gas', '##tric', ',', 'cardiac', 'and', 'fund', '##us', 'mural', 'thick', '##ening', 'of', 'unclear', 'et', '##iology', '.', 'differential', 'considerations', 'include', 'inflammatory', '/', 'neo', '##pl', '##astic', 'in', '##filtration', '.', 'further', 'evaluation', 'with', 'end', '##os', '##co', '##py', 'may', 'be', 'considered', '.', 'he', '##pati', '##c', 'ste', '##ato', '##sis', '.', 'sp', '##len', '##ic', 'low', 'at', '##ten', '##uation', 'lesions', ',', 'not', 'seen', 'before', '.', 'these', 'could', 'represent', 'sp', '##len', '##ic', 'in', '##far', '##cts', '.', 'in', 'the', 'current', 'clinical', 'setting', 'can', 'not', 'exclude', 'an', 'infectious', 'component', '.', 'moderate', 'hi', '##atal', 'her', '##nia', '.', 'micro', '##biology', ':', ':', 'blood', 'ng', '##t', '##d', ':', 'mini', 'bal', 'pending', ',', 'gs', 'c', '/', 'w', 'op', 'flora', ':', 'flu', 'negative', ':', 'blood', 'cultures', 'negative', ':', 'urine', 'negative', ':', 'cs', '##f', 'culture', 'negative', ':', 'hiv', 'negative', ':', 'cs', '##f', 'negative', ':', 'l', '##yme', 'ser', '##ology', 'positive', 'by', 'western', 'b', '##lot', '-', 'i', '##gm', 'po', '##s', ',', 'i', '##gg', 'ne', '##g', 'ec', '##g', ':', 'ec', '##g', ':', 'sin', '##us', 'rhythm', '98', ',', 'vp', '##b', 'x', '##1', ',', 'pr', '120', ',', 'nm', '##l', 'q', '##tc', 'ec', '##g', ':', 'accelerated', 'id', '##io', '##vent', '##ric', '##ular', 'rhythm', ',', 'rate', '96', ',', 'possible', 'retro', '##grade', 'p', 'waves', 'seen', 'best', 'in', 'lead', 'ii', 'and', 'av', '##f', 'assessment', 'and', 'plan', 'arousal', ',', 'attention', ',', 'and', 'cognition', ',', 'impaired', 'balance', ',', 'impaired', 'knowledge', ',', 'impaired', 'muscle', 'perform', '##ace', ',', 'impaired', 'res', '##piration', '/', 'gas', 'exchange', ',', 'impaired', 'transfers', ',', 'impaired', 'alteration', 'in', 'elimination', 'related', 'to', 'con', '##sti', '##pati', '##on', 'respiratory', 'failure', ',', 'acute', '(', 'not', 'ar', '##ds', '/', ')', 'l', '##yme', 'disease', 'altered', 'mental', 'status', '(', 'not', 'del', '##iri', '##um', ')', 'problem', '-', 'enter', 'description', 'in', 'comments', 'bells', 'pal', '##sy', 'assessment', 'and', 'plan', ':', '63', '##m', 'with', 'h', '##t', '##n', ',', 'it', '##p', ',', 'admitted', 'with', 'ne', '##uro', '##logic', 'changes', 'and', 'found', 'to', 'have', 'l', '##yme', 'en', '##ce', '##pha', '##lit', '##is', '.', '.', '#', 'l', '##yme', 'en', '##ce', '##pha', '##lit', '##is', '.', 'highly', 'suspected', 'based', 'on', 'mr', 'findings', ',', 'serum', 'and', 'cs', '##f', 'ser', '##ologies', '.', 'on', 'stable', 'treatment', 'course', 'for', 'planned', '4', 'weeks', 'with', 'ce', '##ft', '##ria', '##xon', '##e', '.', 'with', 'some', 'persistent', 'ne', '##uro', '##logic', 'deficit', '##s', '.', '-', '28', 'day', 'course', 'of', 'ce', '##ft', '##ria', '##xon', '##e', '-', 'clarify', 'date', 'of', 'last', 'dose', '.', '-', 'ne', '##uro', '##logy', 'following', ';', 'unclear', 'if', 'deficit', '##s', 'permanent', '.', '.', '#', 'agitation', '/', 'altered', 'mental', 'status', '.', 'multi', '##fa', '##ctor', '##ial', 'del', '##eri', '##um', '-', 'electro', '##ly', '##te', 'abnormalities', ',', 'en', '##ce', '##pha', '##lit', '##is', ',', 'med', 'related', '.', 'also', 'with', 'some', 'chronic', 'na', '##rco', '##tic', 'use', '.', '-', 'correct', 'l', '##yte', '##s', '-', 'met', '##had', '##one', '10', 'mg', 'ti', '##d', 'given', 'chronic', 'pain', 'control', 'issues', '.', '-', 'ser', '##o', '##quel', '25', 'mg', 'for', 'agitation', '.', '-', 'can', 'also', 'give', 'hal', '##do', '##l', 'pr', '##n', 'agitation', '.', '.', '#', 'respiratory', 'failure', '.', 'difficulty', 'we', '##ani', '##ng', 'off', 'vent', 'now', 's', '/', 'p', 'tr', '##ach', '.', 'seems', 'to', 'des', '##at', 'with', 'plug', '##ging', '/', 'secret', '##ions', 'at', 'times', '.', 'ate', '##le', '##cta', '##sis', 'on', 'imaging', '.', 'be', 'h', '##yp', '##oven', '##tila', '##ting', 'to', 'some', 'degree', 'with', 'se', '##dation', 'med', '##s', 'as', 'above', '.', 'recent', 'mini', '-', 'bal', 'negative', '.', 'today', 'to', '##ler', '##ating', 'tr', '##ach', 'mask', 'well', '.', '-', 'c', '##x', '##r', 'today', '.', '-', 'continue', 'vent', 'we', '##an', 'as', 'tolerated', '.', '-', 'continue', 'inhaled', 'med', '##s', 'as', 'prior', 'for', 'bro', '##nch', '##os', '##pas', '##m', '(', 'no', 'clear', 'history', 'of', 'cop', '##d', ',', 'though', 'with', 'significant', 'smoking', 'history', ')', '.', '.', '#', 'fever', '.', 'daily', 'low', 'grade', 'temps', '(', '100', '-', '3', ')', ';', 't', '##max', '8', 'yesterday', '.', 'blood', 'cultures', 'drawn', ';', 'urine', 'with', 'a', 'few', 'wb', '##cs', '.', 'c', '##x', '##r', 'without', 'evidence', 'of', 'infiltrate', 'though', 'was', 'one', 'day', 'prior', '.', '-', 'repeat', 'c', '##x', '##r', '.', '-', 'sp', '##ut', '##um', 'culture', '.', '-', 'repeat', 'ua', 'with', 'culture', '.', '-', 'send', 'c', '.', 'di', '##ff', '.', '-', 'd', '/', 'c', 'pic', '##c', 'and', 'send', 'tip', 'culture', '.', '.', '#', 'hyper', '##nat', '##rem', '##ia', '.', 'likely', 'ia', '##tro', '##genic', '.', '-', 'free', 'water', 'in', 'tube', 'feeds', 'doubled', 'today', '.', '-', '1', 'more', 'liter', 'of', 'd', '##5', '##w', 'today', '.', '-', 'repeat', 'l', '##yte', '##s', 'in', 'pm', 'today', '.', '.', '#', 'corn', '##eal', 'ul', '##cer', '.', 's', '/', 'p', 'eye', '##lid', 'su', '##turing', 'with', 'op', '##ht', '##hal', '.', 'likely', 'related', 'to', 'inability', 'to', 'protect', 'eye', 'with', 'ne', '##uro', '##logic', 'deficit', '##s', '.', '-', 'vi', '##gam', '##ox', 'and', 'ba', '##cit', '##rac', '##in', 'o', '##int', '##ment', '.', '-', 'clarify', 'treatment', 'duration', 'with', 'op', '##ht', '##hal', '##mology', '.', '.', '#', 'elevated', 'l', '##ft', '##s', '.', 'mild', 'yesterday', '.', '?', 'ce', '##ft', '##ria', '##xon', '##e', 'related', '.', '-', 'rec', '##he', '##ck', 'tomorrow', '.', '-', 'if', 'still', 'abnormal', ',', 'check', 'ru', '##q', 'us', '.', '.', '#', 'accelerated', 'id', '##io', '##vent', '##ric', '##ular', 'rhythm', '.', 'cards', 'saw', ';', 'though', 'benign', 'and', 'not', 'related', 'to', 'l', '##yme', 'disease', '.', '-', 'continue', 'met', '##op', '##rol', '##ol', 'at', 'current', 'dos', '##ing', '.', '.', '#', 'h', '##t', '##n', '.', 'well', 'controlled', 'on', 'met', '##op', '##rol', '##ol', ';', 'written', 'for', 'pr', '##n', 'anti', '##hy', '##per', '##tens', '##ives', ',', 'which', 'we', 'will', 'hold', '.', '-', 'continue', 'met', '##op', '##rol', '##ol', '.', '.', 'fen', ':', 'correct', '/', 'rep', '##lete', 'electro', '##ly', '##tes', ',', 'tube', 'feeds', 'prop', '##hyl', '##ax', '##is', ':', 'sub', '##uta', '##neo', '##us', 'he', '##par', '##in', ',', 'h', '##2', '##b', 'access', ':', 'pic', '##c', 'will', 'be', 'dc', '##ed', ';', 'place', 'peripheral', '##s', '.', 'code', ':', 'full', '(', 'discussed', 'with', 'patient', ')', 'communication', ':', 'patient', '&', 'disposition', ':', 'pending', 'clinical', 'improvement', ';', 'eventual', 'for', 'rehab', 'screening', '.', 'ic', '##u', 'care', 'nutrition', ':', 'rep', '##lete', '(', 'full', ')', '-', '02', ':', '22', 'pm', '55', 'ml', '/', 'hour', 'g', '##ly', '##ce', '##mic', 'control', ':', 'regular', 'insulin', 'sliding', 'scale', 'lines', ':', 'pic', '##c', 'line', '-', '10', ':', '00', 'am', 'prop', '##hyl', '##ax', '##is', ':', 'd', '##v', '##t', ':', 'sq', 'u', '##f', 'he', '##par', '##in', 'stress', 'ul', '##cer', ':', 'h', '##2', 'block', '##er', 'va', '##p', ':', 'comments', ':', 'communication', ':', 'patient', 'discussed', 'on', 'interdisciplinary', 'rounds', ',', 'ic', '##u', 'code', 'status', ':', 'full', 'code', 'disposition', ':', 'ic', '##u']\n","chunk 127 tokenize start!\n","First sentence tokenized\n","['subjective', 'unable', 'to', 'speak', 'with', 'patient', 'due', 'to', 'int', '##uba', '##tion', 'objective', 'height', 'admit', 'weight', 'daily', 'weight', 'weight', 'change', 'b', '##mi', '4', 'cm', '50', 'kg', '6', 'ideal', 'body', 'weight', '%', 'ideal', 'body', 'weight', 'adjusted', 'weight', 'usual', 'body', 'weight', '%', 'usual', 'body', 'weight', '4', '110', '%', 'n', '/', 'a', 'n', '/', 'a', 'diagnosis', ':', 's', '/', 'p', 'fall', 'pm', '##h', ':', 'sc', '##ca', ',', 'br', '##ca', ',', 'h', '##t', '##n', ',', 'cad', ',', 'pv', '##d', ',', 'h', '##yp', '##oth', '##yr', '##od', '##ism', ',', 'ge', '##rd', 'with', 'd', '##ys', '##pha', '##gia', ',', 'recent', 'fall', 'with', 'spinal', 'compression', 'fracture', 'food', 'all', '##er', '##gies', 'and', 'into', '##ler', '##ances', ':', 'n', '/', 'a', 'per', '##tine', '##nt', 'medications', ':', 'ab', '##x', ',', 'lan', '##sop', '##raz', '##ole', ',', 'vitamin', 'd', ',', 'he', '##par', '##in', ',', 'fen', '##tan', '##yl', 'bo', '##lus', '##ed', ',', 'mid', '##az', '##ola', '##m', '(', 'verse', '##d', ')', 'bo', '##lus', '##ed', ',', '1000', 'ml', 'of', 'ns', 'x', '2', ',', 'calcium', 'g', '##lu', '##cona', '##te', '2', 'g', ',', 'potassium', 'chloride', '40', 'me', '##q', 'labs', ':', 'value', 'date', 'glucose', '91', 'mg', '/', 'dl', '02', ':', '53', 'am', 'bun', '17', 'mg', '/', 'dl', '02', ':', '53', 'am', 'cr', '##ea', '##tin', '##ine', '5', 'mg', '/', 'dl', '02', ':', '53', 'am', 'sodium', '129', 'me', '##q', '/', 'l', '02', ':', '53', 'am', 'potassium', '4', 'me', '##q', '/', 'l', '02', ':', '53', 'am', 'chloride', '100', 'me', '##q', '/', 'l', '02', ':', '53', 'am', 'tc', '##o', '##2', '19', 'me', '##q', '/', 'l', '02', ':', '53', 'am', 'po', '##2', '(', 'arterial', ')', 'mm', 'h', '##g', '03', ':', '21', 'am', 'pc', '##o', '##2', '(', 'arterial', ')', '36', 'mm', 'h', '##g', '03', ':', '21', 'am', 'ph', '(', 'arterial', ')', '37', 'units', '03', ':', '21', 'am', 'ph', '(', 'urine', ')', '0', 'units', '11', ':', '02', 'pm', 'co', '##2', '(', 'cal', '##c', ')', 'arterial', '22', 'me', '##q', '/', 'l', '03', ':', '21', 'am', 'album', '##in', '1', 'g', '/', 'dl', '04', ':', '26', 'pm', 'calcium', 'non', '-', 'ion', '##ized', '3', 'mg', '/', 'dl', '02', ':', '53', 'am', 'phosphorus', '4', 'mg', '/', 'dl', '02', ':', '53', 'am', 'magnesium', '1', 'mg', '/', 'dl', '02', ':', '53', 'am', 'alt', '18', 'i', '##u', '/', 'l', '04', ':', '26', 'pm', 'al', '##kali', '##ne', 'phosphate', '43', 'i', '##u', '/', 'l', '04', ':', '26', 'pm', 'as', '##t', '35', 'i', '##u', '/', 'l', '04', ':', '26', 'pm', 'total', 'bi', '##li', '##ru', '##bin', '5', 'mg', '/', 'dl', '04', ':', '26', 'pm', 'wb', '##c', '4', 'k', '/', 'ul', '02', ':', '53', 'am', 'h', '##gb', '8', 'g', '/', 'dl', '02', ':', '53', 'am', 'hem', '##ato', '##cr', '##it', '0', '%', '02', ':', '53', 'am', 'current', 'diet', 'order', '/', 'nutrition', 'support', ':', 'diet', ':', 'np', '##o', 'gi', ':', 'abd', '.', 'soft', ',', 'h', '##yp', '##oa', '##ctive', 'bs', 'assessment', 'of', 'nutritional', 'status', 'at', 'risk', 'for', 'mal', '##nut', '##rit', '##ion', 'pt', 'at', 'risk', 'due', 'to', ':', 'np', '##o', ',', 'altered', 'mental', 'status', ',', 'int', '##uba', '##tion', 'estimated', 'nutritional', 'needs', 'cal', '##ories', ':', '125', '##0', '-', '1500', '(', 'bee', 'x', 'or', '/', '25', '-', '30', 'cal', '/', 'kg', ')', 'protein', ':', '60', '-', '75', '(', '2', '-', '5', 'g', '/', 'kg', ')', 'fluid', ':', 'per', 'team', 'estimation', 'of', 'previous', 'intake', ':', 'md', 'ion', 'of', 'current', 'intake', ':', 'inadequate', 'specific', '##s', ':', '73', 'y', '.', 'o', 'female', 'who', 'initially', 'presented', 'to', 'medical', 'floor', 'from', 'os', '##h', 's', '/', 'p', 'fall', 'and', 'new', 'cv', '##a', ',', 'now', 'admitted', 'to', 'mic', '##u', 'with', 'altered', 'mental', 'status', 'and', 'respiratory', 'distress', 'requiring', 'int', '##uba', '##tion', 'while', 'on', 'floor', '.', 'patient', 'became', 'h', '##yp', '##ote', '##ns', '##ive', 'post', 'se', '##dation', '/', 'int', '##uba', '##tion', '.', 'bro', '##nch', '##os', '##co', '##py', 'noted', 'for', 'particular', 'matter', 'in', 'airways', 'consistent', 'with', 'as', '##piration', '.', 'nutrition', 'consult', 'received', 'regarding', 'tube', 'feeding', 'recommendations', '.', 'agree', 'with', 'initiating', 'volume', 'restrictive', 'enter', '##al', 'formula', 'to', 'help', 'patient', 'meet', 'estimated', 'needs', '.', 'noted', 'rep', '##let', '##ions', 'of', 'ns', 'x', '2', ',', 'calcium', 'g', '##lu', '##cona', '##te', ',', 'and', 'potassium', 'chloride', '.', 'medical', 'nutrition', 'therapy', 'plan', '-', 'recommend', 'the', 'following', 'multi', '##vita', '##min', '/', 'mineral', 'supplement', ':', 'in', 'tube', 'feed', 'tube', 'feeding', 'recommendations', ':', '-', 'initiate', 'nut', '##ren', 'pulmonary', '@', '10', 'ml', '/', 'hour', ',', 'advance', 'as', 'tolerated', 'by', '10', 'ml', 'q', '##4', '##h', 'or', 'as', 'tolerated', 'by', 'patient', 'to', 'goal', 'of', '40', 'ml', '/', 'hour', 'x', '24', 'hours', ',', 'to', 'provide', '144', '##0', 'kc', '##als', 'and', '65', 'gm', 'protein', '.', '-', 'monitor', 'tube', 'feeding', 'tolerance', 'via', 'residual', '##s', ',', 'hold', 'tube', 'feeds', 'if', '>', '200', 'ml', '.', 'fluid', 'needs', 'per', 'team', 'monitor', 'electro', '##ly', '##tes', ',', 'rep', '##lete', 'pr', '##n']\n","chunk 128 tokenize start!\n","First sentence tokenized\n","['sin', '##us', 'rhythm', '.', 'non', '-', 'specific', 'inferior', 'st', '-', 't', 'wave', 'changes', '.', 'no', 'previous', 'tracing', 'available', 'for', 'comparison', '.']\n","chunk 129 tokenize start!\n","First sentence tokenized\n","['respiratory', 'failure', ',', 'acute', '(', 'not', 'ar', '##ds', '/', ')', 'assessment', ':', 'pt', 'on', 'ps', '##v', '5', '/', '5', ',', 'res', '##p', 'status', 'unchanged', ',', 'mod', 'secret', '##ions', 'from', 'et', '##t', ',', 'large', 'am', '##t', 'oral', 'secret', '##ions', 'action', ':', 'discussed', 'plan', 'for', 'ex', '##tub', '##ation', 'during', 'rounds', ',', 'assessed', 'pt', 'ms', 'along', 'w', '/', 'ability', 'to', 'protect', 'air', '##way', '.', 'response', ':', 'no', 'changes', 'in', 'res', '##p', 'or', 'ms', ':', 'plan', 'to', 'ex', '##tub', '##ate', 'in', 'am', ',', 'hold', 't', '##f', 'after', 'mn']\n","chunk 130 tokenize start!\n","First sentence tokenized\n","['66', '##m', 'with', 'pm', '##h', 'notable', 'for', 'type', '2', 'd', '##m', ',', 'av', '##r', 'x', '2', ',', 'tr', '##ache', '##ob', '##ron', '##cho', '##mal', '##ac', '##ia', 's', '/', 'p', 'tr', '##ache', '##al', 'y', 'ste', '##nting', 'earlier', 'this', 'year', 'presents', 'with', 'witnessed', 'pea', 'arrest', 'at', 'friend', \"'\", 's', 'workplace', '.', 'down', 'for', 'approximately', '4', 'min', '##s', 'prior', 'to', 'initiation', 'of', 'cp', '##r', '.', 'reportedly', ',', 'he', 'had', 'return', 'of', 'pulses', 'after', '6', 'minutes', 'of', 'cp', '##r', ',', 'int', '##uba', '##ted', 'in', 'the', 'field', '.', 'in', 'ed', ',', 'hr', '60', '(', 'paced', ')', ',', 'h', '##yp', '##ote', '##ns', '##ive', 'to', '60s', '.', 'right', 'fe', '##m', 'cv', '##l', 'and', 'a', '-', 'line', 'placed', ',', 'started', 'on', 'do', '##pa', 'then', 'lev', '##o', 'then', 'ep', '##i', 'for', 'persistent', 'h', '##yp', '##ote', '##ns', '##ion', '.', 'pan', 'scan', 'revealed', 'bilateral', 'lower', 'lobe', 'infiltrate', '##s', '(', 'as', '##piration', 'vs', 'p', '##na', ')', '.', 'he', 'received', 'iv', 'ab', '##x', '.', 'on', 'ct', 'scan', ',', 'his', 'et', '##t', 'was', 'noted', 'to', 'be', 'anterior', 'to', 'his', 'tr', '##ache', '##al', 'ste', '##nt', '.', 'ip', '/', 'an', '##esthesia', 'was', 'called', 'to', 'the', 'bedside', 'where', 'bro', '##nch', '##os', '##co', '##py', 'was', 'used', 'to', 'rep', '##osition', 'the', 'tube', 'successfully', '.', 'card', '##iology', 'consulted', ',', 'per', 'report', 'pt', 's', 'presentation', 'was', 'not', 'consistent', 'with', 'stem', '##i', '.', 'echo', 'performed', 'at', 'the', 'bedside', 'showed', 'e', '##f', '>', '55', '%', '.', 'transferred', 'to', 'mic', '##u', '.', 'pt', 'we', '##ane', '##d', 'off', 'press', '##ors', 'shortly', 'after', 'admit', 'to', 'the', 'unit', ',', 'fe', '##m', 'line', 'changed', 'to', 'r', 'i', '##j', '.', 'we', '##ani', '##ng', 'from', 'vent', '.', 'respiratory', 'failure', ',', 'acute', '(', 'not', 'ar', '##ds', '/', ')', 'assessment', ':', 'received', 'pt', 'on', 'ps', '##v', '10', '/', '5', '/', '40', '%', '.', 'l', '##s', 'coarse', 'throughout', '.', 'rr', '20', '-', '30', 'with', 'sat', '##s', '>', '95', '%', '.', 'action', ':', 'maintained', 'on', 'ps', '##v', 'overnight', '.', 'su', '##ction', '##ed', 'for', 'mod', 'am', '##ts', 'thick', 'white', 'sp', '##ut', '##um', '.', 'response', ':', 'ab', '##g', '39', '/', '55', '/', '114', '/', '7', '/', 'ri', '##sb', '##i', 'plan', ':', 'sb', '##t', '.', '?', 'ex', '##tub', '##ate', 'this', 'am', '.', 'altered', 'mental', 'status', '(', 'not', 'del', '##iri', '##um', ')', 'assessment', ':', 'pt', 'agitated', 'at', 'times', ',', 'reaching', 'for', 'et', '##t', 'and', 'sq', '##ui', '##rmin', '##g', 'around', 'in', 'bed', '.', 'prop', '##of', '##ol', 'in', '##fus', '##ing', 'at', '10', 'mc', '##g', '##ks', '/', 'kg', '/', 'min', 'action', ':', 'wrist', 'restraints', 'in', 'place', 'for', 'safety', '.', 'pt', 'bo', '##lus', '##ed', 'with', '1', '-', '2', 'cc', '##s', 'prop', '##of', '##ol', '.', 'response', ':', 'less', 'agitation', 's', '/', 'p', 'bo', '##lus', '.', 'plan', ':', 'on', 'going', 'mental', 'status', 'assessment', '.', 'safety', 'precautions', '.']\n","chunk 131 tokenize start!\n","First sentence tokenized\n","['7', ':', '40', 'pm', 'chest', '(', 'portable', 'ap', ')', 'clip', '#', 'reason', ':', 'eva', '##l', 'for', 'infiltrate', 'medical', 'condition', ':', '66', 'year', 'old', 'woman', 'with', 'sob', 'reason', 'for', 'this', 'examination', ':', 'eva', '##l', 'for', 'infiltrate', 'final', 'report', 'exam', ':', 'chest', ',', 'single', 'ap', 'erect', 'portable', 'view', '.', 'clinical', 'information', ':', '66', '-', 'year', '-', 'old', 'female', 'with', 'history', 'of', 'short', '##ness', 'of', 'breath', '.', 'comparison', ':', '.', 'findings', ':', 'single', 'erect', 'portable', 'frontal', 'view', 'of', 'the', 'chest', 'was', 'obtained', '.', 'there', 'has', 'been', 'interval', 'development', 'in', 'moderate', 'left', 'base', 'op', '##ac', '##ity', ',', 'which', 'likely', 'represents', 'combination', 'of', 'pl', '##eur', '##al', 'e', '##ff', '##usion', 'and', 'ate', '##le', '##cta', '##sis', '.', 'underlying', 'consolidation', 'cannot', 'be', 'excluded', '.', 'small', 'right', 'pl', '##eur', '##al', 'e', '##ff', '##usion', 'with', 'overly', '##ing', 'ate', '##le', '##cta', '##sis', 'is', 'also', 'seen', '.', 'cardiac', 'silhouette', 'is', 'difficult', 'to', 'assess', 'due', 'to', 'the', 'adjacent', 'e', '##ff', '##usions', '.', 'the', 'ao', '##rta', 'remains', 'tor', '##tu', '##ous', '.', 'impression', ':', 'interval', 'development', 'of', 'moderate', 'left', 'base', 'op', '##ac', '##ity', 'may', 'represent', 'combination', 'of', 'pl', '##eur', '##al', 'e', '##ff', '##usion', 'and', 'ate', '##le', '##cta', '##sis', ';', 'underlying', 'consolidation', 'cannot', 'be', 'excluded', '.', 'small', 'right', 'pl', '##eur', '##al', 'e', '##ff', '##usion', 'with', 'overly', '##ing', 'ate', '##le', '##cta', '##sis', '.']\n","chunk 132 tokenize start!\n","First sentence tokenized\n","['1', ':', '22', 'pm', 'chest', '(', 'portable', 'ap', ')', 'clip', '#', 'reason', ':', 'pt', '.', 'had', 'central', 'line', 'placed', '.', 'please', 'confirm', 'placement', '.', 'medical', 'condition', ':', '54', 'year', 'old', 'man', 's', '/', 'p', 'l', 'aka', ',', 'com', '##pl', '.', 'by', 'sir', '##s', ',', 'now', 'in', 'respiratory', 'distress', '2nd', 'to', 'ch', '##f', '.', 'l', 'i', '##j', 'pulled', 'and', 'r', 'i', '##j', 'placed', 'this', 'am', '.', 'reason', 'for', 'this', 'examination', ':', 'pt', '.', 'had', 'central', 'line', 'placed', '.', 'please', 'confirm', 'placement', '.', 'final', 'report', 'indication', ':', 'check', 'central', 'line', 'placement', '.', 'chest', 'single', 'view', 'time', '13', ':', '36', ':', 'the', 'left', 'i', '##j', 'central', 'line', 'terminates', 'at', 'the', 'junction', 'of', 'the', 'bra', '##chio', '##ce', '##pha', '##lic', 'veins', 'with', 'no', 'p', '##ne', '##um', '##otho', '##ra', '##x', '.', 'comparison', 'with', 'the', 'film', 'done', '7', 'hours', 'before', 'shows', 'no', 'significant', 'change', 'of', 'bilateral', 'pl', '##eur', '##al', 'e', '##ff', '##usions', 'with', 'per', '##ih', '##ila', '##r', 'ha', '##zine', '##ss', 'and', 'eng', '##org', '##ed', 'pulmonary', 'vessels', '.', 'degree', 'of', 'card', '##iom', '##ega', '##ly', 'is', 'unchanged', '.', 'et', 'tube', 'terminates', '2', 'cm', 'above', 'the', 'car', '##ina', '.', 'ng', 'tube', 'enters', 'the', 'stomach', '.', 'the', 'patient', 'is', 'post', '-', 'cab', '##g', '.', 'impression', ':', 'the', 'left', 'central', 'line', 'terminates', 'at', 'the', 'junction', 'of', 'the', 'left', 'bra', '##chio', '##ce', '##pha', '##lic', 'vein', 'and', 'sv', '##c', 'with', 'no', 'p', '##ne', '##um', '##otho', '##ra', '##x', '.', 'persistent', 'failure', 'with', 'bilateral', 'e', '##ff', '##usions', 'is', 'stable', 'since', '7', 'hours', 'before', '.']\n","chunk 133 tokenize start!\n","First sentence tokenized\n","['ts', '##ic', '##u', 'hp', '##i', ':', '40', '##f', 's', '/', 'p', 'un', '##wi', '##tness', 'fall', 'in', 'bathroom', ',', 'found', 'to', 'have', 'sa', '##h', 'on', 'ct', '##oh', 'chief', 'complaint', ':', 'sub', 'ara', '##ch', '##no', '##id', 'hem', '##mo', '##rh', '##age', 'as', '##piration', 'p', '##num', '##onia', 'pm', '##h', '##x', ':', 'possible', 'cop', '##d', '(', 'family', 'reports', 'chronic', 'cough', ')', ',', 'recent', 'episode', 'of', 'rec', '##tal', 'bleeding', 'apparently', 'negative', 'source', 'found', 'by', 'colon', '##os', '##co', '##py', 'current', 'medications', ':', '.', '1000', 'ml', 'ns', 'ace', '##tam', '##ino', '##ph', '##en', 'artificial', 'tear', 'o', '##int', '##ment', 'artificial', 'tears', 'bis', '##aco', '##dy', '##l', 'calcium', 'g', '##lu', '##cona', '##te', 'ch', '##lor', '##he', '##xi', '##dine', 'g', '##lu', '##cona', '##te', '12', '%', 'oral', 'ri', '##nse', 'doc', '##usa', '##te', 'sodium', '(', 'liquid', ')', 'fa', '##mot', '##idi', '##ne', 'he', '##par', '##in', 'ib', '##up', '##ro', '##fen', 'insulin', 'lev', '##eti', '##race', '##tam', 'lev', '##eti', '##race', '##tam', 'magnesium', 'sulfate', 'mann', '##ito', '##l', '20', '%', 'mor', '##phine', 'sulfate', 'na', '##fc', '##ill', '##in', 'ni', '##mo', '##di', '##pine', 'nic', '##ard', '##ip', '##ine', 'on', '##dan', '##set', '##ron', 'ph', '##en', '##yle', '##ph', '##rine', 'piper', '##ac', '##ill', '##in', '-', 'ta', '##zo', '##ba', '##cta', '##m', 'na', 'potassium', 'chloride', 'potassium', 'phosphate', 'sen', '##na', 'sodium', 'chloride', '9', '%', 'flush', 'van', '##com', '##y', '##cin', 'van', '##com', '##y', '##cin', '24', 'hour', 'events', ':', 'ang', '##iography', '-', 'at', '01', ':', '30', 'pm', 'fever', '-', '6', 'f', '-', '01', ':', '00', 'am', 'went', 'to', 'ang', '##io', 'to', 'search', 'for', 'post', 'clip', '##ping', 'spa', '##sm', '##ing', ',', 'none', 'found', '9', '/', '8', '##tra', '##ns', '##fus', '##ed', '2', 'u', 'pr', '##bc', 'for', 'hc', '##t', '23', 'post', 'operative', 'day', ':', 'pod', '#', '4', '-', 'left', 'cr', '##ani', 'all', '##er', '##gies', ':', 'sul', '##fa', '(', 'sul', '##fo', '##nami', '##des', ')', 'unknown', ';', 'last', 'dose', 'of', 'antibiotics', ':', 'van', '##com', '##y', '##cin', '-', '09', ':', '00', 'pm', 'piper', '##ac', '##ill', '##in', '/', 'ta', '##zo', '##ba', '##cta', '##m', '(', 'z', '##os', '##yn', ')', '-', '06', ':', '00', 'am', 'na', '##fc', '##ill', '##in', '-', '09', ':', '00', 'am', 'in', '##fusion', '##s', ':', 'other', 'ic', '##u', 'medications', ':', 'fa', '##mot', '##idi', '##ne', '(', 'pep', '##ci', '##d', ')', '-', '08', ':', '00', 'pm', 'he', '##par', '##in', 'sodium', '(', 'prop', '##hyl', '##ax', '##is', ')', '-', '08', ':', '00', 'pm', 'other', 'medications', ':', 'flows', '##hee', '##t', 'data', 'as', 'of', '09', ':', '31', 'am', 'vital', 'signs', 'hem', '##od', '##yna', '##mic', 'monitoring', 'fluid', 'balance', '24', 'hours', 'since', 'a', '.', 'm', '.', 't', '##max', ':', '2', 'c', '(', '6', 't', 'current', ':', '2', 'c', '(', '6', 'hr', ':', '109', '(', '78', '-', '109', ')', 'bp', '##m', 'bp', ':', '29', '/', '22', '(', '24', ')', '{', '28', '/', '22', '(', '24', ')', '-', '184', '/', '100', '(', '132', ')', '}', 'mm', '##hg', 'rr', ':', '32', '(', '9', '-', '37', ')', 'ins', '##p', '/', 'min', 'sp', '##o', '##2', ':', '99', '%', 'heart', 'rhythm', ':', 'st', '(', 'sin', '##us', 'ta', '##chy', '##card', '##ia', ')', 'w', '##gt', '(', 'current', ')', ':', '5', 'kg', '(', 'admission', ')', ':', '99', 'kg', 'height', ':', '67', 'inch', 'cv', '##p', ':', '9', '(', '8', '-', '183', ')', 'mm', '##hg', 'ic', '##p', ':', '13', '(', '9', '-', '24', ')', 'mm', '##hg', 'total', 'in', ':', '4', ',', '59', '##2', 'ml', '1', ',', '450', 'ml', 'po', ':', 'tube', 'feeding', ':', '11', 'ml', '147', 'ml', 'iv', 'fluid', ':', '3', ',', '57', '##8', 'ml', '1', ',', '193', 'ml', 'blood', 'products', ':', '54', '##4', 'ml', 'total', 'out', ':', '1', ',', '94', '##9', 'ml', '54', '##2', 'ml', 'urine', ':', '1', ',', '77', '##6', 'ml', '45', '##5', 'ml', 'ng', ':', 'stool', ':', 'drains', ':', '173', 'ml', '87', 'ml', 'balance', ':', '2', ',', '64', '##3', 'ml', '90', '##8', 'ml', 'respiratory', 'support', 'o', '##2', 'delivery', 'device', ':', 'end', '##ot', '##rac', '##hea', '##l', 'tube', 'vent', '##ila', '##tor', 'mode', ':', 'cm', '##v', '/', 'assist', '/', 'auto', '##flow', 'vt', '(', 'set', ')', ':', '600', '(', '600', '-', '600', ')', 'ml', 'vt', '(', 'spontaneous', ')', ':', '130', '(', '130', '-', '41', '##8', ')', 'ml', 'ps', ':', '10', 'cm', '##h', '##2', '##o', 'rr', '(', 'set', ')', ':', '16', 'rr', '(', 'spontaneous', ')', ':', '0', 'pee', '##p', ':', '5', 'cm', '##h', '##2', '##o', 'fi', '##o', '##2', ':', '40', '%', 'rs', '##bi', 'def', '##erre', '##d', ':', 'pee', '##p', '>', '10', 'pip', ':', '35', 'cm', '##h', '##2', '##o', 'plateau', ':', '26', 'cm', '##h', '##2', '##o', 'compliance', ':', '5', 'cm', '##h', '##2', '##o', '/', 'ml', 'sp', '##o', '##2', ':', '99', '%', 'ab', '##g', ':', '53', '/', '27', '/', '127', '/', '22', '/', '1', 've', ':', '6', 'l', '/', 'min', 'pa', '##o', '##2', '/', 'fi', '##o', '##2', ':', '318', 'physical', 'examination', 'general', 'appearance', ':', 'no', 'acute', 'distress', ',', 'over', '##weight', '/', 'obe', '##se', 'hee', '##nt', ':', 'no', '(', 't', ')', 'per', '##rl', ',', 'pupils', ',', '4', '##mm', 'rc', '##orne', '##al', 'impaired', ',', 'l', 'ok', 'cardiovascular', ':', '(', 'rhythm', ':', 'regular', ')', 'respiratory', '/', 'chest', ':', '(', 'breath', 'sounds', ':', 'ct', '##a', 'bilateral', ':', ',', 'diminished', ':', 'bases', ')', 'abdominal', ':', 'soft', ',', 'non', '-', 'di', '##sten', '##ded', ',', 'obe', '##se', 'left', 'ex', '##tre', '##mit', '##ies', ':', '(', 'ed', '##ema', ':', 'no', '(', 't', ')', 'absent', ',', '2', '+', ')', ',', '(', 'temperature', ':', 'cool', ')', 'right', 'ex', '##tre', '##mit', '##ies', ':', '(', 'ed', '##ema', ':', '2', '+', ')', ',', '(', 'temperature', ':', 'cool', ')', 'skin', ':', '(', 'inc', '##ision', ':', 'clean', '/', 'dry', '/', 'intact', ')', 'ne', '##uro', '##logic', ':', '(', 'responds', 'to', ':', 'un', '##res', '##pon', '##sive', ')', 'labs', '/', 'radio', '##logy', '221', 'k', '/', 'ul', '1', 'g', '/', 'dl', '139', 'mg', '/', 'dl', '7', 'mg', '/', 'dl', '22', 'me', '##q', '/', 'l', '3', 'me', '##q', '/', 'l', '14', 'mg', '/', 'dl', '116', 'me', '##q', '/', 'l', '146', 'me', '##q', '/', 'l', '4', '%', '0', 'k', '/', 'ul', '03', ':', '17', 'pm', '10', ':', '00', 'pm', '01', ':', '15', 'am', '03', ':', '39', 'pm', '10', ':', '09', 'pm', '03', ':', '27', 'am', '03', ':', '42', 'am', '07', ':', '49', 'pm', '02', ':', '02', 'am', '02', ':', '24', 'am', 'wb', '##c', '6', '0', '0', 'hc', '##t', '2', '7', '4', 'pl', '##t', '286', '305', '221', 'cr', '##ea', '##tin', '##ine', '7', '7', '7', 'tc', '##o', '##2', '25', '24', '23', '27', '23', '23', 'glucose', '120', '164', '131', '112', '139', 'other', 'labs', ':', 'pt', '/', 'pt', '##t', '/', 'in', '##r', ':', '9', '/', '7', '/', '3', ',', 'alt', '/', 'as', '##t', ':', '21', '/', '30', ',', 'al', '##k', '-', 'ph', '##os', '/', 't', 'bi', '##li', ':', '61', '/', '3', ',', 'lac', '##tic', 'acid', ':', '4', 'mm', '##ol', '/', 'l', ',', 'album', '##in', ':', '6', 'g', '/', 'dl', ',', 'ca', ':', '2', 'mg', '/', 'dl', ',', 'mg', ':', '1', 'mg', '/', 'dl', ',', 'po', '##4', ':', '7', 'mg', '/', 'dl', 'imaging', ':', 'in', 'comparison', 'with', 'the', 'study', 'of', ',', 'there', 'is', 'little', 'change', 'in', 'the', 'appearance', 'of', 'the', 'support', 'lines', 'bilateral', 'pl', '##eur', '##al', 'e', '##ff', '##usions', ',', 'much', 'more', 'marked', 'on', 'the', 'right', 'again', 'seen', '.', 'some', 'elevation', 'of', 'pulmonary', 've', '##nous', 'pressure', 'persist', '##s', '.', 'the', 'possibility', 'of', 'super', '##ven', '##ing', 'pneumonia', ',', 'especially', 'on', 'the', 'right', ',', 'cannot', 'be', 'excluded', '.', 'micro', '##biology', ':', 'cs', '##f', 'c', '##x', ':', 'no', 'pm', '##ns', ',', 'no', 'org', '##s', 'b', '##ld', ',', 'urine', ',', 'sp', '##ut', '##um', ':', 'p', 'rt', 'sub', '##cl', '##avian', 'cat', '##h', 'tip', 'c', '##x', ':', 'p', 'sp', '##ut', '##um', 'c', '##x', ':', 'st', '##ap', '##h', 'au', '##reus', 'coa', '##g', 'positive', 'urine', 'c', '##x', ':', 'ng', '##t', '##d', 'blood', 'c', '##x', ':', 'ng', '##t', '##d', 'urine', 'c', '##x', ':', 'ne', '##g', 'sp', '##ut', '##um', ',', 'coa', '##g', '+', 'st', '##ap', '##h', '(', 'ms', '##sa', ')', 'blood', 'c', '##x', ':', 'ne', '##g', 'assessment', 'and', 'plan', 'suspected', 'cerebral', 'va', '##sos', '##pas', '##m', 'not', 'confirmed', 'by', 'ang', '##io', '.', 'will', 'repeat', 'in', 'one', 'week', '.', 'assessment', 'and', 'plan', ':', '40', '##yo', 'female', 'w', '/', 'sub', '##ara', '##ch', '##no', '##id', 'hem', '##mo', '##rh', '##age', 'with', 'continued', 'elevated', 'ic', '##ps', ',', 'now', 's', '/', 'p', 'hem', '##ic', '##rani', '##ect', '##omy', 'ne', '##uro', '##logic', ':', 'ne', '##uro', 'check', 'q', '##1', '##hr', ',', 'on', 'ke', '##pp', '##ra', '500', '##mg', \"'\", \"'\", 'x', '##3d', '(', 'end', ')', 'then', '1000', '##mg', '\"', 'vent', '##ric', '##le', 'drain', '@', '20', '##cm', 'h', '##20', ',', 'keep', 'sb', '##p', '140', '-', '160', ',', 'on', 'neo', 'gt', '##t', 'pr', '##n', ',', 'f', '/', 'u', 'pen', '##to', '##bar', '##b', 'level', 'will', 'continue', 'to', 'ag', '##ress', '##ively', 'treat', 'fever', '##s', 'pain', ':', 'ty', '##len', '##ol', ',', 'mo', '##tri', '##n', ',', 'mor', '##phine', 'iv', 'pr', '##n', 'cardiovascular', ':', 'hem', '##od', '##yna', '##mic', '##ally', 'stabilized', ',', 'now', 'off', 'neo', 'gt', '##t', ',', 'consider', 'removing', 'a', '-', 'line', 'not', 'currently', 'working', ',', 'difficult', 'to', 'place', 'pulmonary', ':', 'int', '##uba', '##ted', ',', 'keep', 'pc', '##0', '##2', '35', '-', '40', ',', 'place', 'vent', 'on', 'cp', '##ap', '+', 'ps', ',', 'ms', '##sa', 'p', '##na', 'tx', \"'\", 'd', 'with', 'na', '##fc', '##ill', '##in', '.', 'consider', 'tr', '##ach', '-', 'will', 'speak', 'to', 'dr', 'gas', '##tro', '##int', '##estinal', '/', 'abdomen', ':', 'fa', '##mot', '##idi', '##ne', 'prop', '##hyl', '##ax', '##is', '.', 'consider', 'peg', '.', 'nutrition', ':', 't', '##f', 'running', ',', 'goal', '70', 'cc', '/', 'hr', 'renal', ':', 'foley', ',', 'adequate', 'u', '##o', 'hem', '##ato', '##logy', ':', 'hc', '##t', '=', '4', 'today', 'inappropriate', 'response', 's', '/', 'p', '2', '##u', 'pr', '##bc', 'yesterday', '.', 'will', 'trans', '##fus', '##e', '1', '##u', 'pr', '##bc', 'today', '.', 'end', '##oc', '##rine', ':', 'ri', '##ss', 'infectious', 'disease', ':', 'na', '##fc', '##ill', '##in', 'for', 'ms', '##sa', 'pneumonia', '(', ')', 'total', '8', '##d', 'treatment', ',', 'd', '/', 'c', 'van', '##co', '/', 'z', '##os', '##yn', 'today', '.', 'f', '/', 'u', 'cultures', 'lines', '/', 'tubes', '/', 'drains', ':', 'a', '-', 'line', 'in', 'left', 'fe', '##m', 'artery', ',', 'r', 'sub', '##cl', '##avian', 'cv', '##l', '(', 're', '##wire', '##d', ')', ',', 'et', '##t', ',', 'foley', ',', 'vent', '##ric', '##ulo', '##sto', '##my', 'wounds', ':', 'dry', 'dressing', '##s', 'imaging', ':', 'none', 'today', 'fluids', ':', 'l', '##r', ',', '80', '##cc', '/', 'hr', 'consult', '##s', ':', 'ne', '##uro', 'surgery', ',', 'ne', '##uro', '##logy', 'billing', 'diagnosis', ':', '(', 'hem', '##or', '##rh', '##age', ',', 'nos', ':', 'sub', '-', 'ara', '##ch', '##no', '##id', ')', 'ic', '##u', 'care', 'nutrition', ':', 'rep', '##lete', 'with', 'fiber', '(', 'full', ')', '-', '12', ':', '00', 'am', '20', 'ml', '/', 'hour', 'g', '##ly', '##ce', '##mic', 'control', ':', 'regular', 'insulin', 'sliding', 'scale', 'lines', ':', 'multi', 'lu', '##men', '-', '10', ':', '42', 'am', 'ic', '##p', 'cat', '##het', '##er', '-', '12', ':', '00', 'am', 'arterial', 'line', '-', '11', ':', '40', 'am', 'prop', '##hyl', '##ax', '##is', ':', 'd', '##v', '##t', ':', 'boots', ',', 'sq', 'u', '##f', 'he', '##par', '##in', 'stress', 'ul', '##cer', ':', 'h', '##2', 'block', '##er', 'va', '##p', 'bundle', ':', 'ho', '##b', 'elevation', ',', 'mouth', 'care', 'comments', ':', 'communication', ':', 'patient', 'discussed', 'on', 'interdisciplinary', 'rounds', ',', 'ic', '##u', 'code', 'status', ':', 'full', 'code', 'disposition', ':', 'ic', '##u', 'total', 'time', 'spent', ':', '33', 'patient', 'is', 'critically', 'ill']\n","chunk 134 tokenize start!\n","First sentence tokenized\n","['title', ':', 'admission', 'note', '!', 'chief', 'complaint', ':', 'abdominal', 'pain', 'hp', '##i', ':', '65', 'year', '-', 'old', 'gentleman', 'w', 'mor', '##bid', 'obe', '##sti', '##ty', 'and', 'history', 'of', 'cho', '##le', '##cy', '##ts', '##itis', 's', '/', 'p', 'per', '##c', 'cho', '##le', 'tube', 'at', 'hospital', 'in', 'transferred', 'here', 'from', 'hospital', 'with', 'rec', '##urrent', 'ru', '##q', 'pain', 'and', 'concern', 'for', 'cho', '##le', '##cy', '##sti', '##tis', 'or', 'cho', '##lang', '##itis', '.', 'patient', 'is', 'poor', 'historian', ',', 'but', 'describes', 'off', 'and', 'on', 'pain', 'over', 'past', '2', 'months', ',', 'with', 'worse', '##ning', 'pain', 'associated', 'with', 'nausea', 'and', 'vomiting', 'since', 'last', 'week', '.', 'was', 'seen', 'on', 'for', 'ru', '##q', 'pain', 'with', 'essentially', 'normal', 'work', '-', 'up', '.', 're', '-', 'presented', 'today', 'with', 'severe', 'pain', 'and', 'nausea', '/', 'vomiting', ',', 'h', '##yp', '##ote', '##ns', '##ive', 'in', '?', 'new', 'afi', '##b', 'with', 'elevated', 'trans', '##amina', '##ses', ',', 'al', '##k', 'ph', '##os', 'and', 'bi', '##li', '##ru', '##bin', '.', 'treated', 'with', '2', '##l', 'iv', '##f', 'and', 'lev', '##aq', '##uin', 'and', 'transferred', 'here', 'to', 'ed', '.', 'on', 'arrival', 'here', ',', 'h', '##yp', '##ote', '##ns', '##ive', 'with', 'sb', '##ps', 'in', '80', \"'\", 's', ',', 'ta', '##chy', '##card', '##ic', 'in', 'afi', '##b', ',', 'men', '##tat', '##ing', 'well', '.', 'treated', 'with', '2', '##l', 'iv', '##f', ',', 'flag', '##yl', 'and', 'van', '##com', '##y', '##cin', ',', 'r', 'i', '##j', 'central', 'line', 'placed', 'by', 'ed', 'resident', '.', 'converted', 'to', 'sin', '##us', 'rhythm', 'in', 'ed', ',', 'pressures', 'improved', '.', 'admitted', 'to', 'west', 'sic', '##u', 'on', ',', 'transferred', 'to', 'on', 'for', 'er', '##cp', '.', 'er', '##cp', 'revealed', 'multiple', 'gall', '##stones', 'in', 'cb', '##d', 'and', 'large', 'amounts', 'of', 'pu', '##ru', '##lent', 'drainage', ';', 'cb', '##d', 'ste', '##nt', 'was', 'place', 'and', 'sp', '##hin', '##cter', '##oto', '##my', 'performed', '.', 'post', '-', 'er', '##cp', 'was', 'ex', '##tub', '##ated', ',', 'had', 'increased', 'work', 'of', 'breathing', '/', 'difficulty', 'oxygen', '##ating', 'and', 'was', 're', '-', 'int', '##uba', '##ted', '.', 'due', 'to', 'h', '##yp', '##ote', '##ns', '##ion', 'with', 'cv', '##ps', 'not', 'responding', 'to', 'multiple', 'fluid', 'bo', '##lus', '##es', ',', 'lev', '##op', '##hed', 'was', 'initiated', '.', 'currently', ',', 'pt', 'is', 'se', '##date', '##d', 'w', '/', 'prop', '##of', '##ol', 'and', 'int', '##uba', '##ted', 'on', 'ac', ',', 'vt', '600', 'x', '20', ',', 'pee', '##p', '8', '&', 'fi', '##o', '##2', '50', '%', '.', 'all', '##er', '##gies', ':', 'nk', '##da', 'last', 'dose', 'of', 'antibiotics', ':', 'piper', '##ac', '##ill', '##in', '/', 'ta', '##zo', '##ba', '##cta', '##m', '(', 'z', '##os', '##yn', ')', '-', '09', ':', '48', 'am', 'van', '##com', '##y', '##cin', '-', '02', ':', '37', 'pm', 'in', '##fusion', '##s', ':', 'prop', '##of', '##ol', '-', '25', 'mc', '##g', '/', 'kg', '/', 'min', 'nor', '##ep', '##ine', '##ph', '##rine', '-', '03', 'mc', '##g', '/', 'kg', '/', 'min', 'other', 'ic', '##u', 'medications', ':', 'met', '##op', '##rol', '##ol', '-', '02', ':', '00', 'am', 'fa', '##mot', '##idi', '##ne', '(', 'pep', '##ci', '##d', ')', '-', '07', ':', '57', 'am', 'fen', '##tan', '##yl', '-', '02', ':', '00', 'pm', 'mor', '##phine', 'sulfate', '-', '03', ':', '18', 'pm', 'other', 'medications', ':', 'past', 'medical', 'history', ':', 'family', 'history', ':', 'social', 'history', ':', 'obesity', 'd', '##m', 'cho', '##le', '##cy', '##sti', '##tis', 'h', '##t', '##n', 's', '/', 'pc', '##hole', '##cy', '##sto', '##sto', '##my', 'tube', 'occupation', ':', 'drugs', ':', 'tobacco', ':', 'alcohol', ':', 'other', ':', 'review', 'of', 'systems', ':', 'flows', '##hee', '##t', 'data', 'as', 'of', '09', ':', '10', 'pm', 'vital', 'signs', 'hem', '##od', '##yna', '##mic', 'monitoring', 'fluid', 'balance', '24', 'hours', 'since', '12', 'am', 't', '##max', ':', '6', 'c', '(', '9', 'tc', '##urrent', ':', '6', 'c', '(', '9', 'hr', ':', '76', '(', '73', '-', '86', ')', 'bp', '##m', 'bp', ':', '135', '/', '74', '(', '95', ')', '{', '101', '/', '50', '(', '71', ')', '-', '137', '/', '77', '(', '97', ')', '}', 'mm', '##hg', 'rr', ':', '0', '(', '0', '-', '33', ')', 'ins', '##p', '/', 'min', 'sp', '##o', '##2', ':', '97', '%', 'heart', 'rhythm', ':', 'sr', '(', 'sin', '##us', 'rhythm', ')', 'w', '##gt', '(', 'current', ')', ':', '153', 'kg', '(', 'admission', ')', ':', '153', 'kg', 'cv', '##p', ':', '25', '(', '15', '-', '26', ')', 'mm', '##hg', 'total', 'in', ':', '7', ',', '357', 'ml', 'po', ':', 't', '##f', ':', 'iv', '##f', ':', '6', ',', '60', '##7', 'ml', 'blood', 'products', ':', '750', 'ml', 'total', 'out', ':', '0', 'ml', '60', '##4', 'ml', 'urine', ':', '60', '##4', 'ml', 'ng', ':', 'stool', ':', 'drains', ':', 'balance', ':', '0', 'ml', '6', ',', '75', '##3', 'ml', 'respiratory', 'o', '##2', 'delivery', 'device', ':', 'end', '##ot', '##rac', '##hea', '##l', 'tube', 'vent', '##ila', '##tor', 'mode', ':', 'cm', '##v', '/', 'assist', '/', 'auto', '##flow', 'vt', '(', 'set', ')', ':', '600', '(', '550', '-', '600', ')', 'ml', 'rr', '(', 'set', ')', ':', '20', 'rr', '(', 'spontaneous', ')', ':', '3', 'pee', '##p', ':', '8', 'cm', '##h', '##2', '##o', 'fi', '##o', '##2', ':', '40', '%', 'pip', ':', '36', 'cm', '##h', '##2', '##o', 'plateau', ':', '27', 'cm', '##h', '##2', '##o', 'compliance', ':', '7', 'cm', '##h', '##2', '##o', '/', 'ml', 'sp', '##o', '##2', ':', '97', '%', 'ab', '##g', ':', '31', '/', '42', '/', '130', '/', '21', '/', '-', '4', 've', ':', '3', 'l', '/', 'min', 'pa', '##o', '##2', '/', 'fi', '##o', '##2', ':', '325', 'physical', 'examination', 'gen', ':', 'mor', '##bid', '##ly', 'obe', '##se', 'gentleman', ',', 'int', '##uba', '##ted', ',', 'se', '##date', '##d', 'but', 'opening', 'his', 'eyes', 'to', 'voice', 'hee', '##nt', ':', 'no', 'sc', '##ler', '##al', 'ict', '##erus', 'or', 'che', '##mi', '##osis', 'cv', ':', 'regular', 'rate', 'and', 'rhythm', ',', 'distant', 'heart', 'sounds', 'lungs', ':', 'decreased', 'bi', '##bas', '##ila', '##r', 'breath', 'sounds', ',', 'coarse', 'vent', '##ila', '##ted', 'breaths', 'abd', ':', 'mor', '##bid', '##ly', 'obe', '##se', ',', 'soft', ',', 'h', '##yp', '##oa', '##ctive', 'bs', ',', 'grimace', '##s', 'w', 'pal', '##pati', '##on', 'of', 'abd', ',', 'es', '##p', 'ru', '##q', 'but', 'cannot', 'accurately', 'assess', 'pain', 'ex', '##t', ':', 'chronic', 've', '##nous', 'st', '##asi', '##s', 'changes', ',', 'well', '-', 'per', '##fus', '##ed', '2', '+', 'd', '##p', ',', 'pt', 'pulses', 'b', '/', 'l', 'ne', '##uro', ':', 'int', '##uba', '##ted', ',', 'se', '##date', '##d', 'labs', '/', 'radio', '##logy', '213', 'k', '/', 'ul', '7', 'g', '/', 'dl', '100', 'mg', '/', 'dl', '1', 'mg', '/', 'dl', '51', 'mg', '/', 'dl', '21', 'me', '##q', '/', 'l', '105', 'me', '##q', '/', 'l', '0', 'me', '##q', '/', 'l', '140', 'me', '##q', '/', 'l', '0', '%', '6', 'k', '/', 'ul', '2', ':', '33', 'a1', '##1', '/', '24', '/', '03', ':', '00', 'am', '10', ':', '20', 'p', '##11', '/', '24', '/', '03', ':', '41', 'pm', '1', ':', '20', 'p', '##11', '/', '24', '/', '05', ':', '14', 'pm', '11', ':', '50', 'p', '##11', '/', '24', '/', '05', ':', '47', 'pm', '1', ':', '20', 'a1', '##1', '/', '24', '/', '06', ':', '20', 'pm', '7', ':', '20', 'p', '1', '/', '/', '11', '/', '00', '##6', '1', ':', '23', 'p', '1', ':', '20', 'p', '11', ':', '20', 'p', '4', ':', '20', 'p', 'wb', '##c', '3', '6', 'hc', '##t', '2', '0', 'pl', '##t', '243', '213', 'cr', '4', '1', 'tr', '##op', '##t', '<', '01', '<', '01', 'tc', '##0', '##2', '22', '22', '22', 'glucose', '182', '100', 'other', 'labs', ':', 'pt', '/', 'pt', '##t', '/', 'in', '##r', ':', '6', '/', '9', '/', '3', ',', 'ck', '/', 'ck', '##mb', '/', 'tr', '##op', '##oni', '##n', '-', 't', ':', '176', '/', '4', '/', '<', '01', ',', 'alt', '/', 'as', '##t', ':', '72', '/', '67', ',', 'al', '##k', 'ph', '##os', '/', 't', 'bi', '##li', ':', '39', '##1', '/', '4', ',', 'amy', '##lase', '/', 'lip', '##ase', ':', '17', '/', '18', ',', 'differential', '-', 'ne', '##uts', ':', '1', '%', ',', 'l', '##ym', '##ph', ':', '5', '%', ',', 'mono', ':', '8', '%', ',', 'e', '##os', ':', '4', '%', ',', 'lac', '##tic', 'acid', ':', '0', 'mm', '##ol', '/', 'l', ',', 'ld', '##h', ':', '183', 'i', '##u', '/', 'l', ',', 'ca', '+', '+', ':', '2', 'mg', '/', 'dl', ',', 'mg', '+', '+', ':', '2', 'mg', '/', 'dl', ',', 'po', '##4', ':', '4', 'mg', '/', 'dl', 'ct', 'abd', ':', 'mild', 'fat', 'strand', '##ing', 'extending', 'from', 'gall', '##bla', '##dder', 'to', 'anterior', 'abdominal', 'wall', ',', 'indicating', 'tract', 'associated', 'w', 'previous', 'cho', '##le', '##cy', '##sto', '##sto', '##my', 'tube', '.', 'no', 'lo', '##cula', '##ted', 'collections', 'or', 'abc', '##ess', '.', 'mildly', 'thick', '##ened', 'gall', '##bla', '##dder', 'wall', '.', 'no', 'stones', '.', 'no', 'intra', '##he', '##pati', '##c', 'bi', '##lia', '##ry', 'dil', '##ation', 'assessment', 'and', 'plan', '~', '65', 'year', '-', 'old', 'mor', '##bid', '##ly', 'obe', '##se', 'gentleman', 'w', '/', 'd', '##m', '##2', 'and', 'history', 'of', 'cho', '##le', '##cy', '##sti', '##tis', 'admitted', 'for', 'cho', '##lang', '##itis', ',', 's', '/', 'p', 'er', '##cp', 'w', '/', 'cb', '##d', 'ste', '##nt', 'placement', ',', 'extraction', 'of', 'cb', '##d', 'stones', 'and', 'sp', '##hin', '##cter', '##oto', '##my', ',', 'currently', 'se', '##date', '##d', ',', 'int', '##uba', '##ted', 'and', 'on', 'press', '##ors', '.', 'h', '##yp', '##ote', '##ns', '##ion', '/', 'sep', '##sis', '-', 'h', '##yp', '##ote', '##ns', '##ion', 'is', 'likely', 'due', 'to', 'sep', '##sis', 'as', 'pressures', 'not', 'responding', 'to', 'fluid', 'bo', '##lus', '##es', '.', 'cv', '##p', 'goal', 'is', ';', 'however', ',', 'cv', '##p', 'measurements', 'have', 'been', 'unreliable', 'in', 'this', 'patient', '.', 'surgery', 'wants', 'to', 'run', 'maintenance', 'iv', '##f', 'l', '##r', '@', '150', '##cc', '/', 'hr', 'for', '2', '##l', '.', 'would', 'prefer', 'to', 'give', 'fluid', 'bo', '##lus', '##es', 'and', 'we', '##an', 'off', 'lev', '##op', '##hed', 'but', 'will', 'follow', 'surgery', \"'\", 's', 'management', '.', 'likely', 'h', '##yp', '##ote', '##ns', '##ive', 'from', 'sep', '##sis', 'from', 'known', 'infection', 'continue', 'anti', '##biotic', 'mg', '##t', 'fluid', 'bo', '##lus', '##es', ',', 'we', '##an', 'off', 'press', '##ors', 'need', 'tee', 'when', 'no', 'longer', 'ba', '##cter', '##emi', '##c', 'to', 'r', '/', 'o', 'end', '##oca', '##rdi', '##tis', 'as', 'blood', 'c', '##x', 'are', 'growing', 'gp', '##cs', 'in', 'clusters', '(', 'likely', 'st', '##ap', '##h', ')', 'f', '/', 'u', 'surveillance', 'bc', '##x', 'daily', 'send', 'uc', '##x', ',', 'u', '/', 'a', ',', 'ul', '##yte', '##s', ',', 'bc', '##x', 'pt', 'was', 'not', 'feb', '##ril', '##e', 'on', 'admission', ',', 'but', 'had', 'ru', '##q', 'pain', 'and', 't', 'bi', '##li', '4', '(', 'ja', '##und', '##ice', ')', '.', 'also', 'has', 'h', '##yp', '##ote', '##ns', '##ion', 'and', 'renal', 'failure', ',', 'but', 'unable', 'to', 'assess', 'mental', 'status', 'so', 'could', 'be', 'char', '##cot', \"'\", 's', 'triad', '+', '/', '-', 'pen', '##tad', '.', 'patient', 'is', 's', '/', 'p', 'er', '##cp', 'w', '/', 'sp', '##hin', '##cter', '##oto', '##my', 'and', 'extraction', 'of', 'gall', '##stones', 'and', 'pu', '##ru', '##lent', 'material', '.', 'continue', 'anti', '##biotic', 'coverage', 'with', 'z', '##os', '##yn', 'which', 'will', 'cover', 'g', '##nr', '##s', 'from', 'int', '##estinal', 'flora', 'trans', '##lo', '##cation', 'and', 'ana', '##ero', '##bes', 'continue', 'van', '##com', '##y', '##cin', 'for', 'known', 'gp', '##c', \"'\", 's', 'in', 'clusters', 'respiratory', 'distress', '-', 'respiratory', 'distress', 'due', 'to', 'body', 'habit', '##us', '-', 'has', 'short', 'ins', '##pi', '##rator', '##y', 'phase', 'and', 'prolonged', 'ex', '##piration', 'with', 'massive', 'rebound', 'of', 'his', 'pan', '##nus', 'which', 'could', 'cause', 'vent', '##ila', '##tor', 'to', 'deliver', 'additional', 'breaths', '.', 'other', 'considerations', 'could', 'include', 'pneumonia', ',', 'ate', '##le', '##cta', '##sis', 'ar', '##ds', ',', 'volume', 'over', '##load', 'states', ';', 'however', ',', 'primary', 'pulmonary', 'process', 'is', 'less', 'likely', 'given', 'known', 'cho', '##lang', '##itis', '/', 'ba', '##cter', '##emia', '.', 'c', '##x', '##r', 'does', 'not', 'show', 'con', '##sol', '##ida', '##tive', 'process', 'or', 'b', '/', 'l', 'fluffy', 'infiltrate', '##s', 'and', 'most', 'recent', 'pa', '##o', '##2', '/', 'fi', '##o', '##2', 'ratio', '=', '130', '/', '5', '-', '>', '260', '(', '<', '200', 'for', 'ar', '##ds', ')', 'keep', 'int', '##uba', '##ted', 'on', 'current', 'settings', ',', 'try', 'to', 'we', '##an', 'fi', '##o', '##2', 'to', '40', '%', 'while', 'following', 'serial', 'ab', '##gs', 'keep', 'se', '##dation', 'on', 'current', 'settings', 'need', 'c', '##x', '##r', 'in', 'am', 'to', 'confirm', 'placement', 'et', '##t', 'and', 'ng', '##t', '(', 'c', '##x', '##r', 'post', '-', 'tuba', '##tion', 'revealed', 'et', '##t', '8', '##cm', 'above', 'car', '##ina', ',', 'ng', '##t', 'not', 'well', 'visual', '##ized', ',', 'wouldn', \"'\", 't', 'use', 'it', 'yet', ')', '.', 'he', 'was', 'a', 'difficult', 'int', '##uba', '##tion', 'and', 'an', '##esthesia', \"'\", 's', 'initial', 'attempt', 'resulted', 'in', 'r', 'main', '##ste', '##m', 'bro', '##nch', '##us', 'int', '##uba', '##tion', ',', 'so', 'low', 'threshold', 'for', 're', '-', 'imaging', 'if', 'acute', '##ly', 'worse', '##ns', 'on', 'vent', 'settings', 'ol', '##ig', '##uria', '-', 'poor', 'urine', 'output', 'could', 'be', 'poor', 'renal', 'per', '##fusion', 'from', 'h', '##yp', '##ote', '##ns', '##ion', 'leading', 'to', 'at', '##n', 'or', 'due', 'to', 'volume', 'de', '##ple', '##tion', '.', 'will', 'check', 'urine', 'l', '##yte', '##s', 'and', 'e', '##o', \"'\", 's', ',', 'urine', 'os', '##ms', 'if', 'at', '##n', ',', 'unlikely', 'to', 'respond', 'to', 'fluid', 'bo', '##lus', '##es', 'will', 'trend', 'bun', '/', 'cr', 'access', ':', 'r', '-', 'i', '##j', '(', '3', '##lum', '##en', ')', ',', '3', 'pi', '##v', \"'\", 's', '(', \"'\", 's', 'and', ')', 'fen', '/', 'gi', ':', 'np', '##o', ',', 'not', 'on', 'pp', '##i', ',', 'insulin', 'gt', '##t', ',', 'iv', '##f', '-', 'l', '##r', '@', '150', '##cc', '/', 'hr', 'for', '2', '##l', 'pp', '##x', ':', 've', '##no', '##dy', '##nes', ',', 'sc', 'he', '##par', '##in', 'code', ':', 'full', 'ic', '##u', 'care', 'nutrition', ':', 'np', '##o', 'g', '##ly', '##ce', '##mic', 'control', ':', 'insulin', 'gt', '##t', 'lines', ':', 'multi', 'lu', '##men', '-', '12', ':', '59', 'am', '20', 'gauge', '-', '01', ':', '47', 'am', '18', 'gauge', '-', '01', ':', '47', 'am', 'arterial', 'line', '-', '10', ':', '30', 'am', 'prop', '##hyl', '##ax', '##is', ':', 'd', '##v', '##t', ':', 've', '##no', '##dy', '##nes', ',', 'he', '##par', '##in', 'sq', 'stress', 'ul', '##cer', ':', 'fa', '##mot', '##idi', '##ne', 'va', '##p', ':', 'bundle', 'comments', ':', 'communication', ':', 'comments', ':', 'hc', '##p', 'is', 'pc', '##p', 'status', ':', 'full', 'disposition', ':', 'til', 'sic', '##u', 'x', '-', 'fe', '##r', 'protected', 'section', 'mic', '##u', 'attending', 'add', '##end', '##um', 'i', 'saw', 'and', 'examined', 'the', 'patient', ',', 'and', 'was', 'physically', 'present', 'with', 'the', 'ic', '##u', 'team', 'for', 'the', 'key', 'portions', 'of', 'the', 'services', 'provided', '.', 'i', 'agree', 'with', 'the', 'note', 'above', ',', 'including', 'the', 'assessment', 'and', 'plan', '.', 'i', 'would', 'emphasize', 'and', 'add', 'the', 'following', 'points', ':', '65', '##m', 'obesity', ',', 'd', '##m', ',', 'h', '##t', '##n', ',', 'cho', '##lang', '##itis', 's', '/', 'p', 'per', '##c', 'cho', '##le', 'at', 'os', '##h', ',', 'er', '##cp', 'today', '-', 'sp', '##hin', '##cter', '##oto', '##my', 'and', 'ste', '##nt', ',', 'rep', '##ira', '##tory', 'failure', 'following', 'ex', '##tub', '##ation', '.', 'currently', 'on', 'press', '##ors', 'and', 'va', '##c', ',', 'bc', '##x', 'gp', '##c', '/', 'clusters', '.', 'exam', 'notable', 'for', 't', '##m', '7', 'bp', '110', '/', '70', 'hr', '78', 'rr', '20', 'with', 'sat', 'on', 'va', '##c', '600', '##x', '##20', '5', '8', '31', '/', '42', '/', 'obe', '##se', 'man', ',', 'awake', ',', 'no', 'discomfort', '.', 'distant', 'bs', 'b', '.', 'ct', '##ab', '.', 'soft', ',', 'obe', '##se', ',', 'min', 'bs', '.', '1', '+', 'ed', '##ema', '.', 'labs', 'notable', 'for', 'wb', '##c', '10', '##k', ',', 'hc', '##t', '27', ',', 'k', '+', '0', ',', 'cr', '1', ',', 'lac', '##tate', 'agree', 'with', 'plan', 'to', 'manage', 'cho', '##lang', '##itis', 'c', '/', 'b', 'sept', '##ic', 'shock', 'with', 'aggressive', 'fluid', 'res', '##us', '##cit', '##ation', ',', 'van', '##co', '/', 'z', '##os', '##yn', ',', 'f', '/', 'u', 'c', '##x', 'results', ',', 'and', 'consider', 'tee', '.', 'tonight', ',', 'we', 'will', 'monitor', 'cv', '##p', ',', 'cv', '##o', '##2', ',', 'serial', 'lac', '##tate', '##s', 'and', 'will', 'check', 'sv', '##v', 'to', 'assess', 'pre', '##load', 'dependence', 'if', 'he', 'goes', 'back', 'on', 'press', '##ors', '.', 'for', 'respiratory', 'failure', ',', 'mechanics', 'reflect', 'poor', 'compliance', ',', 'much', 'of', 'which', 'is', 'likely', 'd', '/', 't', 'obesity', 'and', 'restriction', ',', 'may', 'benefit', 'from', 'es', '##op', '##h', 'pressure', 'monitoring', 'if', 'he', 'doesn', \"'\", 't', 'mob', '##ili', '##ze', 'fluid', 'overnight', '.', 'for', 'now', 'will', 'decrease', 'vt', 'to', '6', '##cc', '/', 'kg', 'and', 'maintain', 'pee', '##p', 'of', 'for', 'ar', '##f', ',', 'give', 'iv', '##f', 'and', 'monitor', 'u', '##op', ',', 'rd', 'med', '##s', '.', 'will', 'keep', 'np', '##o', 'for', 'now', '.', 'pi', '##v', ',', 'h', '##2', '##b', ',', 'hs', '##c', ',', 'ri', '##ss', ',', 'full', '.', 'to', 'sic', '##u', 'in', 'am', '.', 'remainder', 'of', 'plan', 'as', 'outlined', 'above', '.', 'patient', 'is', 'critically', 'ill', 'total', 'time', ':', '50', 'min', 'protected', 'section', 'add', '##end', '##um', 'entered', 'by', ':', ',', 'md', 'on', ':', '00', ':', '38']\n","chunk 135 tokenize start!\n","First sentence tokenized\n","['cv', '##ic', '##u', 'hp', '##i', ':', 'hd', '##4', 'pod', '2', '-', 's', '/', 'p', 'ascending', 'ao', '##rta', 'replacement', 'res', '##us', '##pen', '##sion', 'av', '##r', 'e', '##ject', '##ion', 'fraction', ':', '55', '%', 'pre', '-', 'op', 'weight', ':', '5', 'lbs', '110', 'kg', '##s', 'baseline', 'cr', '##ea', '##tin', '##ine', ':', '4', '(', 'acute', ')', 'pm', '##h', '##x', ':', 'h', '##t', '##n', ',', 's', '/', 'p', 't', '+', 'a', ':', 'hc', '##tz', '?', 'dose', 'current', 'medications', ':', 'ace', '##tam', '##ino', '##ph', '##en', 'all', '##op', '##uri', '##no', '##l', 'al', '##bu', '##terol', '-', 'ip', '##rat', '##rop', '##ium', 'ami', '##oda', '##rone', 'as', '##pi', '##rin', 'ce', '##fa', '##zo', '##lin', 'ch', '##lor', '##he', '##xi', '##dine', 'g', '##lu', '##cona', '##te', '12', '%', 'oral', 'ri', '##nse', 'doc', '##usa', '##te', 'sodium', '(', 'liquid', ')', 'fen', '##tan', '##yl', 'ci', '##tra', '##te', 'fur', '##ose', '##mide', 'he', '##par', '##in', 'hydra', '##la', '##zine', 'insulin', 'lab', '##eta', '##lo', '##l', 'magnesium', 'sulfate', 'met', '##op', '##rol', '##ol', 'tar', '##tra', '##te', 'met', '##oc', '##lo', '##pr', '##ami', '##de', 'mid', '##az', '##ola', '##m', 'milk', 'of', 'mag', '##nesia', 'nic', '##ard', '##ip', '##ine', 'ni', '##tro', '##gly', '##cer', '##in', 'ph', '##en', '##yle', '##ph', '##rine', 'rani', '##ti', '##dine', 'tam', '##sul', '##osi', '##n', '24', 'hour', 'events', ':', 'h', '##yp', '##ox', '##ia', '^', 'pee', '##p', ',', 'afi', '##b', 'tx', 'w', '/', 'bb', 'and', 'ami', '##oda', '##rone', ',', 'converted', 'to', 'sr', 'las', '##ix', 'gt', '##t', 'for', 'dir', '##ues', '##is', '.', 'post', 'operative', 'day', ':', 'pod', '#', '2', '-', 'ascending', 'ao', '##rta', 'graf', '##t', 'all', '##er', '##gies', ':', 'no', 'known', 'drug', 'all', '##er', '##gies', 'last', 'dose', 'of', 'antibiotics', ':', 'ce', '##fa', '##zo', '##lin', '-', '08', ':', '14', 'am', 'in', '##fusion', '##s', ':', 'fen', '##tan', '##yl', '(', 'concentrate', ')', '-', '50', 'mc', '##g', '/', 'hour', 'mid', '##az', '##ola', '##m', '(', 'verse', '##d', ')', '-', '8', 'mg', '/', 'hour', 'fur', '##ose', '##mide', '(', 'las', '##ix', ')', '-', '5', 'mg', '/', 'hour', 'ami', '##oda', '##rone', '-', '1', 'mg', '/', 'min', 'other', 'ic', '##u', 'medications', ':', 'fur', '##ose', '##mide', '(', 'las', '##ix', ')', '-', '09', ':', '19', 'pm', 'met', '##op', '##rol', '##ol', '-', '10', ':', '10', 'pm', 'he', '##par', '##in', 'sodium', '(', 'prop', '##hyl', '##ax', '##is', ')', '-', '08', ':', '28', 'am', 'rani', '##ti', '##dine', '(', 'prop', '##hyl', '##ax', '##is', ')', '-', '08', ':', '29', 'am', 'other', 'medications', ':', 'flows', '##hee', '##t', 'data', 'as', 'of', '09', ':', '01', 'am', 'vital', 'signs', 'hem', '##od', '##yna', '##mic', 'monitoring', 'fluid', 'balance', '24', 'hours', 'since', 'a', '.', 'm', '.', 't', '##max', ':', '5', 'c', '(', '5', 't', 'current', ':', '5', 'c', '(', '5', 'hr', ':', '103', '(', '57', '-', '136', ')', 'bp', '##m', 'bp', ':', '110', '/', '66', '(', '78', ')', '{', '84', '/', '51', '(', '60', ')', '-', '137', '/', '75', '(', '91', ')', '}', 'mm', '##hg', 'rr', ':', '11', '(', '11', '-', '30', ')', 'ins', '##p', '/', 'min', 'sp', '##o', '##2', ':', '95', '%', 'heart', 'rhythm', ':', 'af', '(', 'at', '##rial', 'fi', '##bri', '##llation', ')', 'w', '##gt', '(', 'current', ')', ':', '117', 'kg', '(', 'admission', ')', ':', '6', 'kg', 'height', ':', '70', 'inch', 'total', 'in', ':', '1', ',', '92', '##4', 'ml', '82', '##1', 'ml', 'po', ':', 'tube', 'feeding', ':', '85', 'ml', '250', 'ml', 'iv', 'fluid', ':', '1', ',', '83', '##9', 'ml', '510', 'ml', 'blood', 'products', ':', 'total', 'out', ':', '2', ',', '48', '##5', 'ml', '1', ',', '110', 'ml', 'urine', ':', '2', ',', '375', 'ml', '1', ',', '110', 'ml', 'ng', ':', '50', 'ml', 'stool', ':', 'drains', ':', 'balance', ':', '-', '56', '##1', 'ml', '-', '289', 'ml', 'respiratory', 'support', 'o', '##2', 'delivery', 'device', ':', 'end', '##ot', '##rac', '##hea', '##l', 'tube', 'vent', '##ila', '##tor', 'mode', ':', 'cm', '##v', '/', 'assist', '/', 'auto', '##flow', 'vt', '(', 'set', ')', ':', '600', '(', '600', '-', '600', ')', 'ml', 'vt', '(', 'spontaneous', ')', ':', '65', '##6', '(', '65', '##6', '-', '65', '##6', ')', 'ml', 'ps', ':', '15', 'cm', '##h', '##2', '##o', 'rr', '(', 'set', ')', ':', '12', 'rr', '(', 'spontaneous', ')', ':', '6', 'pee', '##p', ':', '15', 'cm', '##h', '##2', '##o', 'fi', '##o', '##2', ':', '40', '%', 'rs', '##bi', 'def', '##erre', '##d', ':', 'pee', '##p', '>', '10', 'pip', ':', '33', 'cm', '##h', '##2', '##o', 'plateau', ':', '22', 'cm', '##h', '##2', '##o', 'compliance', ':', '7', 'cm', '##h', '##2', '##o', '/', 'ml', 'sp', '##o', '##2', ':', '95', '%', 'ab', '##g', ':', '39', '/', '40', '/', '/', '25', '/', '0', 've', ':', '3', 'l', '/', 'min', 'pa', '##o', '##2', '/', 'fi', '##o', '##2', ':', '245', 'physical', 'examination', 'labs', '/', 'radio', '##logy', '106', 'k', '/', 'ul', '4', 'g', '/', 'dl', '122', 'mg', '/', 'dl', '7', 'mg', '/', 'dl', '25', 'me', '##q', '/', 'l', '7', 'me', '##q', '/', 'l', '61', 'mg', '/', 'dl', '108', 'me', '##q', '/', 'l', '142', 'me', '##q', '/', 'l', '3', '%', '9', 'k', '/', 'ul', '12', ':', '00', 'pm', '12', ':', '19', 'pm', '01', ':', '29', 'pm', '02', ':', '43', 'pm', '04', ':', '16', 'pm', '08', ':', '18', 'pm', '11', ':', '41', 'pm', '02', ':', '14', 'am', '02', ':', '40', 'am', '06', ':', '11', 'am', 'wb', '##c', '9', 'hc', '##t', '3', 'pl', '##t', '106', 'cr', '##ea', '##tin', '##ine', '4', '7', 'tc', '##o', '##2', '24', '23', '22', '24', '25', '25', '27', '25', 'glucose', '140', '125', '110', '122', 'other', 'labs', ':', 'pt', '/', 'pt', '##t', '/', 'in', '##r', ':', '4', '/', '0', '/', '1', ',', 'ck', '/', 'ck', '-', 'mb', '/', 'tr', '##op', '##oni', '##n', 't', ':', '35', '##8', '/', '/', ',', 'alt', '/', 'as', '##t', ':', '69', '/', '68', ',', 'al', '##k', '-', 'ph', '##os', '/', 't', 'bi', '##li', ':', '43', '/', '6', ',', 'amy', '##lase', '/', 'lip', '##ase', ':', '23', '/', '19', ',', 'fi', '##bri', '##no', '##gen', ':', '214', 'mg', '/', 'dl', ',', 'lac', '##tic', 'acid', ':', '8', 'mm', '##ol', '/', 'l', ',', 'ca', ':', '3', 'mg', '/', 'dl', ',', 'mg', ':', '0', 'mg', '/', 'dl', ',', 'po', '##4', ':', '1', 'mg', '/', 'dl', 'assessment', 'and', 'plan', 'acute', 'respiratory', 'distress', 'syndrome', '(', 'ar', '##ds', ',', 'acute', 'lung', 'injury', ',', ')', ',', 'anxiety', ',', 'ao', '##rti', '##c', 'di', '##sse', '##ction', ',', 'per', '##ica', '##rdial', 'e', '##ff', '##usion', 'with', 'tam', '##pon', '##ade', 'assessment', 'and', 'plan', ':', 'assessment', ':', '61', 'year', 'old', 'male', 'repair', 'of', 'type', 'a', 'ao', '##rti', '##c', 'di', '##sse', '##ction', '-', '28', '-', 'mm', 'da', '##cr', '##on', 'inter', '##position', 'tube', 'graf', '##t', 'from', 'the', 'sino', '##tub', '##ular', 'junction', '>', 'pro', '##xi', '##mal', 'arch', 'using', 'deep', 'h', '##yp', '##oth', '##er', '##mic', 'ci', '##rc', '##ulator', '##y', 'arrest', 'ne', '##uro', '##logic', ':', 'pain', 'controlled', ',', 'mor', '##phine', 'pr', '##n', '.', 'cardiovascular', ':', 'as', '##pi', '##rin', ',', 'beta', '-', 'block', '##er', ',', 'stat', '##ins', 'pulmonary', ':', 'con', '##t', 'et', '##t', ',', '(', 'vent', '##ila', '##tor', 'mode', ':', 'cm', '##v', ')', ',', 'we', '##an', 'pee', '##p', 'as', 'tolerated', 'today', '.', 'consider', 'ps', 'if', 'able', 'to', 'we', '##an', 'below', 'pee', '##p', 'of', 'gas', '##tro', '##int', '##estinal', '/', 'abdomen', ':', 'og', '##t', 'nutrition', ':', 'tube', 'feeding', 'renal', ':', 'foley', ',', 'adequate', 'u', '##o', ',', 'con', '##t', 'las', '##ix', 'gt', '##t', 'for', 'goal', '1', '-', '2', 'liter', '##s', 'negative', 'today', '.', 'hem', '##ato', '##logy', ':', 'mod', 'an', '##emia', '>', 'con', '##t', 'to', 'follow', '.', 'end', '##oc', '##rine', ':', 'ri', '##ss', 'infectious', 'disease', ':', 'an', '##ce', '##f', 'for', 'stern', '##al', 'wound', 'drainage', '.', 'lines', '/', 'tubes', '/', 'drains', ':', 'foley', ',', 'et', '##t', ',', 'pacing', 'wires', 'wounds', ':', 'dry', 'dressing', '##s', 'imaging', ':', 'c', '##x', '##r', 'today', 'fluids', ':', 'kv', '##o', 'consult', '##s', ':', 'ct', 'surgery', ',', 'ne', '##ph', '##rol', '##ogy', 'billing', 'diagnosis', ':', 'ar', '##rh', '##yt', '##hmi', '##a', ',', '(', 'respiratory', 'distress', ':', 'failure', ')', ',', 'post', '-', 'op', 'hyper', '##tension', ',', 'acute', 'renal', 'failure', 'ic', '##u', 'care', 'nutrition', ':', 'nova', '##so', '##ur', '##ce', 'renal', '(', 'full', ')', '-', '07', ':', '39', 'am', '40', 'ml', '/', 'hour', 'g', '##ly', '##ce', '##mic', 'control', ':', 'regular', 'insulin', 'sliding', 'scale', 'lines', ':', 'arterial', 'line', '-', '03', ':', '18', 'am', '-', '03', ':', '20', 'am', 'prop', '##hyl', '##ax', '##is', ':', 'd', '##v', '##t', ':', 'boots', ',', 'sq', 'u', '##f', 'he', '##par', '##in', 'stress', 'ul', '##cer', ':', 'h', '##2', 'block', '##er', 'va', '##p', 'bundle', ':', 'ho', '##b', 'elevation', ',', 'mouth', 'care', ',', 'daily', 'wake', 'up', ',', 'rs', '##bi', 'comments', ':', 'communication', ':', 'patient', 'discussed', 'on', 'interdisciplinary', 'rounds', ',', 'ic', '##u', 'code', 'status', ':', 'full', 'code', 'disposition', ':', 'ic', '##u', 'total', 'time', 'spent', ':', '33', 'minutes', 'patient', 'is', 'critically', 'ill']\n","chunk 136 tokenize start!\n","First sentence tokenized\n","['altered', 'mental', 'status', 'assessment', ':', 'pt', 'opens', 'eyes', 'sp', '##ont', ',', 'mae', 's', ',', 'follows', 'commands', 'at', 'times', ',', 'nods', 'appropriately', 'at', 'times', ',', 'but', 'then', 'has', 'moments', 'of', 'inc', '##omp', '##re', '##hen', '##sible', 'sounds', '.', 'non', 'verbal', 'most', 'of', 'night', ',', 'pupils', 'equal', 'and', 'reactive', 'bi', '##lat', 'action', ':', 'q', '4', 'hour', 'ne', '##uro', 'checks', ',', 're', '##ori', '##ented', 'pt', 'throughout', 'night', 'response', ':', 'no', 'changes', 'in', 'mental', 'status', 'plan', ':', 'con', '##t', 'to', 'reassure', 'pt', 'that', 'he', 'is', 'safe', ',', 're', '##ori', '##ent', 'pt', 'throughout', 'shift', '.', 'int', '##est', '##ine', ',', 'per', '##for', '##ation', 'of', '(', 'per', '##for', '##ation', 'of', 'hollow', 'vis', '##cus', ')', 'assessment', ':', 'abd', 'softly', 'di', '##sten', '##ded', ',', 'g', 'tube', 'to', 'tube', '##fe', '##ed', '##s', ',', 'left', 'jp', 'to', 'bulb', 's', '##x', '##n', '-', 'tan', 'drainage', '.', ',', 'ile', '##ost', '##omy', 'to', 'gravity', 'drainage', ',', 'wound', 'va', '##c', 'to', 'abdomen', 'tan', '/', 'yellow', 'drainage', 'action', ':', 'wound', 'va', '##c', 'kept', 'alarm', '##ing', 'in', 'beginning', 'of', 'shift', '-', 'block', '##age', ',', 'increased', 'drainage', 'via', 'jp', '.', 'wound', 'va', '##c', 'changed', 'by', 'doctor', '.', 'white', 'sponge', 'in', 'bottom', 'of', 'wound', 'and', 'black', 'sponge', 'on', 'top', '.', 'dil', '##aud', '##id', 'iv', '##p', 'given', 'to', 'pt', 'for', 'dressing', 'change', 'response', ':', 'wound', 'va', '##c', 'intact', ',', 'tissue', 'gran', '##ulating', 'at', 'distal', 'end', 'of', 'wound', ',', 'increased', 'drainage', 'at', 'top', 'half', 'of', 'wound', 'with', 'tissue', 'that', 'had', 'ex', '##uda', '##te', '/', 'and', 'very', 'little', 'gran', '##ulating', 'tissue', '.', 'l', '##rg', 'am', '##t', 'of', 'drainage', 'throughout', 'night', 'from', 'wound', 'va', '##c', 'and', 'jp', '.', 'jp', 'drainage', 'slowed', 'down', 'after', 'wound', 'va', '##c', 'dressing', 'was', 'changed', '.', 'pt', 'appeared', 'comfortable', 'after', 'receiving', 'dil', '##aud', '##id', '.', '.', 'plan', ':', 'con', '##t', 'to', 'assess', 'pat', '##ency', 'of', 'wound', 'va', '##c', ',', 'assess', 'drainage', 'from', 'drains', 'q', 'hours', '.', 'alteration', 'in', 'nutrition', 'assessment', ':', 'pt', 's', 'abdomen', 'softly', 'di', '##sten', '##ded', ',', 'h', '##yp', '##oa', '##ctive', 'bs', ',', 'ile', '##ost', '##omy', '-', 'st', '##oma', 'pink', ',', 'nothing', 'per', 'rec', '##tum', '.', 'stage', '2', 'pressure', 'ul', '##cer', 'to', 'co', '##cc', '##yx', ',', 'sc', '##rot', '##al', 'area', 'with', 'fungal', 'rash', '.', 'na', 'high', 'action', ':', 'pt', 'continues', 'with', 't', '##p', '##n', 'with', 'lip', '##ids', ',', 'tube', '##fe', '##ed', '##s', 'in', '##fus', '##ing', 'at', '30', '##cc', '/', 'hr', ',', 'residual', 'checks', 'q', '4', 'hours', ',', 'keeping', 'pt', 'off', 'of', 'bottom', 'to', 'help', 'heal', 'stage', '2', ',', 'me', '##pile', '##x', 'dressing', 'on', 'co', '##cc', '##yx', ',', 'anti', '##fu', '##nga', '##l', 'cream', 'and', 'ny', '##sta', '##tin', 'to', 'per', '##i', 'area', '.', 'continue', 'with', '300', '##cc', 'free', 'water', 'flush', '##es', 'q', '4', 'hours', 'response', ':', 'residual', '##s', 'have', 'decreased', 'from', 'the', 'day', 'shift', '-', 'able', 'to', 'increase', 'tube', '##fe', '##ed', '##s', 'to', '40', '##cc', '/', 'hr', ',', 'ile', '##ost', '##omy', 'draining', 'liquid', 'brown', '.', 'plan', ':', 'con', '##t', 'to', 'assess', 'changes', 'in', 'skin', 'integrity', ',', 'con', '##t', 'to', 'check', 'for', 'high', 'residual', '##s', ',', 'increase', 'tube', '##fe', '##ed', '##s', 'as', 'tolerated', 'until', 'at', 'goal', '.']\n","chunk 137 tokenize start!\n","First sentence tokenized\n","['chief', 'complaint', ':', '24', 'hour', 'events', ':', 'no', 'overnight', 'events', 'patient', 'subjective', '##ly', 'feels', 'like', 'he', 'is', 'breathing', 'better', 'all', '##er', '##gies', ':', 'ami', '##oda', '##rone', 'worse', '##ning', 'cop', '##d', ';', 'pro', '##sca', '##r', '(', 'oral', ')', '(', 'fin', '##aster', '##ide', ')', 'breast', 'sen', '##sit', '##iv', 'so', '##tal', '##ol', 'unknown', ';', 'last', 'dose', 'of', 'antibiotics', ':', 'ce', '##ft', '##ria', '##xon', '##e', '-', '11', ':', '45', 'pm', 'in', '##fusion', '##s', ':', 'other', 'ic', '##u', 'medications', ':', 'he', '##par', '##in', 'sodium', '(', 'prop', '##hyl', '##ax', '##is', ')', '-', '04', ':', '00', 'am', 'other', 'medications', ':', 'changes', 'to', 'medical', 'and', 'family', 'history', ':', 'review', 'of', 'systems', 'is', 'unchanged', 'from', 'admission', 'except', 'as', 'noted', 'below', 'review', 'of', 'systems', ':', 'flows', '##hee', '##t', 'data', 'as', 'of', '06', ':', '31', 'am', 'vital', 'signs', 'hem', '##od', '##yna', '##mic', 'monitoring', 'fluid', 'balance', '24', 'hours', 'since', '12', 'am', 't', '##max', ':', '9', 'c', '(', '4', 'tc', '##urrent', ':', '1', 'c', '(', '97', 'hr', ':', '85', '(', '70', '-', '102', ')', 'bp', '##m', 'bp', ':', '119', '/', '72', '(', '82', ')', '{', '112', '/', '69', '(', '82', ')', '-', '126', '/', '78', '(', '87', ')', '}', 'mm', '##hg', 'rr', ':', '13', '(', '13', '-', '26', ')', 'ins', '##p', '/', 'min', 'sp', '##o', '##2', ':', '99', '%', 'heart', 'rhythm', ':', 'av', 'paced', 'total', 'in', ':', '325', 'ml', 'po', ':', 't', '##f', ':', 'iv', '##f', ':', '85', 'ml', 'blood', 'products', ':', 'total', 'out', ':', '525', 'ml', '213', 'ml', 'urine', ':', '525', 'ml', '213', 'ml', 'ng', ':', 'stool', ':', 'drains', ':', 'balance', ':', '-', '200', 'ml', '-', '213', 'ml', 'respiratory', 'support', 'o', '##2', 'delivery', 'device', ':', 'nasal', 'can', '##nu', '##la', 'sp', '##o', '##2', ':', '99', '%', 'ab', '##g', ':', '45', '/', '47', '/', '114', '/', '35', '/', '8', 'physical', 'examination', 'general', ':', 'alert', ',', 'oriented', ',', 'mild', 'sob', 'hee', '##nt', ':', 'sc', '##ler', '##a', 'an', '##ic', '##ter', '##ic', ',', 'mmm', ',', 'oro', '##pha', '##ryn', '##x', 'clear', 'neck', ':', 'su', '##pp', '##le', ',', 'j', '##v', '##p', 'not', 'elevated', 'lungs', ':', 'diminished', 'throughout', 'r', '>', 'l', 'with', 'scattered', 'w', '##hee', '##zes', 'and', 'ra', '##les', 'on', 'r', 'cv', ':', 'ir', '##re', '##g', 'rhythm', 'with', 'skipped', 'beats', ',', 'normal', 's', '##1', '+', 's', '##2', ',', 'se', '##m', 'at', 'rs', '##b', 'abdomen', ':', 'soft', ',', 'non', '-', 'tender', ',', 'pro', '##tub', '##eran', '##t', ',', 'bow', '##el', 'sounds', 'present', ',', 'no', 'rebound', 'tenderness', 'or', 'guarding', ',', 'no', 'organ', '##ome', '##gal', '##y', 'ex', '##t', ':', 'warm', ',', 'well', 'per', '##fus', '##ed', ',', '2', '+', 'pulses', ',', 'no', 'club', '##bing', ',', 'cy', '##ano', '##sis', 'or', 'ed', '##ema', 'labs', '/', 'radio', '##logy', '176', 'k', '/', 'ul', '4', 'g', '/', 'dl', '162', 'mg', '/', 'dl', '8', 'mg', '/', 'dl', '35', 'me', '##q', '/', 'l', '9', 'me', '##q', '/', 'l', '20', 'mg', '/', 'dl', '100', 'me', '##q', '/', 'l', '141', 'me', '##q', '/', 'l', '8', '%', '3', 'k', '/', 'ul', '05', ':', '17', 'pm', '09', ':', '59', 'pm', '02', ':', '02', 'am', '05', ':', '00', 'am', 'wb', '##c', '3', 'hc', '##t', '8', 'pl', '##t', '176', 'cr', '8', 'tr', '##op', '##t', '02', 'tc', '##o', '##2', '32', '34', 'glucose', '162', 'other', 'labs', ':', 'pt', '/', 'pt', '##t', '/', 'in', '##r', ':', '8', '/', '3', '/', '3', ',', 'ck', '/', 'ck', '##mb', '/', 'tr', '##op', '##oni', '##n', '-', 't', ':', '120', '/', '5', '/', '02', ',', 'lac', '##tic', 'acid', ':', '7', 'mm', '##ol', '/', 'l', ',', 'ca', '+', '+', ':', '9', 'mg', '/', 'dl', ',', 'mg', '+', '+', ':', '4', 'mg', '/', 'dl', ',', 'po', '##4', ':', '6', 'mg', '/', 'dl', 'assessment', 'and', 'plan', 'this', 'is', 'a', '70', 'yo', 'male', 'with', 'known', 'stage', 'iv', 'cop', '##d', 'with', 'home', 'o', '##2', 'requirement', 'and', 'chronic', 'pre', '##d', '##nis', '##one', ',', 'as', ',', 'and', 'cardiac', 'pace', '##r', ',', 'who', 'presents', 'with', 'acute', 'short', '##ness', 'of', 'breath', ',', 'fever', ',', 'and', 'productive', 'cough', 'for', '2', 'days', '.', '#', 'pneumonia', ':', 'acute', 'onset', 'fever', ',', 'cough', 'and', 'd', '##ys', '##p', '##nea', 'in', 'setting', 'of', 'c', '##x', '##r', 'infiltrate', 'is', 'most', 'likely', 'acute', 'pneumonia', '-', 'typical', 'vs', 'at', '##yp', '##ical', '.', '-', 'con', '##t', 'ce', '##ft', '##ria', '##xon', '##e', 'and', 'az', '##ith', '##rom', '##y', '##cin', '(', 'monitor', 'in', '##r', ',', 'co', '##uma', '##din', 'interaction', ')', '.', 'low', 'threshold', 'for', 'ct', '##a', 'to', 'look', 'for', 'pe', ',', 'which', 'also', 'can', 'cause', 'fever', ',', 'if', 'not', 'responding', 'to', 'tx', '-', 'f', '/', 'u', 'legion', '##ella', 'ag', '-', 'f', '/', 'u', 'lac', '##tate', 'trend', '##ing', 'down', '3', '-', '>', '7', '-', 'will', 'allow', 'po', 'fluids', 'as', 'known', 'as', 'could', 'pre', '##ci', '##pit', '##ate', 'pulmonary', 'ed', '##ema', 'with', 'fluid', 'bo', '##lus', '##es', '-', 'con', '##t', 'me', '##pro', '##n', 'for', 'pc', '##p', '.', '#', 'cop', '##d', 'ex', '##as', '##cer', '##bation', ':', 'likely', 'pre', '##ci', '##pit', '##ated', 'by', 'acute', 'pneumonia', 'as', 'evidenced', 'by', 'marked', 'd', '##ys', '##p', '##nea', 'and', 'w', '##hee', '##zing', 'and', 'increased', 'o', '##2', 'requirement', '-', 'sol', '##ume', '##dro', '##l', '125', '##mg', 'q', '##8', '##hr', 'x', '##2', 'doses', '-', 'transition', 'to', 'po', 'pre', '##d', '##nis', '##one', 'burst', 'in', 'am', '-', 'we', '##an', 'o', '##2', 'as', 'tolerated', '.', '#', 'rom', '##i', ':', 'r', '-', 'sided', 'pl', '##eur', '##itic', 'cp', 'suspicious', 'for', 'ami', ',', 'but', 'ek', '##g', 'largely', 'unchanged', 'from', 'prior', 'and', 'first', 'set', 'ce', 'negative', '-', 'second', 'set', 'ce', 'trend', '##ed', 'down', '04', '-', '>', '02', '.', '#', 'cardiac', 'ar', '##rh', '##yt', '##hmi', '##a', ':', 'known', 'av', 'pace', '##r', 's', '/', 'p', 'ab', '##lation', 'for', 'a', '-', 'fi', '##b', '-', 'con', '##t', 'do', '##fe', '##ti', '##lide', '375', 'mc', '##g', 'and', 'dil', '##tia', '##ze', '##m', '180', 'mg', 'daily', '-', 'con', '##t', 'co', '##uma', '##din', 'and', 'monitor', 'in', '##r', 'for', 'drug', 'interactions', '.', '#', 'fen', ':', 'no', 'iv', '##f', ',', 'rep', '##lete', 'electro', '##ly', '##tes', ',', 'reg', 'diet', '.', '#', 'prop', '##hyl', '##ax', '##is', ':', 'therapeutic', 'on', 'co', '##uma', '##din', ',', 'p', '##ne', '##um', '##ob', '##oot', '##s', ',', 'h', '##2', '.', '#', 'access', ':', 'pi', '##v', 'x', '##1', '.', '#', 'code', ':', 'full', '.', '#', 'communication', ':', 'patient', '.', '#', 'disposition', ':', 'likely', 'transfer', 'to', 'the', 'floor', 'today', 'ic', '##u', 'care', 'nutrition', ':', 'g', '##ly', '##ce', '##mic', 'control', ':', 'lines', ':', '18', 'gauge', '-', '06', ':', '26', 'pm', 'prop', '##hyl', '##ax', '##is', ':', 'd', '##v', '##t', ':', 'stress', 'ul', '##cer', ':', 'va', '##p', ':', 'comments', ':', 'communication', ':', 'comments', ':', 'code', 'status', ':', 'disposition', ':']\n","chunk 138 tokenize start!\n","First sentence tokenized\n","['vent', '##ric', '##ular', 'premature', 'beats', '(', 'vp', '##b', ',', 'vp', '##c', ',', 'pv', '##c', ')', 'assessment', ':', 'pt', 'remains', 'in', 'ns', '##r', 'with', 'frequent', 'pv', '##c', 's', '.', 'pt', 'with', 'episodes', 'of', 'vent', '##ric', '##ular', 'big', '##emi', '##ny', '.', 'sb', '##p', '~', '90', '-', '140', 's', 'on', 'neo', 'gt', '##t', '.', 'k', '1', 'this', 'am', 'and', 'mag', '8', 'this', 'am', 'action', ':', '12', 'lead', 'ek', '##g', 'done', 'this', 'am', '.', 'card', '##iology', 'consult', '-', '>', 'no', 'recommendations', 'at', 'this', 'time', '-', '>', 'plan', 'to', 'monitor', '.', 'neo', 'gt', '##t', 'ti', '##tra', '##ted', 'to', 'keep', 'sb', '##p', '>', '90', 'and', 'map', '>', 'response', ':', 'pt', 'remains', 'in', 'ns', '##r', 'with', 'frequent', 'pv', '##c', 's', 'and', 'has', 'episodes', 'of', 'vent', '##ric', '##ular', 'big', '##emi', '##ny', '.', 'plan', ':', 'monitor', 'rhythm', 'and', 'bp', 'renal', 'failure', ',', 'acute', '(', 'acute', 'renal', 'failure', ',', 'ar', '##f', ')', 'assessment', ':', 'l', '##s', 'with', 'r', '##hon', '##chi', 'and', 'dim', 'bases', 'bi', '##l', '.', 'pt', 'su', '##ction', '##ed', 'for', 'small', 'amount', 'of', 'thick', 'sp', '##ut', '##um', 'action', ':', 'response', ':', 'plan', ':', 'respiratory', 'failure', ',', 'acute', '(', 'not', 'ar', '##ds', '/', ')', 'assessment', ':', 'action', ':', 'response', ':', 'plan', ':', 'alteration', 'in', 'nutrition', 'assessment', ':', 'action', ':', 'response', ':', 'plan', ':', 'impaired', 'skin', 'integrity', 'assessment', ':', 'action', ':', 'response', ':', 'plan', ':']\n","chunk 139 tokenize start!\n","First sentence tokenized\n","['normal', 'sin', '##us', 'rhythm', '.', 'non', '-', 'specific', 'st', '-', 't', 'wave', 'abnormalities', '.', 'low', 'q', '##rs', 'voltage', '##s', '.', 'poor', 'r', 'wave', 'progression', 'in', 'leads', 'v', '##1', '-', 'v', '##4', 'of', 'uncertain', 'significance', '.', 'clinical', 'correlation', 'is', 'suggested', '.', 'compared', 'to', 'tracing', '#', '1', 'r', 'wave', 'in', 'lead', 'v', '##4', 'is', 'slightly', 'smaller', '.', 'question', 'lead', 'placement', '.', 'low', 'q', '##rs', 'voltage', '##s', 'raise', 'question', 'of', 'increase', 'imp', '##edance', ',', 'perhaps', 'due', 'to', 'per', '##ica', '##rdial', 'fluids', '.', 'repeat', 'tracing', 'and', 'clinical', 'correlation', 'are', 'suggested', '.', 'tracing', '#', '2']\n","chunk 140 tokenize start!\n","First sentence tokenized\n","['demographics', 'day', 'of', 'int', '##uba', '##tion', ':', 'day', 'of', 'mechanical', 'ventilation', ':', '4', 'ideal', 'body', 'weight', ':', '4', 'none', 'ideal', 'tidal', 'volume', ':', '6', '/', '4', '/', '2', 'ml', '/', 'kg', 'air', '##way', 'air', '##way', 'placement', 'data', 'known', 'difficult', 'int', '##uba', '##tion', ':', 'no', 'procedure', 'location', ':', 'reason', ':', 'tube', 'type', 'et', '##t', ':', 'position', ':', '21', 'cm', 'at', 'teeth', 'route', ':', 'oral', 'type', ':', 'standard', 'size', ':', '5', '##mm', 'lung', 'sounds', 'r', '##ll', 'lung', 'sounds', ':', 'clear', 'ru', '##l', 'lung', 'sounds', ':', 'clear', 'lu', '##l', 'lung', 'sounds', ':', 'clear', 'll', '##l', 'lung', 'sounds', ':', 'clear', 'comments', ':', 'secret', '##ions', 'sp', '##ut', '##um', 'color', '/', 'consistency', ':', 'clear', '/', 'ten', '##acious', 'sp', '##ut', '##um', 'source', '/', 'amount', ':', 'su', '##ction', '##ed', '/', 'moderate', 'comments', ':', 'some', 'thick', 'yellow', 'at', 'times', 'ventilation', 'assessment', 'level', 'of', 'breathing', 'assistance', ':', 'intermittent', 'invasive', 'ventilation', 'visual', 'assessment', 'of', 'breathing', 'pattern', ':', 'normal', 'quiet', 'breathing', 'assessment', 'of', 'breathing', 'comfort', ':', 'no', 'response', '(', 'sleeping', '/', 'se', '##date', '##d', ')', ';', 'comments', ':', 'na', '##rd', ';', 'no', 'episodes', 'of', 'des', '##at', '##uration', 'overnight', '.', 'plan', 'next', '24', '-', '48', 'hours', ':', 'continue', 'with', 'daily', 'rs', '##bi', 'tests', '&', 'sb', '##t', \"'\", 's', 'as', 'tolerated', ';', 'comments', ':', 'failed', 'rs', '##bi', 'this', 'morning', '(', '110', ')', 'reason', 'for', 'continuing', 'current', 'vent', '##ila', '##tory', 'support', ':', 'into', '##ler', '##ant', 'of', 'we', '##ani', '##ng', 'attempts', ';', 'comments', ':', 'patient', 'gets', 'd', '##ys', '##p', '##ne', '##ic', 'after', 'trial', 'of', 'lowering', 'pressure', 'support', '.', 'comments', ':', 'o', '##2', 'sat', '##s', 'stable', 'overnight', '.', 'continues', 'to', 'have', 'cop', '##ious', 'amount', 'of', 'oral', 'secret', '##ions', '.', 'does', 'not', 'doe', 'well', 'on', 'with', 'res', '##p', 'rate', 'up', 'to', '30', '##s', '.', 'failed', 'rs', '##bi', 'this', 'morning', '.']\n","chunk 141 tokenize start!\n","First sentence tokenized\n","['chief', 'complaint', ':', '24', 'hour', 'events', ':', 'er', '##cp', '-', 'at', '05', ':', '30', 'pm', '-', 'given', '4', '##u', 'ff', '##p', 'prior', 'to', 'er', '##cp', 'today', '.', 'in', '##r', 'did', 'not', 'change', 'post', 'trans', '##fusion', '.', '-', 'pr', '##uri', '##tus', 'over', 'back', 'since', 'yesterday', 'likely', 'related', 'to', 'hyper', '##bil', '##ir', '##ub', '##ine', '##mia', '.', 'also', 'developed', 'hive', '##s', 'during', 'third', 'unit', 'of', 'ff', '##p', ',', 'trans', '##fusion', 'stopped', 'and', '25', 'mg', 'iv', 'ben', '##ad', '##ryl', 'given', '.', '-', 'called', 'os', '##h', ':', 'pathology', 'did', 'not', 'reveal', 'tumor', 'and', 'only', 'fi', '##bro', '##sis', '?', '?', 'possible', 'they', 'missed', 'the', 'mass', '.', 'blood', 'cultures', 'ng', '##t', '##d', 'and', 'urine', 'c', '##x', 'negative', '.', '-', 'er', '##cp', ':', 'large', 'strict', '##ure', 'involving', 'the', 'r', 'he', '##pati', '##c', '(', 'complete', ')', ',', 'l', 'he', '##pati', '##c', 'partial', 'and', 'the', 'port', '##a', 'he', '##pati', '##s', '.', 'flu', '##ro', 'machine', 'was', 'not', 'working', 'properly', 'so', 'couldn', \"'\", 't', 'evaluate', 'fully', '.', 'placed', 'a', 'plastic', 'ste', '##nt', 'in', 'the', 'common', '/', 'right', 'bi', '##lia', '##ry', 'duct', '.', 'sent', 'sample', 'for', 'cy', '##tology', '.', 'did', 'not', 'do', 'sp', '##hin', '##cter', '##oto', '##my', 'b', '/', 'c', 'in', '##r', 'can', 'repeat', 'er', '##cp', 'tomorrow', 'or', 'next', 'day', 'if', 'hyper', '##bil', '##i', 'does', 'not', 'resolve', '.', 'recommend', ':', 'repeat', 'f', '##na', '(', 'ct', '-', 'guided', ')', 'of', 'mass', 'if', 'no', 'd', '##x', 'from', 'os', '##h', '(', 'waiting', 'for', 'further', 'stains', ')', '.', 'if', 'not', 'a', 'surgical', 'candidate', 'can', 'place', 'metal', 'ste', '##nt', 'in', 'the', 'future', '.', '-', 'er', '##cp', 'fellow', 'wanted', 'an', 'mr', '##cp', 'for', 'better', 'eva', '##l', 'of', 'the', 'mass', '/', 'strict', '##ure', '.', 'ordered', 'for', 'tomorrow', '.', '-', 'er', '##cp', 'request', 'post', '-', 'er', '##cp', 'ku', '##b', ':', 'contrast', 'in', 'gall', '##bla', '##dder', 'and', 'left', 'bi', '##lia', '##ry', 'system', '.', 'no', 'free', 'air', '.', 'no', 'ob', '##st', '##ru', '##ctive', 'bow', '##el', 'gas', 'pattern', '.', 'all', '##er', '##gies', ':', 'no', 'known', 'drug', 'all', '##er', '##gies', 'last', 'dose', 'of', 'antibiotics', ':', 'van', '##com', '##y', '##cin', '-', '07', ':', '30', 'am', 'piper', '##ac', '##ill', '##in', '/', 'ta', '##zo', '##ba', '##cta', '##m', '(', 'z', '##os', '##yn', ')', '-', '10', ':', '32', 'pm', 'in', '##fusion', '##s', ':', 'other', 'ic', '##u', 'medications', ':', 'other', 'medications', ':', 'changes', 'to', 'medical', 'and', 'family', 'history', ':', 'review', 'of', 'systems', 'is', 'unchanged', 'from', 'admission', 'except', 'as', 'noted', 'below', 'review', 'of', 'systems', ':', 'abdominal', 'pain', 'is', 'improved', ';', 'good', 'appetite', ';', '1', 'bow', '##el', 'movement', 'yesterday', 'flows', '##hee', '##t', 'data', 'as', 'of', '07', ':', '10', 'am', 'vital', 'signs', 'hem', '##od', '##yna', '##mic', 'monitoring', 'fluid', 'balance', '24', 'hours', 'since', '12', 'am', 't', '##max', ':', '9', 'c', '(', '5', 'tc', '##urrent', ':', '3', 'c', '(', '3', 'hr', ':', '68', '(', '61', '-', '79', ')', 'bp', '##m', 'bp', ':', '128', '/', '78', '(', '90', ')', '{', '104', '/', '63', '(', '72', ')', '-', '145', '/', '86', '(', '101', ')', '}', 'mm', '##hg', 'rr', ':', '17', '(', '16', '-', '27', ')', 'ins', '##p', '/', 'min', 'sp', '##o', '##2', ':', '98', '%', 'heart', 'rhythm', ':', 'sr', '(', 'sin', '##us', 'rhythm', ')', 'total', 'in', ':', '3', ',', '00', '##6', 'ml', '138', 'ml', 'po', ':', 't', '##f', ':', 'iv', '##f', ':', '1', ',', '89', '##5', 'ml', '138', 'ml', 'blood', 'products', ':', '1', ',', '111', 'ml', 'total', 'out', ':', '2', ',', '375', 'ml', '92', '##0', 'ml', 'urine', ':', '2', ',', '375', 'ml', '92', '##0', 'ml', 'ng', ':', 'stool', ':', 'drains', ':', 'balance', ':', 'los', ':', '+', '3', '##l', '63', '##1', 'ml', '-', '78', '##2', 'ml', 'respiratory', 'support', 'o', '##2', 'delivery', 'device', ':', 'nasal', 'can', '##nu', '##la', 'sp', '##o', '##2', ':', '98', '%', 'ab', '##g', ':', '/', '/', '/', '17', '/', 'physical', 'examination', 'gen', ':', 'resting', 'comfortably', ',', 'nad', 'skin', ':', 'ja', '##und', '##ice', '##d', 'cv', ':', 'rr', '##r', ',', 'normal', 's', '##1', '/', 's', '##2', ',', 'no', 'murmurs', 'pu', '##lm', ':', 'decreased', 'breath', 'sounds', 'right', 'base', ';', 'no', 'w', '##hee', '##zes', ',', 'ra', '##les', ',', 'r', '##hon', '##chi', 'abd', ':', 'decreased', 'bow', '##el', 'sounds', ';', 'obe', '##se', ';', 'soft', ';', 'non', '##ten', '##der', 'ex', '##t', ':', 'trace', 'pitt', '##ing', 'ed', '##ema', 'labs', '/', 'radio', '##logy', '334', 'k', '/', 'ul', '8', 'g', '/', 'dl', '98', 'mg', '/', 'dl', '1', 'mg', '/', 'dl', '17', 'me', '##q', '/', 'l', '9', 'me', '##q', '/', 'l', '23', 'mg', '/', 'dl', '118', 'me', '##q', '/', 'l', '146', 'me', '##q', '/', 'l', '9', '%', '4', 'k', '/', 'ul', 'ca', '8', ',', 'mg', '0', ',', 'ph', '##os', '4', 'in', '##r', '8', ',', 'pt', '##t', '5', 'tb', '##ili', '1', '>', '7', 'al', '##k', 'ph', '##os', '217', '>', '168', 'as', '##t', '40', '>', '36', 'alt', '31', '>', '26', 'ld', '##h', '221', '>', '157', 'amy', '##lase', '42', '>', '56', '##5', 'lip', '##ase', '51', '>', '144', '##3', '07', ':', '49', 'pm', '09', ':', '10', 'pm', '04', ':', '42', 'am', '04', ':', '39', 'pm', '04', ':', '05', 'am', '05', ':', '19', 'am', 'wb', '##c', '7', '3', '5', '4', 'hc', '##t', '1', '2', '4', '9', 'pl', '##t', '38', '##8', '34', '##8', '326', '334', 'cr', '6', '5', '8', '2', '1', 'tc', '##o', '##2', '17', 'glucose', '56', '146', '298', '192', '98', 'other', 'labs', ':', 'pt', '/', 'pt', '##t', '/', 'in', '##r', ':', '0', '/', '5', '/', '8', ',', 'alt', '/', 'as', '##t', ':', '26', '/', '36', ',', 'al', '##k', 'ph', '##os', '/', 't', 'bi', '##li', ':', '168', '/', '7', ',', 'amy', '##lase', '/', 'lip', '##ase', ':', ',', 'differential', '-', 'ne', '##uts', ':', '0', '%', ',', 'band', ':', '0', '%', ',', 'l', '##ym', '##ph', ':', '0', '%', ',', 'mono', ':', '0', '%', ',', 'e', '##os', ':', '0', '%', ',', 'lac', '##tic', 'acid', ':', '0', 'mm', '##ol', '/', 'l', ',', 'album', '##in', ':', '5', 'g', '/', 'dl', ',', 'ld', '##h', ':', '157', 'i', '##u', '/', 'l', ',', 'ca', '+', '+', ':', '8', 'mg', '/', 'dl', ',', 'mg', '+', '+', ':', '0', 'mg', '/', 'dl', ',', 'po', '##4', ':', '4', 'mg', '/', 'dl', 'urine', 'culture', 'no', 'growth', ',', 'final', 'blood', 'culture', 'no', 'growth', 'to', 'date', 'assessment', 'and', 'plan', '48', 'year', 'old', 'female', 'with', 'd', '##m', ',', 'h', '##t', '##n', ',', 'and', 'recently', 'found', 'liver', 'mass', ',', 'transferred', 'from', 'os', '##h', 'with', 'h', '##yp', '##ote', '##ns', '##ion', ',', 'band', '##emia', ',', 'h', '##yp', '##og', '##ly', '##ce', '##mia', ',', 'ar', '##f', 'likely', 'secondary', 'to', 'sep', '##sis', 'after', 'recent', 'liver', 'bio', '##psy', '.', 'currently', 'stable', 'and', 'awaiting', 'identification', 'of', 'mass', '.', '#', '.', 'hyper', '##bil', '##ir', '##ub', '##ine', '##mia', '/', 'he', '##pati', '##c', 'failure', '/', 'liver', 'mass', ':', 'right', 'lobe', 'mass', 'now', 's', '/', 'p', 'bio', '##psy', '.', 'mildly', 'elevated', 'trans', '##amina', '##ses', 'with', 'significant', 'hyper', '##bil', '##ir', '##ub', '##ine', '##mia', 'with', 'mixed', 'con', '##ju', '##gated', '/', 'un', '##con', '##ju', '##gated', 'picture', 'per', 'os', '##h', 'lab', 'results', 'hyper', '##bil', '##ir', '##ub', '##ine', '##mia', 'improving', 'after', 'er', '##cp', 'yesterday', '.', 'final', 'mass', 'bio', '##psy', 'data', 'from', 'os', '##h', 'no', 'evidence', 'of', 'mali', '##gnan', '##cy', '(', 'fi', '##bro', '##sis', '/', 'inflammation', ')', '.', 'viral', 'ser', '##ologies', 'pending', '.', 's', '/', 'p', 'er', '##cp', '-', 'plastic', 'ste', '##nt', 'placed', 'in', 'common', '/', 'right', 'bi', '##lia', '##ry', 'duct', ',', 'could', 'not', 'fully', 'evaluate', 'bi', '##lia', '##ry', 'tree', 'due', 'to', 'mal', '##fu', '##nction', '##ing', 'flu', '##oro', 'machine', ',', 'cy', '##tology', 'sent', '-', 'he', '##pa', '##tology', 'rec', '##s', '-', 'er', '##cp', 'rec', '##s', '-', 'mr', '##cp', 'ordered', 'for', 'better', 'eva', '##l', 'of', 'mass', '/', 'strict', '##ure', 'may', 'not', 'be', 'necessary', 'given', 'that', 'mri', 'was', 'done', 'at', 'os', '##h', ';', 'may', 'order', 'ct', '-', 'guided', 'f', '##na', 'given', 'no', 'definitive', 'diagnosis', 'from', 'os', '##h', ';', 'possible', 'repeat', 'er', '##cp', 'if', 'hyper', '##bil', '##ir', '##ub', '##ine', '##mia', 'does', 'not', 'improve', '#', '.', 'sep', '##sis', '/', 'h', '##yp', '##ote', '##ns', '##ion', ',', 'now', 'resolved', ':', 'patient', 'was', 'norm', '##ote', '##ns', '##ive', 'overnight', '.', 'continues', 'to', 'have', 'elevated', 'wb', '##c', 'today', 'to', 'likely', 'source', 'was', 'he', '##pa', '##to', '##bil', '##iary', 'given', 'recent', 'instrumentation', '.', 'h', '##yp', '##ote', '##ns', '##ion', 'on', 'admission', 'may', 'also', 'have', 'had', 'an', 'intra', '##vas', '##cular', 'h', '##yp', '##ovo', '##lem', '##ic', 'component', '.', '-', 'continue', 'pip', '/', 'ta', '##zo', 'as', 'patient', 'likely', 'to', 'have', 'repeat', 'instrumentation', ';', 'currently', 'day', '3', '-', 'disco', '##nti', '##nu', '##e', 'van', '##com', '##y', '##cin', 'as', 'patient', 'with', 'all', 'negative', 'cultures', 'to', 'date', '-', 'follow', '-', 'up', 'cultures', '-', 'bo', '##lus', 'for', 'map', '<', '65', ',', 'decreased', 'u', '##op', ',', 'worse', '##ning', 'men', '##tation', '#', '.', 'hyper', '##nat', '##rem', '##ia', ':', 'likely', 'due', 'to', 'iv', '##f', '.', 'free', 'water', 'deficit', '45', '##l', '-', 'encourage', 'patient', 'to', 'drink', 'water', '#', 'h', '##yp', '##og', '##ly', '##ce', '##mia', '/', 'diabetes', ':', 'f', '##s', '98', '-', '175', 'over', 'past', '24', 'hours', '.', 'patient', 'has', 'been', 'off', 'of', 'her', 'home', 'regime', '##n', 'of', 'insulin', '.', 'potential', 'et', '##iol', '##og', '##ies', 'to', 'h', '##yp', '##og', '##ly', '##ce', '##mia', 'included', 'liver', 'failure', 'although', 'unlikely', 'given', 'trans', '##amina', '##ses', ',', 'ad', '##ren', '##al', 'ins', '##uf', '##fi', '##ciency', ',', 'hc', '##c', 'pan', '##ane', '##op', '##lastic', 'process', ',', 'or', 'drug', '-', 'related', '.', '-', 'd', '##5', 'ns', 'as', 'necessary', 'for', 'h', '##yp', '##og', '##ly', '##ce', '##mia', '.', '-', 'acc', '##uche', '##cks', '-', 'continue', 'hold', 'iss', 'and', 'basal', 'insulin', 'for', 'now', '.', '#', 'ut', '##i', ':', 'ua', 'on', 'admission', 'with', 'p', '##yu', '##ria', '.', 'os', '##h', 'urine', 'culture', 'with', 'no', 'growth', '.', 'urine', 'culture', 'no', 'growth', '.', '-', 'currently', 'on', 'z', '##os', '##yn', '#', 'acute', 'renal', 'failure', ':', 'cr', '##ea', '##tin', '##ine', 'this', 'am', 'trend', '##ing', 'down', 'to', 'fen', '##a', 'of', '9', 'initially', 'suggested', 'at', '##n', 'consistent', 'with', 'h', '##yp', '##ote', '##ns', '##ion', '.', '-', 'trend', 'cr', '##ea', '##tin', '##ine', 'and', 'electro', '##ly', '##tes', '#', 'h', '##t', '##n', ':', 'hold', 'anti', '-', 'hyper', '##tens', '##ives', '#', 'ge', '##rd', ':', 'pp', '##i', '#', 'fen', ':', 'np', '##o', 'for', 'now', ',', 'rep', '##lete', 'as', 'necessary', '#', 'pp', '##x', ':', 'he', '##par', '##in', 'sc', ',', 'pp', '##i', '#', 'access', ':', 'pi', '##v', '#', 'code', ':', 'full', '#', 'di', '##sp', '##o', ':', 'call', 'out', 'today', 'ic', '##u', 'care', '(', 'as', 'above', ')', 'nutrition', ':', 'g', '##ly', '##ce', '##mic', 'control', ':', 'lines', ':', '18', 'gauge', '-', '06', ':', '43', 'pm', '20', 'gauge', '-', '08', ':', '26', 'pm', 'prop', '##hyl', '##ax', '##is', ':', 'd', '##v', '##t', ':', 'stress', 'ul', '##cer', ':', 'va', '##p', ':', 'comments', ':', 'communication', ':', 'comments', ':', 'code', 'status', ':', 'full', 'code', 'disposition', ':']\n","chunk 142 tokenize start!\n","First sentence tokenized\n","['cv', '##ic', '##u', 'hp', '##i', ':', 'hd', '##12', 'pod', '8', '88', '##m', 's', '/', 'p', 'removal', 'of', 'r', 'ax', '-', 'bi', '##fe', '##m', ':', 'pl', '##avi', '##x', '75', 'daily', ',', 'as', '##pi', '##rin', '81', 'daily', ',', 'pr', '##ava', '##cho', '##l', '40', 'daily', ',', 'ni', '##fed', '##ip', '##ine', '90', 'daily', ',', 'proton', '##ix', '40', ',', 'sp', '##iri', '##va', 'pr', '##n', ',', 'ca', '##co', '##3', ',', 'ce', '##le', '##xa', '20', 'daily', ',', 'cl', '##oni', '##dine', '2', 'po', 'bid', ',', 'fe', '##so', '##4', '325', ',', 'li', '##sin', '##op', '##ril', '5', 'daily', ',', 'mir', '##ta', '##za', '##pine', '5', 'hs', ',', 'mtv', ',', 'vic', '##od', '##in', 'q', '##4', 'pr', '##n', 'pm', '##h', '##x', ':', 'pm', '##h', ':', 'pv', '##d', 's', '/', 'p', 'right', 'fe', '##m', '-', '(', ')', ',', 'left', 'fe', '##m', '-', '(', ')', 'ao', '##rt', '##ob', '##ife', '##m', '(', ')', ',', 'right', 'ax', '-', 'fe', '##m', ',', 'right', 'aka', ',', 'cad', ',', 'afi', '##b', 's', '/', 'p', 'pace', '##maker', ',', 'hyper', '##lip', '##ide', '##mia', ',', 'h', '##t', '##n', ',', 'renal', 'at', '##rop', '##hy', ',', 'ge', '##rd', ',', 'an', '##emia', ',', 'hi', '##atal', 'her', '##nia', ',', 'depression', ',', 'anxiety', ',', 'dementia', ',', 'bp', '##h', 'current', 'medications', ':', 'as', '##pi', '##rin', 'ci', '##tal', '##op', '##ram', 'hydro', '##bro', '##mide', 'ci', '##pro', '##fl', '##ox', '##ac', '##in', 'hc', '##l', 'doc', '##usa', '##te', 'sodium', '(', 'liquid', ')', 'fen', '##tan', '##yl', 'ci', '##tra', '##te', 'he', '##par', '##in', 'insulin', 'magnesium', 'sulfate', 'pan', '##top', '##raz', '##ole', 'p', '##ne', '##um', '##oco', '##cca', '##l', 'va', '##c', 'poly', '##valent', 'pr', '##ava', '##sta', '##tin', 'sodium', 'chloride', '9', '%', 'flush', 'sodium', 'ci', '##tra', '##te', '4', '%', 'van', '##com', '##y', '##cin', '24', 'hour', 'events', ':', '4', '/', '12', '-', '100', '##mg', 'las', '##ix', 'w', '/', 'o', 'result', '.', 'cv', '##v', '##h', 'per', 'va', '##sc', '.', 'qui', '##nton', 'placed', 'ri', '##j', '(', 'wire', ')', '.', 'needs', 'fluid', 'off', 'before', 'ex', '##tub', '##ation', '-', 'c', '##x', '##r', 'wet', '.', '*', '*', 'full', 'code', '*', '*', 'he', '##p', '500', '/', 'hr', 'per', 'va', '##sc', '.', '-', 'cv', '##v', '##h', '-', '200', '/', 'hr', '.', 'if', 'tolerated', 'hd', 'tomorrow', '.', 'check', 'c', '##x', '##r', 'in', 'am', ',', 'if', 'pe', 'resolved', 'w', '##te', '.', '-', 'ex', '##tub', '##ated', ',', 'cv', '##v', '##h', 'ne', '##g', '##4', '-', '500', 'for', '24', '##hr', 'then', 'to', 'hd', '.', 'spoke', 'w', '/', 'med', '.', 'proxy', 'to', 'update', '.', 'post', 'operative', 'day', ':', 'pod', '8', '88', '##m', 's', '/', 'p', 'removal', 'of', 'r', 'ax', '-', 'bi', '##fe', '##m', 'pod', '#', '6', '-', '(', 'r', ')', 'chest', 'wall', 'revision', 'due', 'to', 'hem', '##ato', '##ma', '.', 'all', '##er', '##gies', ':', 'met', '##op', '##rol', '##ol', 'unknown', ';', 'last', 'dose', 'of', 'antibiotics', ':', 'piper', '##ac', '##ill', '##in', '/', 'ta', '##zo', '##ba', '##cta', '##m', '(', 'z', '##os', '##yn', ')', '-', '12', ':', '28', 'am', 'van', '##com', '##y', '##cin', '-', '09', ':', '00', 'am', 'in', '##fusion', '##s', ':', 'he', '##par', '##in', 'sodium', '-', '800', 'units', '/', 'hour', 'flows', '##hee', '##t', 'data', 'as', 'of', '09', ':', '36', 'am', 'vital', 'signs', 'hem', '##od', '##yna', '##mic', 'monitoring', 'fluid', 'balance', '24', 'hours', 'since', 'a', '.', 'm', '.', 't', '##max', ':', '4', 'c', '(', '6', 't', 'current', ':', '6', 'c', '(', '1', 'hr', ':', '80', '(', '80', '-', '80', ')', 'bp', '##m', 'bp', ':', '116', '/', '63', '(', '75', ')', '{', '90', '/', '53', '(', '64', ')', '-', '128', '/', '70', '(', '81', ')', '}', 'mm', '##hg', 'rr', ':', '19', '(', '16', '-', '22', ')', 'ins', '##p', '/', 'min', 'sp', '##o', '##2', ':', '100', '%', 'heart', 'rhythm', ':', 'v', 'paced', 'w', '##gt', '(', 'current', ')', ':', '1', 'kg', '(', 'admission', ')', ':', '88', 'kg', 'height', ':', '72', 'inch', 'total', 'in', ':', '1', ',', '343', 'ml', '125', 'ml', 'po', ':', 'tube', 'feeding', ':', 'iv', 'fluid', ':', '1', ',', '343', 'ml', '125', 'ml', 'blood', 'products', ':', 'total', 'out', ':', '5', ',', '97', '##7', 'ml', '42', 'ml', 'urine', ':', '10', 'ml', '12', 'ml', 'ng', ':', 'stool', ':', 'drains', ':', '50', 'ml', '30', 'ml', 'balance', ':', '-', '4', ',', '63', '##4', 'ml', '83', 'ml', 'respiratory', 'support', 'o', '##2', 'delivery', 'device', ':', 'none', 'sp', '##o', '##2', ':', '100', '%', 'ab', '##g', ':', '/', '/', '/', '20', '/', 'physical', 'examination', 'general', 'appearance', ':', 'no', 'acute', 'distress', 'hee', '##nt', ':', 'per', '##rl', 'cardiovascular', ':', '(', 'rhythm', ':', 'regular', ')', ',', 'v', 'paced', 'respiratory', '/', 'chest', ':', '(', 'expansion', ':', 'symmetric', ')', ',', '(', 'breath', 'sounds', ':', 'crack', '##les', ':', 'bases', 'bi', '##lat', ')', ',', 'rt', 'pe', '##ctor', '##al', 'hem', '##ato', '##mas', '##ub', '##cl', '##avian', 'inc', '##ision', 'with', 'su', '##tures', 'clean', 'and', 'dry', 'abdominal', ':', 'soft', ',', 'non', '-', 'di', '##sten', '##ded', ',', 'non', '-', 'tender', ',', 'bow', '##el', 'sounds', 'present', 'left', 'ex', '##tre', '##mit', '##ies', ':', '(', 'ed', '##ema', ':', '1', '+', ')', ',', '(', 'temperature', ':', 'warm', ')', ',', '(', 'pulse', '-', 'dorsal', '##is', 'pe', '##dis', ':', 'diminished', ')', ',', '(', 'pulse', '-', 'posterior', 'ti', '##bial', ':', 'diminished', ')', 'skin', ':', 'right', 'lateral', 'inc', '##ision', 'su', '##ture', 'lines', 'clean', 'and', 'dry', ',', 'no', 'er', '##y', '##hre', '##ma', 'or', 'drainage', 'ne', '##uro', '##logic', ':', 'follows', 'simple', 'commands', ',', '(', 'responds', 'to', ':', 'verbal', 'stimuli', ')', ',', 'moves', 'all', 'ex', '##tre', '##mit', '##ies', ',', 'oriented', 'only', 'to', 'person', '.', 'year', 'at', 'a', 'resort', 'in', 'labs', '/', 'radio', '##logy', '140', 'k', '/', 'ul', '7', 'g', '/', 'dl', '119', 'mg', '/', 'dl', '3', 'mg', '/', 'dl', '20', 'me', '##q', '/', 'l', '8', 'me', '##q', '/', 'l', '29', 'mg', '/', 'dl', '99', 'me', '##q', '/', 'l', '136', 'me', '##q', '/', 'l', '7', '%', '8', 'k', '/', 'ul', '03', ':', '48', 'am', '08', ':', '55', 'am', '02', ':', '11', 'pm', '08', ':', '17', 'pm', '02', ':', '36', 'am', '11', ':', '28', 'am', '06', ':', '50', 'pm', '12', ':', '23', 'am', '02', ':', '23', 'am', '02', ':', '33', 'am', 'wb', '##c', '3', '5', '3', '8', 'hc', '##t', '4', '9', '8', '7', 'pl', '##t', '179', '188', '182', '140', 'cr', '##ea', '##tin', '##ine', '6', '6', '0', '4', '4', '3', 'glucose', '127', '102', '124', '121', '105', '139', '113', '97', '94', '119', 'other', 'labs', ':', 'pt', '/', 'pt', '##t', '/', 'in', '##r', ':', '9', '/', '2', '/', '4', ',', 'ck', '/', 'ck', '-', 'mb', '/', 'tr', '##op', '##oni', '##n', 't', ':', '114', '##3', '/', '14', '/', '48', ',', 'alt', '/', 'as', '##t', ':', '61', '/', '150', ',', 'al', '##k', '-', 'ph', '##os', '/', 't', 'bi', '##li', ':', '83', '/', '1', ',', 'amy', '##lase', '/', 'lip', '##ase', ':', '54', '/', '56', ',', 'fi', '##bri', '##no', '##gen', ':', '333', 'mg', '/', 'dl', ',', 'lac', '##tic', 'acid', ':', '9', 'mm', '##ol', '/', 'l', ',', 'album', '##in', ':', '3', 'g', '/', 'dl', ',', 'ld', '##h', ':', '46', '##1', 'i', '##u', '/', 'l', ',', 'ca', ':', '3', 'mg', '/', 'dl', ',', 'mg', ':', '5', 'mg', '/', 'dl', ',', 'po', '##4', ':', '8', 'mg', '/', 'dl', 'assessment', 'and', 'plan', '.', 'h', '/', 'o', 'sep', '##sis', ',', 'severe', '(', 'with', 'organ', 'dysfunction', ')', ',', '.', 'h', '/', 'o', 'dec', '##ub', '##it', '##us', 'ul', '##cer', '(', 'present', 'at', 'admission', ')', ',', '.', 'h', '/', 'o', 'dementia', '(', 'including', 'alzheimer', \"'\", 's', ',', 'multi', 'in', '##far', '##ct', ')', ',', '.', 'h', '/', 'o', 'respiratory', 'failure', ',', 'acute', '(', 'not', 'ar', '##ds', '/', ')', ',', '.', 'h', '/', 'o', 'renal', 'failure', ',', 'acute', '(', 'acute', 'renal', 'failure', ',', 'ar', '##f', ')', ',', 'pain', 'control', '(', 'acute', 'pain', ',', 'chronic', 'pain', ')', ',', 'hem', '##or', '##rh', '##age', '/', 'hem', '##ato', '##ma', ',', 'procedure', '-', 'related', '(', 'e', '.', 'g', '.', ',', 'cat', '##h', ',', 'pace', '##maker', ',', 'ic', '##d', 'bleed', ')', ',', 'ol', '##ig', '##uria', '/', 'an', '##uria', 'assessment', 'and', 'plan', ':', '88', '##yo', 's', '/', 'p', 'right', 'ax', '-', 'fe', '##m', 'removal', '.', 'now', 'pod', '8', ',', 'hem', '##od', '##yna', '##mic', '##ally', 'stable', 'and', 'ex', '##tub', '##ated', '.', 'ready', 'for', 'transfer', 'to', 'vic', '##u', 'ne', '##uro', '##logic', ':', 'no', 'complaint', 'of', 'pain', 'except', 'with', 'pal', '##pati', '##on', 'of', 'hem', '##ato', '##ma', '.', 'cardiovascular', ':', 'as', '##pi', '##rin', ',', 'full', 'anti', '##co', '##ag', '##ulation', ',', 'stat', '##ins', ',', 'add', 'bb', '##lock', '##er', '.', 'd', '/', 'c', 'he', '##par', '##in', 'pulmonary', ':', 'is', ',', 'o', '##ob', '-', 'chair', 'today', 'gas', '##tro', '##int', '##estinal', '/', 'abdomen', ':', 'nutrition', ':', 'advance', 'diet', 'as', 'tolerated', ',', 'encourage', 'oral', 'intake', 'renal', ':', 'foley', ',', 'hd', ',', 'an', '##uri', '##c', 'now', 'on', 'hd', 'hem', '##ato', '##logy', ':', 'stable', 'hc', '##t', 'end', '##oc', '##rine', ':', 'ri', '##ss', 'infectious', 'disease', ':', 'blood', 'and', 'tissue', 'cultures', 'with', 'mrs', '##a', 'on', 'van', '##co', 'level', 'yes', '##t', '13', 'dose', 'increased', 'repeat', 'blood', 'cultures', 'from', 'yes', '##ter', '##ds', '##ay', 'pending', '.', 'u', '/', 'a', 'with', 'sm', 'le', '##uk', '/', '3', '-', '5', '##w', '##bc', \"'\", 's', 'started', 'on', 'ci', '##pro', 'lines', '/', 'tubes', '/', 'drains', ':', 'foley', ',', 'surgical', 'drains', '(', 'hem', '##ova', '##c', ',', 'jp', ')', ',', 'te', '##mp', '##hd', 'cat', '##h', ',', 'rt', 'i', '##j', 'wounds', ':', 'dry', 'dressing', '##s', 'consult', '##s', ':', 'vascular', 'surgery', ',', 'ct', 'surgery', ',', 'p', '.', 't', '.', ',', 'nutrition', 'ic', '##u', 'care', 'nutrition', ':', 'ada', '##t', 'g', '##ly', '##ce', '##mic', 'control', ':', 'ri', '##ss', 'lines', ':', 'dial', '##ysis', 'cat', '##het', '##er', '-', '03', ':', '04', 'pm', 'prop', '##hyl', '##ax', '##is', ':', 'd', '##v', '##t', ':', '(', 'systemic', 'anti', '##co', '##ag', '##ulation', ':', 'he', '##par', '##in', 'drip', ')', 'stress', 'ul', '##cer', ':', 'pp', '##i', 'va', '##p', 'bundle', ':', 'ho', '##b', 'elevation', ',', 'mouth', 'care', 'comments', ':', 'communication', ':', 'patient', 'discussed', 'on', 'interdisciplinary', 'rounds', ',', 'ic', '##u', 'code', 'status', ':', 'full', 'code', 'disposition', ':', 'transfer', 'to', 'floor']\n","chunk 143 tokenize start!\n","First sentence tokenized\n","['subjective', 'other', ':', 'objective', 'per', '##tine', '##nt', 'medications', ':', 'hiss', ',', 'reg', '##lan', ',', 'others', 'noted', 'labs', ':', 'value', 'date', 'glucose', '228', 'mg', '/', 'dl', '03', ':', '00', 'am', 'glucose', 'finger', 'stick', '280', '06', ':', '00', 'am', 'bun', '109', 'mg', '/', 'dl', '03', ':', '00', 'am', 'cr', '##ea', '##tin', '##ine', '2', 'mg', '/', 'dl', '03', ':', '00', 'am', 'sodium', '128', 'me', '##q', '/', 'l', '03', ':', '00', 'am', 'potassium', '7', 'me', '##q', '/', 'l', '03', ':', '00', 'am', 'chloride', '94', 'me', '##q', '/', 'l', '03', ':', '00', 'am', 'tc', '##o', '##2', '21', 'me', '##q', '/', 'l', '03', ':', '00', 'am', 'album', '##in', '3', 'g', '/', 'dl', '03', ':', '44', 'am', 'calcium', 'non', '-', 'ion', '##ized', '4', 'mg', '/', 'dl', '03', ':', '00', 'am', 'phosphorus', '6', 'mg', '/', 'dl', '03', ':', '00', 'am', 'ion', '##ized', 'calcium', '14', 'mm', '##ol', '/', 'l', '03', ':', '02', 'am', 'magnesium', '1', 'mg', '/', 'dl', '03', ':', '00', 'am', 'current', 'diet', 'order', '/', 'nutrition', 'support', ':', 't', '##p', '##n', 'to', 'be', 'stopped', 'd', '/', 't', 'fun', '##ge', '##mia', 't', '##f', ':', 'nut', '##ren', '0', 'at', '10', '##ml', '/', 'hr', 'x', '24', 'hours', 'gi', ':', 'abdomen', 'soft', '/', 'di', '##sten', '##ded', 'with', 'h', '##yp', '##oa', '##ctive', 'bow', '##el', 'sounds', 'assessment', 'of', 'nutritional', 'status', 'specific', '##s', ':', '38', 'yo', 'w', 'with', 're', '##la', '##pse', '##d', 'all', 's', '/', 'p', 'chemotherapy', 'with', 'vr', '##e', 'sep', '##sis', ',', 'feb', '##ril', '##e', 'ne', '##ut', '##rop', '##enia', ',', 'respiratory', 'distress', ',', 'an', '##ion', '-', 'gap', 'acid', '##osis', ',', 'and', 'pan', '##cre', '##ati', '##tis', 'and', 'possible', 'tam', '##pon', '##ade', 'physiology', 'with', 'recent', 'pea', 'arrest', '.', 'patient', 'was', 'on', 't', '##p', '##n', 'but', 'now', 'to', 'be', 'stopped', 'd', '/', 't', 'fun', '##ge', '##mia', '.', 'would', 'continue', 'to', 'advance', 'tube', 'feeding', 'as', 'possible', '.', 'goal', 'tube', 'feeding', 'is', 'nut', '##ren', '0', 'with', '35', '##g', 'ben', '##ep', '##rot', '##ein', 'at', '30', '##ml', '/', 'hr', 'x', '24', 'hours', '.', 'medical', 'nutrition', 'therapy', 'plan', '-', 'recommend', 'the', 'following', 'advance', 'nut', '##ren', '0', 'as', 'tolerate', 'to', 'goal', 'of', '30', '##ml', '/', 'hr', 'x', '24', 'hours', '.', 'add', '35', '##g', 'ben', '##ep', '##rot', '##ein', 'once', 'tube', 'feeding', 'to', 'start', 'advancing', '.', 'monitor', 'residual', '##s', 'q', '##4', '##h', 'and', 'hold', 'if', '>', '150', '##ml', 'monitor', 'tolerance', 'will', 'follow', '11', ':', '47', 'am']\n","chunk 144 tokenize start!\n","First sentence tokenized\n","['73', '##f', 'w', '/', 'h', '##x', 'divert', '##ic', '##uli', '##tis', ',', 'recent', 'admit', 'from', '-', 'for', 'complicated', 'divert', '##ic', '##uli', '##tis', ',', 're', '-', 'presented', 'on', 'w', '/', 'n', '/', 'v', '.', 'abd', 'ct', 'reported', 'acute', 'si', '##gm', '##oid', 'divert', '##ic', '##uli', '##tis', 'with', 'si', '##gm', '##oid', 'intra', '-', 'mural', 'abs', '##ces', '##s', '.', 'it', 'also', 'showed', 'multiple', 'low', '-', 'at', '##ten', '##uating', 'pan', '##cre', '##atic', 'lesions', ',', 'largest', 'in', 'tail', 'thought', 'to', 'represent', 'side', '-', 'branch', 'ip', '##m', '##n', '.', 'taken', 'to', 'the', 'or', 'for', 'si', '##gm', '##oid', '##ect', '##omy', '.', 'she', 'had', 'pouch', 'formed', 'with', 'an', 'end', 'col', '##ost', '##omy', 'to', 'her', 'right', 'lower', 'quadrant', '.', 'jp', 'drain', 'was', 'placed', '.', 'she', 'is', 'being', 'admitted', 'to', 'the', 'ic', '##u', 'for', 'overnight', 'monitoring', 'in', 'the', 'setting', 'of', 'greater', 'than', 'expected', 'blood', 'loss', '.', 'pm', '##h', '##x', 'divert', '##ic', '##uli', '##tis', ',', 'cerebral', 'an', '##eur', '##ys', '##m', '/', 'sa', '##h', 's', '/', 'p', 'clip', '##ping', ',', 'back', ',', ',', 'pv', '##d', 's', '/', 'p', 'fe', '##moral', 'ang', '##io', '##pl', '##ast', '##y', ',', 'h', '##t', '##n', ',', 'elevated', 'lip', '##ids', 'ne', '##uro', ':', 'pt', 'remains', 'let', '##har', '##gic', 'but', 'response', 'to', 'voice', '.', 'af', '##eb', '##ril', '##e', ',', 'c', '/', 'o', 'abdominal', 'pain', 'which', 'is', 'resolved', 'with', 'pc', '##a', 'mor', '##phine', '.', 'res', '##p', ':', 'l', '##sc', ',', 'o', '##2', 'sat', '98', '%', 'on', '2', '##l', 'nc', '.', 'no', 'c', '/', 'o', 'sob', '.', 'cv', ':', 'bp', 'stable', ',', 'ns', '##r', '.', 'on', 'met', '##op', '##rol', '##ol', 'q', '##6', '##hr', '##s', 'for', 'h', '##t', '##n', '.', 'gi', '/', 'gu', ':', 'l', 'col', '##ost', '##omy', 'placed', ',', 'st', '##oma', 'pink', 'no', 'out', '##pt', '.', 'r', 'jp', 'draining', 'ser', '##osa', '##ng', '##uo', '##s', 'fluid', ',', 'mid', 'abdominal', 'inc', '##ision', ',', 'dr', '##s', '##ng', 'c', '/', 'd', '/', 'i', '.', 'foley', 'patent', 'and', 'draining', 'adequate', 'clear', 'yellow', 'urine', '.']\n","chunk 145 tokenize start!\n","First sentence tokenized\n","['pl', '##eur', '##al', 'e', '##ff', '##usion', ',', 'acute', 'assessment', ':', 'action', ':', 'response', ':', 'plan', ':', 'my', '##oca', '##rdial', 'in', '##far', '##ction', ',', 'acute', '(', 'ami', ',', 'stem', '##i', ',', 'ns', '##tem', '##i', ')', 'assessment', ':', 'action', ':', 'response', ':', 'plan', ':']\n","chunk 146 tokenize start!\n","First sentence tokenized\n","['chief', 'complaint', ':', 'transfer', 'from', 'hem', '.', '/', 'on', '##c', '.', '(', 'cm', '##l', ')', 'with', 'vt', '##ach', '.', '24', 'hour', 'events', ':', 'one', 'more', 'episode', 'of', 'v', 'ta', '##ch', ',', 'took', '3', 'over', '##ride', 'pace', 'attempts', 'to', 'rev', '##ert', 'to', 'sin', '##us', '.', 'no', 'more', 'episodes', '.', 'lid', '##o', 'at', 'bedside', '.', 'history', 'obtained', 'from', 'medical', 'records', 'all', '##er', '##gies', ':', 'history', 'obtained', 'from', 'medical', 'records', '##per', '##co', '##ce', '##t', '(', 'oral', ')', '(', 'ox', '##y', '##co', '##don', '##e', 'hc', '##l', '/', 'ace', '##tam', '##ino', '##ph', '##en', ')', 'unknown', ';', 'li', '##sin', '##op', '##ril', '(', 'oral', ')', 'cough', ';', 'ze', '##tia', '(', 'oral', ')', '(', 'e', '##ze', '##ti', '##mi', '##be', ')', 'dia', '##rr', '##hea', ';', 'lip', '##itor', '(', 'oral', ')', '(', 'at', '##or', '##vas', '##tat', '##in', 'calcium', ')', 'liver', 'blood', 'te', '##s', 'lo', '##vas', '##tat', '##in', 'muscle', 'cr', '##amps', ';', 'do', '##x', '##ep', '##in', 'dr', '##ows', '##iness', '/', 'fat', '##i', 'bon', '##iva', '(', 'oral', ')', '(', 'ib', '##and', '##rona', '##te', 'sodium', ')', 'nausea', '/', 'vomiting', 'glee', '##ve', '##c', '(', 'oral', ')', '(', 'im', '##atin', '##ib', 'me', '##sy', '##late', ')', 'nausea', '/', 'vomiting', 'ci', '##pro', '##fl', '##ox', '##ac', '##in', 'rash', ';', 'last', 'dose', 'of', 'antibiotics', ':', 'in', '##fusion', '##s', ':', 'ami', '##oda', '##rone', '-', '1', 'mg', '/', 'min', 'kc', '##l', '(', 'cr', '##rt', ')', '-', '5', 'me', '##q', '.', '/', 'hour', 'other', 'ic', '##u', 'medications', ':', 'ami', '##oda', '##rone', '-', '12', ':', '30', 'am', 'other', 'medications', ':', 'changes', 'to', 'medical', 'and', 'family', 'history', ':', 'review', 'of', 'systems', 'is', 'unchanged', 'from', 'admission', 'except', 'as', 'noted', 'below', 'review', 'of', 'systems', ':', 'flows', '##hee', '##t', 'data', 'as', 'of', '07', ':', '00', 'am', 'vital', 'signs', 'hem', '##od', '##yna', '##mic', 'monitoring', 'fluid', 'balance', '24', 'hours', 'since', 'am', 't', '##max', ':', '8', 'c', '(', '2', 'tc', '##urrent', ':', '8', 'c', '(', '2', 'hr', ':', '85', '(', '79', '-', '137', ')', 'bp', '##m', 'bp', ':', '116', '/', '51', '(', '67', ')', '{', '89', '/', '28', '(', '44', ')', '-', '116', '/', '74', '(', '80', ')', '}', 'mm', '##hg', 'rr', ':', '16', '(', '15', '-', '23', ')', 'ins', '##p', '/', 'min', 'sp', '##o', '##2', ':', '94', '%', 'heart', 'rhythm', ':', '1st', 'av', '(', 'first', 'degree', 'av', 'block', ')', 'height', ':', '63', 'inch', 'total', 'in', ':', '286', 'ml', 'po', ':', 't', '##f', ':', 'iv', '##f', ':', '286', 'ml', 'blood', 'products', ':', 'total', 'out', ':', '0', 'ml', '330', 'ml', 'urine', ':', '330', 'ml', 'ng', ':', 'stool', ':', 'drains', ':', 'balance', ':', '0', 'ml', '-', '44', 'ml', 'respiratory', 'support', 'o', '##2', 'delivery', 'device', ':', 'nasal', 'can', '##nu', '##la', 'sp', '##o', '##2', ':', '94', '%', 'ab', '##g', ':', '/', '/', '/', '25', '/', 'physical', 'examination', 'peripheral', 'vascular', ':', '(', 'right', 'radial', 'pulse', ':', 'not', 'assessed', ')', ',', '(', 'left', 'radial', 'pulse', ':', 'not', 'assessed', ')', ',', '(', 'right', 'd', '##p', 'pulse', ':', 'not', 'assessed', ')', ',', '(', 'left', 'd', '##p', 'pulse', ':', 'not', 'assessed', ')', 'skin', ':', 'not', 'assessed', 'ne', '##uro', '##logic', ':', 'responds', 'to', ':', 'not', 'assessed', ',', 'movement', ':', 'not', 'assessed', ',', 'tone', ':', 'not', 'assessed', 'labs', '/', 'radio', '##logy', '133', 'k', '/', 'ul', '5', 'g', '/', 'dl', '132', 'mg', '/', 'dl', '8', 'mg', '/', 'dl', '25', 'me', '##q', '/', 'l', '1', 'me', '##q', '/', 'l', '35', 'mg', '/', 'dl', '106', 'me', '##q', '/', 'l', '140', 'me', '##q', '/', 'l', '8', '%', '9', 'k', '/', 'ul', '12', ':', '06', 'am', '01', ':', '34', 'am', 'wb', '##c', '9', 'hc', '##t', '8', 'pl', '##t', '133', 'cr', '1', '8', 'glucose', '73', '132', 'other', 'labs', ':', 'pt', '/', 'pt', '##t', '/', 'in', '##r', ':', '0', '/', '3', '/', '4', ',', 'alt', '/', 'as', '##t', ':', '40', '/', '41', ',', 'ca', '+', '+', ':', '6', 'mg', '/', 'dl', ',', 'mg', '+', '+', ':', '2', 'mg', '/', 'dl', ',', 'po', '##4', ':', '8', 'mg', '/', 'dl', 'imaging', ':', 'none', 'micro', '##biology', ':', 'none', 'assessment', 'and', 'plan', 'vent', '##ric', '##ular', 'ta', '##chy', '##card', '##ia', ',', 'sustained', 'cancer', '(', 'mali', '##gnant', 'neo', '##pl', '##as', '##m', ')', ',', 'other', 'assessment', 'and', 'plan', '87', '##yo', 'woman', 'with', 'h', '/', 'o', 'cad', ',', 'afi', '##b', 'on', 'do', '##fe', '##tal', '##ide', ',', 'h', '/', 'o', 'v', 'ta', '##ch', 's', '/', 'p', 'pp', '##m', '/', 'ic', '##d', ',', 'cm', '##l', 'on', 'glee', '##ve', '##c', 'but', 'not', 'taking', ',', 'type', '2', 'diabetes', 'mel', '##lit', '##us', ',', 'ck', '##d', ',', 'who', 'initially', 'presented', 'to', 'the', 'b', '##mt', 'service', 'with', 'vertigo', 'and', 'vomiting', 'on', ',', 'and', 'a', 'white', 'count', 'of', '173', 'thought', 'to', 'be', 'due', 'to', 'un', '##tre', '##ated', 'cm', '##l', '.', 'now', 'transferred', 'to', 'the', 'cc', '##u', 'for', 'management', 'of', 'v', 'ta', '##ch', '.', '.', '#', 'vent', '##ric', '##ular', 'ta', '##chy', '##card', '##ia', ':', 'most', 'likely', 'et', '##iology', 'is', 'h', '##yp', '##oka', '##lem', '##ia', 'in', 'the', 'setting', 'of', 'di', '##ures', '##is', 'with', 'las', '##ix', '.', 'disco', '##nti', '##nu', '##ation', 'of', 'do', '##fe', '##tal', '##ide', 'may', 'also', 'be', 'contributing', '.', 'another', 'possibility', 'includes', 'tumor', 'l', '##ysis', 'syndrome', ',', 'which', 'is', 'known', 'to', 'cause', 'cardiac', 'd', '##ys', '##ry', '##th', '##mia', '##s', '.', 'however', 'this', 'is', 'less', 'likely', 'in', 'the', 'setting', 'of', 'h', '##yp', '##oka', '##lem', '##ia', '(', 'usually', 'hyper', '##kal', '##emia', ')', 'and', 'normal', 'phosphate', '.', 'ia', '##tro', '##genic', 'hyper', '##thy', '##roid', '##ism', 'possible', '.', 'is', '##che', '##mia', '/', 'h', '##yp', '##ox', '##ia', '/', 'infection', 'less', 'likely', 'contributors', '.', 'per', 'ep', ',', 'pace', '##r', 'functioning', 'appropriately', '.', '-', 'correct', 'h', '##yp', '##oka', '##lem', '##ia', 'and', 'h', '##yp', '##oma', '##gne', '##se', '##mia', 'stat', '-', 'rec', '##he', '##ck', 'k', 'and', 'tumor', 'l', '##ysis', 'labs', '-', 'check', 'ts', '##h', '-', 'if', 'e', '/', 'o', 'increased', 'tumor', 'l', '##ysis', 'will', 'd', '/', 'w', 'hem', '/', 'on', '##c', 're', 'slowing', 'rate', 'of', 'chemotherapy', '-', 'continuous', 'tel', '##eme', '##try', '-', 'ami', '##oda', '##rone', 'bo', '##lus', 'and', 'drip', '-', 'continue', 'met', '##op', '##rol', '##ol', '25', '##mg', 'po', 'bid', '-', 'ic', '##d', 'reset', 'at', 'over', '##drive', 'pacing', 'at', 'rate', 'of', '128', 'with', '8', 'es', '##cala', '##ting', 'attempts', 'until', 'shock', '-', 'lid', '##oca', '##ine', 'at', 'bedside', 'in', 'case', 'over', '##drive', 'pacing', 'fails', '-', 'ep', 'consult', 'closely', 'following', 'and', 'their', 'input', 'is', 'much', 'appreciated', '-', 'goals', 'of', 'care', 'clarified', 'with', 'patient', 'and', 'hc', '##p', '(', 'daughter', ')', ',', 'pt', 'is', 'ok', 'with', 'ic', '##d', 'shocks', ',', 'but', 'does', 'not', 'want', 'any', 'external', 'interventions', 'beyond', 'such', 'as', 'shocks', ',', 'cp', '##r', ',', 'or', 'int', '##uba', '##tion', ',', 'even', 'if', 'she', 'becomes', 'unstable', '.', 'therefore', ',', 'she', 'is', 'd', '##nr', '/', 'd', '##ni', '.', '.', '#', 'cm', '##l', ':', 'patient', \"'\", 's', 'white', 'count', 'at', '87', ',', 'coming', 'down', 'after', 'glee', '##ve', '##c', '.', '-', 'continue', 'glee', '##ve', '##c', '400', '##mg', 'po', 'daily', '(', 'started', ')', '-', 'pro', '##ch', '##lor', '##az', '##ap', '##ine', '/', 'z', '##of', '##ran', 'pr', '##n', 'nausea', '-', 'tumor', 'l', '##ysis', 'labs', '-', 'b', '##mt', 'rec', '##s', '-', 'all', '##op', '##uri', '##no', '##l', '100', '##mg', 'po', 'daily', 'for', 'tumor', 'l', '##ysis', 'pp', '##x', '(', 'clarify', 'with', 'hem', '/', 'on', '##c', 'if', 'correct', 'dose', ')', '.', '#', 'chronic', 'sy', '##sto', '##lic', 'heart', 'failure', ':', 'patient', 'appears', 'slightly', 'hyper', '##vo', '##lem', '##ic', '.', 'would', 'benefit', 'from', 'di', '##ures', '##is', ',', 'however', 'will', 'hold', 'off', 'given', 'v', 'ta', '##ch', 'and', 'electro', '##ly', '##te', 'abnormalities', '.', '-', 'hold', 'on', 'di', '##ures', '##is', 'for', 'now', '-', 'continue', 'met', '##op', '##rol', '##ol', '25', '##mg', 'po', 'bid', '-', 'hold', 'ir', '##bes', '##art', '##an', '*', 'n', '##f', '*', '75', 'mg', 'po', 'daily', '.', '#', 'afi', '##b', '/', 'afl', '##utter', ':', 'do', '##fe', '##ti', '##lide', 'initially', 'held', 'because', 'of', 'renal', 'failure', '.', 'no', 'active', 'issues', 'at', 'present', '.', 'co', '##uma', '##din', 'also', 'held', 'for', 'unclear', 'reasons', '.', '-', 'clarify', 'with', 'hem', '/', 'on', '##c', 'why', 'holding', 'co', '##uma', '##din', '-', 'continue', 'met', '##op', '##rol', '##ol', '25', '##mg', 'po', 'bid', '.', '#', 'ck', '##d', ':', 'stable', ',', 'improved', 'from', 'baseline', '.', '-', 'consider', 'restart', '##ing', 'do', '##fe', '##ti', '##lide', ',', 'will', 'd', '/', 'w', 'ep', 'in', 'am', '-', 'monitor', 'cr', '.', '#', 'cad', ':', 'no', 'active', 'issues', '.', '-', 'continue', 'asa', '-', 'no', 'stat', '##in', 'due', 'to', 'my', '##opa', '##thy', '.', '#', 'd', '##m', ':', 'no', 'active', 'issues', '.', '-', 'g', '##lar', '##gin', '##e', '23', 'hs', '-', 'ss', '##i', '.', '#', 'h', '##yp', '##oth', '##yr', '##oid', '##ism', ':', 'no', 'active', 'issues', '.', '-', 'continue', 'synth', '##roid', '-', 'checking', 'ts', '##h', '.', '#', 'fen', ':', 'cardiac', '/', 'dia', '##bet', '##ic', 'diet', '.', '#', 'access', ':', '2', 'pi', '##vs', '.', '#', 'prop', '##hyl', '##ax', '##is', ':', '-', 'd', '##v', '##t', 'pp', '##x', 'with', 'p', '##ne', '##um', '##ob', '##oot', '##s', 'for', 'now', '-', 'pain', 'management', 'with', 'ace', '##tam', '##ino', '##ph', '##en', '-', 'bow', '##el', 'regime', '##n', 'with', 'doc', '##usa', '##te', '/', 'sen', '##na', 'pr', '##n', '.', '#', 'code', ':', 'd', '##nr', '/', 'd', '##ni', 'but', 'ic', '##d', 'to', 'remain', 'active', '.', '#', 'com', '##m', ':', 'hc', '##p', 'is', 'her', 'daughter', ':', '.', 'she', 'does', 'want', 'her', 'daughter', 'notified', 'regarding', 'this', 'current', 'hospital', 'admission', '.', '.', '#', 'di', '##sp', '##o', ':', 'cc', '##u', 'for', 'now', 'ic', '##u', 'care', 'nutrition', ':', 'g', '##ly', '##ce', '##mic', 'control', ':', 'lines', ':', '20', 'gauge', '-', '11', ':', '57', 'pm', '22', 'gauge', '-', '11', ':', '59', 'pm', 'prop', '##hyl', '##ax', '##is', ':', 'd', '##v', '##t', ':', 'stress', 'ul', '##cer', ':', 'va', '##p', ':', 'comments', ':', 'communication', ':', 'comments', ':', 'code', 'status', ':', 'full', 'code', 'disposition', ':', 'cc', '##u', 'for', 'today']\n","chunk 147 tokenize start!\n","First sentence tokenized\n","['pt', 'is', 'a', '79', 'y', '/', 'o', 'male', 's', '/', 'p', 'mv', '##c', 'w', '/', 'multiple', 'injuries', 'including', 'c2', 'den', '##s', 'fx', ',', 'stern', '##al', 'fx', ',', 'bilateral', 'rib', 'fx', '##s', 'with', 'associated', 'bilateral', 'bloody', 'pl', '##eur', '##al', 'e', '##ff', '##usions', ',', 'left', 'distal', 'radius', 'fx', 'w', '/', 'di', '##sl', '##ocation', ',', 'reduced', 'and', 'set', 'in', 'sp', '##lin', '##t', ',', 'facial', 'lace', '##rations', 'and', 'multiple', 'areas', 'of', 'con', '##tus', '##ion', 'and', 'ec', '##chy', '##mos', '##is', ',', 't', '##4', 'end', 'plate', 'fx', 'and', 't', '##5', ',', '6', ',', '7', 'fx', 's', 'requiring', 'brace', 'which', 'pt', 'has', 'been', 'measured', 'for', 'and', 'may', 'be', 'arriving', 'today', '.', 'pt', 'went', 'to', 'the', 'or', 'on', 'friday', 'for', 'halo', 'placement', ',', 'tr', '##ach', ',', 'peg', ',', 'and', 'iv', '##c', 'filter', 'placement', 'as', 'well', '.', 'sunday', 'pt', 'had', 'a', 'bro', '##nch', 'for', 'des', '##at', '##uration', 'and', 'bilateral', 'ct', 'placement', 'for', 'e', '##ff', '##usions', ',', 'pt', 'also', 'started', 'on', 'triple', 'ab', '##x', 's', 'for', '+', 'bal', '.', 'trauma', ',', 's', '/', 'p', 'assessment', ':', 'ne', '##uro', 'status', 'unchanged', ',', 'alert', ',', 'mouth', '##ing', 'words', ',', 'following', 'commands', 'consistently', 'w', '/', 'all', 'ex', '##tre', '##ms', 'as', 'able', '.', 'res', 'moving', '>', 'les', '.', '+', 'cough', '/', 'gag', '.', 'per', '##rl', '##a', '.', 'low', 'grade', 'te', '##mp', 'with', 't', 'max', 'halo', 'in', 'place', '.', 'vs', '##s', '.', 'action', ':', 'ne', '##uro', 'exam', 'q', '##4', '##hr', '##s', 'o', '##ob', '-', 'chair', ',', 'halo', 'only', ',', 'no', 't', '##ls', '##o', 'md', '&', 'ne', '##uro', '##sur', '##g', 'rom', 'performed', 'pic', '##c', 'line', 'placed', 'l', 'wrist', 'sp', '##lin', '##ted', '/', 'caste', '##d', 'response', ':', 'to', '##ler', '##ating', 'sitting', 'at', 'edge', 'of', 'bed', ',', 'standing', '&', 'sitting', 'in', 'chair', '.', 'denying', 'pain', 'w', '/', 'stable', 'vs', '.', 'plan', ':', 'con', 't', 'to', 'monitor', 'bp', ',', 'u', '/', 'o', 'and', 'o', '##2', 'sat', '##s', 'closely', ',', 'con', 'pulmonary', 'toilet', ',', 'plan', 'for', 'pic', '##c', 'line', 'placement', 'in', 'ir', 'today', '.', 'hem', '##otho', '##ra', '##x', 'assessment', ':', 'remains', 'on', 'cp', '##ap', '/', 'ps', '8', '/', '5', '/', '50', '%', ',', 'sat', '##s', '95', '-', '100', '%', ',', 'su', '##ction', '##ed', 'for', 'ct', 's', 'as', 'above', ',', 'draining', 'around', 'sites', 'as', 'well', 'as', 'through', 'tubes', 'action', ':', 'ct', '##s', 'discontinued', '##dre', '##ssing', '##s', 'changed', 'over', 'left', 'and', 'right', 'tubes', 'van', '##co', ',', 'z', '##os', '##yn', ',', 'ci', '##pro', 'as', 'ordered', 'response', ':', 'gradually', 'decreased', 'output', 'over', 'night', 'plan', ':', 'con', 't', 'to', 'monitor', 'closely', 'pain', 'control', '(', 'acute', 'pain', ',', 'chronic', 'pain', ')', 'assessment', ':', 'pt', 'sleepy', 'initially', ',', 'not', 'c', '/', 'o', 'pain', '.', 'action', ':', 'med', '##icated', 'with', '5', '##cc', 's', 'ro', '##xi', '##ce', '##t', 'po', 'for', 'am', 'care', 'response', ':', 'pt', 'comfortable', 'over', 'night', 'plan', ':', 'con', 't', 'to', 'assess', ',', 'interventions', 'per', 'ns', '##g', 'care', 'plan']\n","chunk 148 tokenize start!\n","First sentence tokenized\n","['h', '##yp', '##ote', '##ns', '##ion', '(', 'not', 'shock', ')', 'assessment', ':', 'action', ':', 'response', ':', 'plan', ':', 'respiratory', 'failure', ',', 'acute', '(', 'not', 'ar', '##ds', '/', ')', 'assessment', ':', 'action', ':', 'response', ':', 'plan', ':', 'altered', 'mental', 'status', '(', 'not', 'del', '##iri', '##um', ')', 'assessment', ':', 'action', ':', 'response', ':', 'plan', ':', 'hyper', '##gly', '##ce', '##mia', 'assessment', ':', 'action', ':', 'response', ':', 'plan', ':', 'renal', 'failure', ',', 'acute', '(', 'acute', 'renal', 'failure', ',', 'ar', '##f', ')', 'assessment', ':', 'action', ':', 'response', ':', 'plan', ':']\n","chunk 149 tokenize start!\n","First sentence tokenized\n","['5', ':', '29', 'am', 'chest', '(', 'portable', 'ap', ')', 'clip', '#', 'reason', ':', 'eva', '##l', 'p', '##ne', '##um', '##otho', '##race', '##s', ',', 'e', '##ff', '##usions', 'admitting', 'diagnosis', ':', 'pl', '##eur', '##al', 'e', '##ff', '##usion', 'medical', 'condition', ':', '75', 'year', 'old', 'woman', 'with', 'bilateral', 'pl', '##eur', '##al', 'e', '##ff', '##usions', 's', '/', 'p', 'chest', 'tube', 'placement', 'with', 'known', 'bilateral', 'apical', 'p', '##ne', '##um', '##otho', '##race', '##s', 'reason', 'for', 'this', 'examination', ':', 'eva', '##l', 'p', '##ne', '##um', '##otho', '##race', '##s', ',', 'e', '##ff', '##usions', 'final', 'report', 'history', ':', 'e', '##ff', '##usions', 'with', 'chest', 'tube', 'placement', '.', 'findings', ':', 'in', 'comparison', 'with', 'the', 'study', 'of', ',', 'there', 'is', 'no', 'definite', 'p', '##ne', '##um', '##otho', '##ra', '##x', ',', 'though', 'there', 'may', 'be', 'a', 'mild', 'pl', '##eur', '##al', 'cap', '##ping', 'on', 'the', 'left', '.', 'chest', 'tubes', 'remain', 'in', 'place', '.', 'continued', 'bilateral', 'pl', '##eur', '##al', 'e', '##ff', '##usions', 'with', 'underlying', 'com', '##pressive', 'ate', '##le', '##cta', '##sis', 'and', 'diffuse', 'prominence', 'of', 'inter', '##sti', '##tial', 'markings', '.']\n","chunk 150 tokenize start!\n","First sentence tokenized\n","['sin', '##us', 'ta', '##chy', '##card', '##ia', '.', 'there', 'is', 'a', 'late', 'transition', 'which', 'is', 'probably', 'normal', '.', 'compared', 'to', 'the', 'previous', 'tracing', 'late', 'transition', 'is', 'new', '.', 'tracing', '#', '2']\n","chunk 151 tokenize start!\n","First sentence tokenized\n","['3', ':', '23', 'pm', 'chest', '(', 'portable', 'ap', ')', 'clip', '#', 'reason', ':', 'eva', '##l', 'line', '/', 'et', '##t', 'admitting', 'diagnosis', ':', 'peripheral', 'vascular', 'disease', '\\\\', 'bilateral', 'leg', 'ang', '##io', '##gram', 'medical', 'condition', ':', '75', 'year', 'old', 'woman', 'reason', 'for', 'this', 'examination', ':', 'eva', '##l', 'line', '/', 'et', '##t', 'final', 'report', 'indication', ':', '75', '-', 'year', '-', 'old', 'woman', 'int', '##uba', '##ted', ',', 'assess', 'tube', 'position', '.', 'comparisons', ':', '.', 'portable', 'su', '##pine', 'chest', 'radio', '##graph', 'is', 'obtained', 'demonstrating', 'end', '##ot', '##rac', '##hea', '##l', 'tube', 'in', 'the', 'mid', 'tr', '##ache', '##a', 'and', 'swan', '-', 'gan', '##z', 'cat', '##het', '##er', 'in', 'appropriate', 'position', '.', 'increased', 'inter', '##sti', '##tial', 'markings', 'are', 'unchanged', 'from', 'the', 'previous', 'study', 'and', 'reflect', 'chronic', 'ob', '##st', '##ru', '##ctive', 'pulmonary', 'disease', 'with', 'unchanged', 'right', 'greater', 'than', 'left', 'apical', 'scar', '##ring', '.', 'no', 'pl', '##eur', '##al', 'e', '##ff', '##usion', 'or', 'p', '##ne', '##um', '##otho', '##ra', '##x', 'is', 'seen', 'with', 'normal', 'heart', 'size', '.']\n","chunk 152 tokenize start!\n","First sentence tokenized\n","['alcohol', 'withdrawal', '(', 'including', 'del', '##iri', '##um', 'tre', '##men', '##s', ',', 'dt', '##s', ',', 'seizures', ')', 'assessment', ':', 'pt', 'has', 'intermittent', 'episodes', 'of', 'acute', 'agitation', 'followed', 'by', 'di', '##sor', '##ient', '##ation', 'and', 'del', '##iri', '##um', '.', 'ta', '##chy', '##card', '##ia', 'and', 'hyper', '##tension', 'are', 'present', 'during', 'these', 'episodes', '.', 'action', ':', 'rn', 'at', 'bedside', 'to', 'function', 'as', 'a', 'sit', '##ter', ',', 'restraints', 'removed', ',', 'clear', 'firm', 'limit', 'setting', ',', 'provides', 'distraction', ',', 'frequent', 're', '-', 'orientation', 'strategies', 'implemented', ',', 'allow', 'pt', 'to', 'make', 'choices', ',', 'advanced', 'diet', ',', 'out', 'of', 'bed', 'with', 'assistance', ',', 'anti', '##psy', '##cho', '##tic', 'and', 'benz', '##od', '##ia', '##ze', '##pine', '##s', 'administered', 'as', 'ordered', ',', 'ci', '##wa', 'scale', 'assessments', 'used', 'when', 'indicated', '.', 'response', ':', 'decreased', 'episodes', 'of', 'acute', 'agitation', ',', 'decreased', 'hr', 'and', 'blood', 'pressure', ',', 'intermittent', '##ly', 'alert', 'and', 'oriented', 'to', 'person', 'place', 'and', 'time', ',', 'restraints', 'removed', 'for', 'duration', 'of', 'day', 'shift', 'with', '1', ':', '1', 'sit', '##ter', 'for', 'pt', 'safety', '.', 'plan', ':', 'continue', 'to', 'monitor', 'ci', '##wa', 'scale', ',', 're', '-', 'orientation', 'strategies', 'as', 'needed', ',', 'administer', 'benz', '##od', '##ia', '##ze', '##pine', '##s', 'and', 'anti', '##psy', '##cho', '##tic', 'medication', 'as', 'prescribed', '.']\n","chunk 153 tokenize start!\n","First sentence tokenized\n","['60', '##yo', 'male', 'with', 'history', 'of', 'renal', 'stones', ',', 'es', '##rd', 'on', 'hd', ',', 'anxiety', ',', 'and', 'hyper', '##tension', 'was', 'admitted', 'from', 'the', 'ed', 'with', 'abdominal', 'pain', '.', 'two', 'months', 'ago', 'he', 'underwent', 'external', 'lit', '##hot', '##rip', '##sy', 'for', 'a', 'left', 'kidney', 'stone', '.', 'two', 'weeks', 'ago', 'he', 'underwent', 'left', 'ur', '##eter', '##os', '##co', '##py', 'with', 'laser', 'lit', '##hot', '##rip', '##sy', 'and', 'ur', '##eta', '##l', 'ste', '##nt', 'placement', '.', 'on', ',', 'the', 'pt', 'was', 'scheduled', 'to', 'undergo', 'ste', '##nt', 'extraction', ',', 'however', 'the', 'procedure', 'was', 'unsuccessful', '.', 'he', 'presented', 'to', 'aj', '##h', 'on', 'with', 'n', '/', 'v', ',', 'chill', '##s', ',', 'abdominal', 'pain', ',', 'd', '##ys', '##uria', 'and', 'ur', '##ina', '##ry', 'frequency', 'for', 'evaluation', '.', 'on', 'he', 'was', 'transferred', 'to', 'the', 'for', 'further', 'ur', '##olo', '##gic', 'care', '.', 'a', 'ct', 'scan', 'revealed', 'a', 'possible', 'left', 'renal', 'abs', '##ces', '##s', 'and', 'possible', 'prostate', 'abs', '##ces', '##s', ',', 'as', 'well', 'as', 'bilateral', 'renal', 'cal', '##cu', '##li', 'and', 'left', 'ur', '##eter', '##al', 'calculus', '.', 'ct', 'guided', 'drainage', 'of', 'renal', 'and', 'prostate', 'abs', '##ces', '##ses', 'was', 'performed', '.', 'acute', 'pain', 'assessment', ':', 'pt', 'reports', 'abdominal', 'pain', 'which', 'he', 'reports', 'as', 'my', 'prostate', 'hurts', 'pt', 'rep', '##ror', '##ts', 'that', 'the', 'pain', 'is', 'mana', '##ga', '##ble', 'action', ':', 'pt', 'med', '##icated', 'x', '##1', 'with', '1', 'gm', 'pt', 'has', 'been', 'getting', 'o', '##ob', 'to', 'com', '##mo', '##de', 'with', 'supervision', 'response', ':', 'pt', 'reports', 'that', 'the', 'pain', 'is', 'manage', '##able', 'plan', ':', 'med', '##icate', 'for', 'pain', 'pr', '##n', 'activity', 'progression', 'sir', '##s', 'assessment', ':', 'pt', 'bo', '##lus', '##ed', '3', 'l', 'ns', 'overnight', 'for', 'h', '##yp', '##ote', '##ns', '##ion', 'wb', '##c', '8', 'this', 'am', 't', '-', 'max', '3', 'at', 'noon', 'today', 'with', 'rig', '##ors', 'action', ':', 'med', '##icated', 'x', '##1', 'with', '1', 'gm', 'blood', 'cultures', 'x', '##2', 'ua', '##c', '&', 's', 'sent', 'response', ':', 'pt', 'has', 'remained', 'norm', '##ote', '##ns', '##ive', 'all', 'day', 'lac', '##tate', '1', 'this', 'afternoon', 'plan', ':', 'continue', 'antibiotics', 'as', 'ordered', 'follow', 'micro', 'data', 'monitor', 'closely']\n","chunk 154 tokenize start!\n","First sentence tokenized\n","['8', ':', '13', 'am', 'chest', '(', 'portable', 'ap', ')', 'clip', '#', 'reason', ':', 'pu', '##lm', 'va', '##sc', 'congestion', '##s', 'admitting', 'diagnosis', ':', 'liver', 'disease', 'medical', 'condition', ':', '42', 'year', 'old', 'man', 'with', 'ci', '##rr', '##hosis', 'reason', 'for', 'this', 'examination', ':', 'pu', '##lm', 'va', '##sc', 'congestion', '##s', 'provisional', 'findings', 'impression', '(', 'p', '##fi', ')', ':', 'lc', '##pc', 'fr', '##i', '11', ':', '59', 'am', 'p', '##fi', ':', 'swan', '-', 'gan', '##z', 'tip', 'is', 'followed', 'to', 'the', 'right', 'atrium', ',', 'at', 'the', 'origin', 'of', 'the', 'tri', '##cus', '##pid', 'valve', 'with', 'its', 'tip', 'ind', '##ist', '##in', '##ct', '.', 'better', 'lung', 'volumes', '.', 'no', 'signs', 'of', 'volume', 'over', '##load', '.', 'bi', '##bas', '##ila', '##r', 'ate', '##le', '##cta', '##sis', '.', 'final', 'report', 'chest', 'portable', 'ap', 'reason', 'for', 'exam', ':', '42', '-', 'year', '-', 'old', 'man', 'with', 'ci', '##rr', '##hosis', ',', 'pulmonary', 'vascular', 'congestion', '.', 'since', ',', 'the', 'patient', 'was', 'ex', '##tub', '##ated', '.', 'do', '##bb', '##hoff', 'tip', 'is', 'not', 'image', '##d', 'in', 'this', 'study', ',', 'below', 'the', 'dia', '##ph', '##rag', '##m', '.', 'swan', '-', 'gan', '##z', 'tip', 'is', 'followed', 'to', 'the', 'right', 'atrium', ',', 'at', 'the', 'origin', 'of', 'the', 'tri', '##cus', '##pid', 'valve', 'with', 'its', 'tip', 'ind', '##ist', '##in', '##ct', '.', 'lung', 'volumes', 'improved', '.', 'bi', '##bas', '##ila', '##r', 'and', 'right', 'mid', 'lung', 'ate', '##le', '##cta', '##sis', 'are', 'minimal', '.', 'lungs', 'are', 'otherwise', 'clear', '.', 'there', 'are', 'no', 'signs', 'of', 'volume', 'over', '##load', '.', 'the', 'card', '##iom', '##ed', '##ias', '##tina', '##l', 'silhouette', 'and', 'hi', '##lar', 'con', '##tour', '##s', 'are', 'otherwise', 'unchanged', '.']\n","chunk 155 tokenize start!\n","First sentence tokenized\n","['3', ':', '23', 'pm', 'chest', 'port', '.', 'line', 'placement', ';', '-', '76', 'by', 'same', 'physician', '#', 'reason', ':', 'pl', '##s', 'eva', '##l', 'cv', '##l', 'position', '&', '?', 'p', '##ne', '##um', '##otho', '##ra', '##x', 'admitting', 'diagnosis', ':', 'chronic', 'wound', ',', 'right', 'abdominal', 'wall', 'medical', 'condition', ':', '65', 'year', 'old', 'man', 's', '/', 'p', 'ex', '##pl', '##ora', '##tory', 'lap', '##aro', '##tom', '##y', ',', 'small', 'bow', '##el', 'res', '##ection', ',', 'revision', 'of', 'ile', '##oco', '##lic', 'ana', '##sto', '##mos', '##is', ',', 'take', '##down', 'of', 'ec', 'fist', '##ula', 'now', 's', '/', 'p', 'l', 'sc', '##v', 'cv', '##l', 'placement', 'reason', 'for', 'this', 'examination', ':', 'pl', '##s', 'eva', '##l', 'cv', '##l', 'position', '&', '?', 'p', '##ne', '##um', '##otho', '##ra', '##x', 'final', 'report', 'reason', 'for', 'examination', ':', 'follow', '##up', 'of', 'the', 'patient', 'after', 'small', 'bow', '##el', 'res', '##ection', ',', 'revision', 'of', 'the', 'ile', '##oco', '##lic', 'ana', '##sto', '##mos', '##is', '.', 'portable', 'ap', 'chest', 'radio', '##graph', 'was', 'compared', 'to', '.', 'the', 'left', 'sub', '##cl', '##avian', 'line', 'tip', 'is', 'at', 'the', 'level', 'of', 'junction', 'of', 'left', 'bra', '##chio', '##ce', '##pha', '##lic', 'vein', 'and', 'sv', '##c', '.', 'the', 'card', '##iom', '##ed', '##ias', '##tina', '##l', 'silhouette', 'is', 'stable', '.', 'the', 'left', 'basal', 'ate', '##le', '##cta', '##sis', 'is', 'unchanged', '.', 'there', 'is', 'no', 'evidence', 'of', 'p', '##ne', '##um', '##otho', '##ra', '##x', ',', 'apical', 'hem', '##ato', '##ma', 'after', 'insertion', 'of', 'the', 'central', 've', '##nous', 'line', '.']\n","chunk 156 tokenize start!\n","First sentence tokenized\n","['70', '##y', 'f', 'struck', 'by', 'motor', 'vehicle', 'in', 'front', 'lawn', ',', 'presented', 'to', 'to', 'os', '##h', 'w', '/', 'gs', '15', ',', 'subsequent', 'mental', 'status', 'deterioration', ',', 'int', '##uba', '##ted', 'and', 'transfer', '##ed', '.', 'injuries', 'include', ':', 'sa', '##h', '/', 'sd', '##h', 'w', '/', 'small', 'mid', '##line', 'shift', 'r', 'l', '##2', 'transverse', 'process', 'fx', 'r', 'ace', '##ta', '##bular', 'non', '-', 'displaced', 'fx', 'r', 'in', '##f', 'and', 'l', 'su', '##p', 'pub', '##ic', 'ram', '##us', 'fx', '.', 'r', '6th', 'rib', 'fx', 'l', 'medial', 'fe', '##moral', 'con', '##dy', '##le', ',', 'pro', '##xi', '##mal', 'fi', '##bula', 't', '##12', 'bust', 'fracture', '(', 'needs', 't', '##ls', '##o', 'brace', 'for', '>', '30', '##de', '##gree', '##s', ')', 'hyper', '##gly', '##ce', '##mia', 'assessment', ':', 'pt', 'with', 'h', '/', 'o', 'd', '##m', 'continues', 'on', 'g', '##ly', '##pi', '##zi', '##de', ',', 'nh', '##p', 'and', 'insulin', 'gt', '##t', 'action', ':', 'blood', 'sugar', '##s', 'checked', 'q', '##1', '##ho', '##ur', 'response', ':', 'pt', 'continues', 'with', 'elevated', 'bs', ',', 'on', 'insulin', 'gt', '##t', ',', 'np', '##h', 'and', 'oral', 'agents', 'plan', ':', 'continue', 'to', 'monitor', 'blood', 'sugar', '##s', ',', 'adjust', 'gt', '##t', 'accordingly', 'and', 'we', '##an', 'off', 'once', 'bs', 'more', 'stable', 'pain', 'control', '(', 'acute', 'pain', ',', 'chronic', 'pain', ')', 'assessment', ':', 'pt', 'grim', '##acing', 'with', 'nursing', 'care', 'and', 'turning', ',', 'occasionally', 'ta', '##chy', '##card', '##ic', 'and', 'hyper', '##tens', '##ive', 'action', ':', 'fen', '##tan', '##yl', 'patch', 'dose', 'increased', 'to', '75', '##mc', '##gs', '/', 'hr', 't', '##p', ',', 'ro', '##xi', '##ce', '##t', 'given', 'pr', '##n', 'and', 'ty', '##len', '##ol', 'given', 'at', '##c', 'response', ':', 'pt', 'appearing', 'more', 'comfortable', 'throughout', 'shift', 'plan', ':', 'continue', 'to', 'monitor', 'for', 'pain', 'and', 'med', '##icate', 'as', 'needed', 'respiratory', 'failure', ',', 'acute', '(', 'not', 'ar', '##ds', '/', ')', 'assessment', ':', 'pt', 'oral', '##ly', 'int', '##uba', '##ted', 'on', 'sim', '##v', 'with', 'clear', 'lung', 'sounds', 'and', 'diminished', 'bases', ',', 'su', '##ction', '##ed', 'for', 'moderate', 'amounts', 'of', 'thick', 'tan', 'secret', '##ions', ',', 'ab', '##g', 'w', '##nl', 'with', 'presumed', 'pneumonia', 'action', ':', 'mouth', 'care', 'q', '##4', '##ho', '##urs', ',', 'frequent', 'rep', '##osition', '##ing', 'and', 'respiratory', 'assessments', ',', 'ce', '##fe', '##pi', '##me', ',', 'ci', '##pro', 'and', 'van', '##co', 'administered', 'as', 'ordered', 'response', ':', 'pt', 'af', '##eb', '##ril', '##e', 'and', 'to', '##ler', '##ating', 'vent', 'settings', 'plan', ':', 'continue', 'to', 'monitor', 'respiratory', 'status', 'and', 'med', '##s', 'as', 'ordered', ',', 'plan', 'for', 'tr', '##ach', 'and', 'peg', 'tomorrow', 'sub', '##dur', '##al', 'hem', '##or', '##rh', '##age', '(', 'sd', '##h', ')', 'assessment', ':', 'pt', 'opens', 'eyes', 'to', 'name', ',', 'does', 'not', 'track', 'speaker', ',', 'mae', 's', ',', 'lu', '##e', 'strongest', 'and', 'purpose', '##ful', 'towards', 'et', '##t', '.', 'not', 'following', 'commands', '.', 'strong', 'cough', 'and', 'gag', 'which', 'is', 'improved', 'from', 'previous', 'exams', '.', 'pupils', 'bilateral', '##ly', 'and', 'equal', '.', 'pt', 'now', 'able', 'to', 'lift', 'head', 'off', 'bed', 'action', ':', 'ne', '##uro', 'checks', 'q', '##4', '##ho', '##urs', ',', 'ke', '##pp', '##ra', 'as', 'ordered', 'response', ':', 'pt', 'remains', 'with', 'above', 'noted', 'exam', 'plan', ':', 'continue', 'to', 'monitor', 'ne', '##uro', 'status', 'and', 'update', 'team', 'of', 'changes', ',', 'ke', '##pp', '##ra', 'as', 'ordered']\n","chunk 157 tokenize start!\n","First sentence tokenized\n","['sin', '##us', 'rhythm', 'with', 'first', 'degree', 'a', '-', 'v', 'block', '.', 'progressive', 't', 'wave', 'inversion', '##s', 'in', 'the', 'inferior', 'leads', 'consistent', 'with', 'progressing', 'my', '##oca', '##rdial', 'in', '##far', '##ction', '.', 'non', '-', 'specific', 'st', 'segment', 'changes', 'pre', '##cor', '##dial', '##ly', 'could', 'reflect', 'reciprocal', 'changes', 'or', 'is', '##che', '##mia', '.', 'clinical', 'correlation', 'is', 'suggested', '.', 'compared', 'to', 'tracing', '#', '2', 't', 'wave', 'inversion', '##s', 'are', 'progressing', 'inferior', '##ly', '.', 'premature', 'vent', '##ric', '##ular', 'contraction', '##s', 'are', 'not', 'seen', 'and', 'at', '##rial', 'pacing', 'is', 'not', 'seen', '.', 'tracing', '#', '3']\n","chunk 158 tokenize start!\n","First sentence tokenized\n","['see', 'h', '&', 'p', 'for', 'details', '.', 'briefly', '74', '##m', 'w', '/', 'et', '##oh', 'ci', '##rr', '##hosis', 'who', 'stopped', 'his', 'ne', '##xi', '##um', 'and', 'started', 'taking', 'asa', 'daily', ',', 'increasing', 'mel', '##ena', 'and', 'fatigue', ',', 'hc', '##t', '24', 'hour', 'events', ':', 'end', '##os', '##co', '##py', 'evidence', 'of', 'recent', 'var', '##ice', '##al', 'bleed', ',', 'grade', '2', 'var', '##ices', ',', 'duo', '##den', '##al', 'vi', '##llo', '##us', 'blunt', '##ing', ',', 'gas', '##tri', '##tis', 'trans', '##fus', '##ed', '2', '##u', 'pr', '##bc', '##s', 'gas', '##tro', '##int', '##estinal', 'bleed', ',', 'other', '(', 'gi', 'bleed', ',', 'gi', '##b', ')', 'assessment', ':', 'no', 'bleeding', 'noted', ',', 'sb', '##p', '>', '100', ',', 'continues', 'on', 'oct', '##re', '##otide', 'and', 'pan', '##tro', '##pa', '##zo', '##le', 'iv', ',', 'u', '##o', '<', '30', '##ml', '/', 'hr', '.', 'k', '4', 'action', ':', 'hc', '##t', '@', '09', '##00', ',', 'ho', 's', 'aware', 'of', 'decreased', 'u', '##o', ',', 'liver', 'team', 'into', 'assess', 'pt', ',', '20', 'me', '##q', 'kc', '##l', 'in', '##25', '##0', 'ml', 'in', '##fus', '##ing', 'over', '2', 'hours', ',', 'response', ':', 'hc', '##t', '7', ',', '^', 'u', '##o', 'with', '250', 'ml', ',', '?', 'trans', '##fus', '##e', 'vs', 'fluid', 'bo', '##lus', ',', 'plan', ':', 'monitor', 'for', 'bleeding', ',', 'hc', '##t', 'q', '##12', '##hr', ',', 'trans', '##fus', '##e', 'per', 'orders', ',', 'pan', '##top', '##raz', '##ole', 'changed', 'to', 'q', '##12', '##hr', 'gt', '##t', 'dc', 'd', ',', 'continue', 'oct', '##re', '##otide', ',', '?', 'abd', 'ct', '+', 'diagnostic', 'para', '##cent', '##esis', ',', 'ci', '##pro', 'approval', 'and', 'administer', 'x', '5', 'days', '.', 'liver', 'protocol', '.', '?', 'transfer', 'to', 'liver', 'floor', '.', 'altered', 'mental', 'status', '(', 'not', 'del', '##iri', '##um', ')', 'assessment', ':', 'easily', 'ar', '##ous', '##able', ',', 'oriented', 'to', 'self', 'do', '##b', ',', 'place', 'hospital', '(', 'could', 'not', 'tell', 'me', 'which', 'one', ')', 'year', 'then', 'corrected', 'me', 'when', 'i', 'said', '09', 'he', 'said', 'no', ',', ',', 'follows', 'commands', ',', 'agitated', 'when', 'initially', 'approached', ',', 'admits', 'to', 'back', 'pain', 'resolve', '##s', 'with', 'rep', '##osition', '##ing', '.', 'aware', 'of', 'month', 'and', 'president', ',', 'wife', '##s', 'name', '.', 'denies', 'seeing', '/', 'hearing', 'things', '.', 'skin', 'warm', 'and', 'dry', ',', 'sr', 'one', '8', 'second', 'run', 'of', 'sv', '##t', 'action', ':', 're', '##ori', '##ented', 'to', 'pr', '##n', ',', 're', '##ass', '##urance', 'offered', ',', 'liver', 'attending', 'into', 'visit', 'and', 'update', 'pt', '.', 'val', '##ium', '5', 'mg', 'po', 'at', 'response', ':', 'pt', 'remains', 'calm', ',', 'good', 'effect', 'from', 'val', '##ium', 'plan', ':', 'monitor', 'mental', 'status', ',', 'ci', '##wa', 'scale', ',', 'offer', 're', '##ass', '##urance', ',', 'transfer', 'to', 'floor', 'as', 'per', 'orders', ',', '?', 'dc', 'to', 'rehab', '?', 'monday', 'per', 'liver', 'attending', '.', 'diabetes', 'mel', '##lit', '##us', '(', 'd', '##m', ')', ',', 'type', 'i', 'assessment', ':', 'glucose', '100', 'action', ':', 'no', 'ss', '##i', 'this', 'am', ',', 'assisted', 'with', 'clear', 'liquids', ',', 'response', ':', 'tolerated', 'pills', 'and', 'clear', 'liquids', 'without', 'issue', 'plan', ':', 'monitor', 'glucose', '##s', '/', 'ss', '##i', 'as', 'per', 'orders', '.', 'see', 'h', '&', 'p', 'for', 'details', '.', 'briefly', '74', '##m', 'w', '/', 'et', '##oh', 'ci', '##rr', '##hosis', 'who', 'stopped', 'his', 'ne', '##xi', '##um', 'and', 'started', 'taking', 'asa', 'daily', ',', 'increasing', 'mel', '##ena', 'and', 'fatigue', ',', 'hc', '##t', '24', 'hour', 'events', ':', 'end', '##os', '##co', '##py', 'evidence', 'of', 'recent', 'var', '##ice', '##al', 'bleed', ',', 'grade', '2', 'var', '##ices', ',', 'duo', '##den', '##al', 'vi', '##llo', '##us', 'blunt', '##ing', ',', 'gas', '##tri', '##tis', 'tran', '##fus', '##ed', 'with', 'one', 'unit', 'packed', 'cells', '25', '##g', 'album', '##in', 'at', '1400', 'urine', 'output', 'continues', '20', '-', '25', '##cc', 'hourly', '.', 'became', 'very', 'agitated', 'and', 'angry', 'at', 'yelling', 'out', '.', 'i', 'want', 'a', 'new', 'doctor', 'where', 'are', 'my', 'peach', '##es', 'waving', 'nurse', 'away', 'get', 'out', 'of', 'my', 'room', '.', '5', 'mg', 'val', '##ium', 'given', 'with', 'improvement', 'of', 'agitation', '.', 'hc', '##t', 'due', 'at', '9', '##pm', '.', 'demographics', 'attending', 'md', ':', 'd', '.', 'admit', 'diagnosis', ':', 'upper', 'gi', 'b', '##lle', '##ed', 'code', 'status', ':', 'full', 'code', 'height', ':', '28', 'inch', 'admission', 'weight', ':', '75', 'kg', 'daily', 'weight', ':', '5', 'kg', 'all', '##er', '##gies', '/', 'reactions', ':', 'no', 'known', 'drug', 'all', '##er', '##gies', 'precautions', ':', 'pm', '##h', ':', 'an', '##emia', ',', 'cop', '##d', ',', 'diabetes', '-', 'insulin', ',', 'et', '##oh', ',', 'gi', 'bleed', 'cv', '-', 'pm', '##h', ':', 'hyper', '##tension', 'additional', 'history', ':', 'di', '##zziness', 'and', 'ga', '##it', 'instability', 'd', '/', 't', 'ne', '##uro', '##pathy', ',', 'chronic', 'pain', 'syndrome', 'surgery', '/', 'procedure', 'and', 'date', ':', 'latest', 'vital', 'signs', 'and', 'i', '/', 'o', 'non', '-', 'invasive', 'bp', ':', 's', ':', '115', 'd', ':', '55', 'temperature', ':', '6', 'arterial', 'bp', ':', 's', ':', 'd', ':', 'respiratory', 'rate', ':', '19', 'ins', '##p', '/', 'min', 'heart', 'rate', ':', '70', 'bp', '##m', 'heart', 'rhythm', ':', 'sr', '(', 'sin', '##us', 'rhythm', ')', 'o', '##2', 'delivery', 'device', ':', 'none', 'o', '##2', 'sat', '##uration', ':', '96', '%', '%', 'o', '##2', 'flow', ':', '2', 'l', '/', 'min', 'fi', '##o', '##2', 'set', ':', '24', '##h', 'total', 'in', ':', '3', ',', '60', '##3', 'ml', '24', '##h', 'total', 'out', ':', '44', '##8', 'ml', 'per', '##tine', '##nt', 'lab', 'results', ':', 'sodium', ':', '145', 'me', '##q', '/', 'l', '02', ':', '47', 'am', 'potassium', ':', '4', 'me', '##q', '/', 'l', '02', ':', '47', 'am', 'chloride', ':', '112', 'me', '##q', '/', 'l', '02', ':', '47', 'am', 'co', '##2', ':', '20', 'me', '##q', '/', 'l', '02', ':', '47', 'am', 'bun', ':', '28', 'mg', '/', 'dl', '02', ':', '47', 'am', 'cr', '##ea', '##tin', '##ine', ':', '8', 'mg', '/', 'dl', '02', ':', '47', 'am', 'glucose', ':', '42', 'mg', '/', 'dl', '02', ':', '47', 'am', 'hem', '##ato', '##cr', '##it', ':', '7', '%', '09', ':', '24', 'am', 'finger', 'stick', 'glucose', ':', '181', '12', ':', '00', 'pm', 'valuable', '##s', '/', 'signature', 'patient', 'valuable', '##s', ':', 'other', 'valuable', '##s', ':', 'clothes', ':', 'sent', 'home', 'with', ':', 'wallet', '/', 'money', ':', 'no', 'money', '/', 'wallet', 'cash', '/', 'credit', 'cards', 'sent', 'home', 'with', ':', 'jewelry', ':', 'transferred', 'from', ':', 'transferred', 'to', ':', 'date', '&', 'time', 'of', 'transfer', ':']\n","chunk 159 tokenize start!\n","First sentence tokenized\n","['11', ':', '14', 'am', 'av', 'fist', '##ulo', '##gram', 'sc', '##h', 'clip', '#', 'reason', ':', 'please', 'perform', 'th', '##rom', '##be', '##ct', '##omy', 'admitting', 'diagnosis', ':', 'cl', '##otted', 'av', '##g', 'contrast', ':', 'om', '##ni', '##pa', '##que', 'am', '##t', ':', '45', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', 'cp', '##t', 'codes', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', 'intro', 'dial', '##ysis', 'fist', '##ula', 'non', '-', 'tunnel', '##ed', '*', '*', 'flu', '##oro', 'gui', '##d', 'plc', '##t', '/', 'rep', '##lc', '##t', '/', 'remove', 'us', 'gui', '##d', 'for', 'va', '##s', '.', 'access', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', '*', 'medical', 'condition', ':', '83', 'year', 'old', 'woman', 'with', 'es', '##rd', 'on', 'hd', '(', 'mw', '##f', ')', 'presented', 'with', 'inability', 'to', 'have', 'l', 'av', '##g', 'accessed', 'today', 'in', 'dial', '##ysis', ',', 'was', 'functioning', 'on', 'wednesday', ',', 'bedside', 'u', '/', 's', 'shows', 'cl', '##ot', ',', 'no', 'he', '##par', '##in', 'given', 'at', 'this', 'time', ',', 'transplant', 'surgery', 'informed', '.', 'reason', 'for', 'this', 'examination', ':', 'please', 'perform', 'th', '##rom', '##be', '##ct', '##omy', 'final', 'report', 'attempted', 'av', 'graf', '##t', '-', 'gram', 'and', 'dec', '##lot', ';', 'temporary', 'hem', '##od', '##ial', '##ysis', 'cat', '##het', '##er', 'placement', '.', 'operators', ':', 'dr', '##s', '.', '(', 'fellow', ')', 'and', '(', 'attending', 'physician', ')', '.', 'doctor', 'was', 'present', 'throughout', 'the', 'procedure', '.', 'indication', ':', '83', '-', 'year', '-', 'old', 'woman', 'with', 'end', '-', 'stage', 'renal', 'disease', 'on', 'hem', '##od', '##ial', '##ysis', 'presenting', 'with', 'inability', 'to', 'use', 'left', 'av', 'graf', '##t', 'on', 'dial', '##ysis', '.', 'se', '##dation', ':', 'moderate', 'se', '##dation', 'with', 'divided', 'doses', 'of', 'intra', '##ven', '##ous', '75', 'mc', '##g', 'fen', '##tan', '##yl', 'and', '5', 'mg', 'verse', '##d', 'over', '2', 'hours', 'and', '55', 'minutes', 'during', 'which', 'patient', \"'\", 's', 'hem', '##od', '##yna', '##mic', 'status', 'was', 'continuously', 'monitored', 'by', 'a', 'trained', 'radio', '##logy', 'nurse', '.', 'contrast', ':', 'sterile', '45', 'ml', 'om', '##ni', '##pa', '##que', 'procedure', ':', 'consent', 'was', 'obtained', 'from', 'the', 'patient', 'after', 'explaining', 'the', 'benefits', ',', 'risks', 'and', 'alternatives', '.', 'patient', 'was', 'placed', 'su', '##pine', 'on', 'the', 'imaging', 'table', 'in', 'the', 'intervention', '##al', 'suite', '.', 'time', '##out', 'was', 'performed', 'as', 'per', 'protocol', '.', 'color', 'son', 'of', 'the', 'left', 'arm', 'av', 'graf', '##t', 'was', 'performed', '.', 'under', 'as', '##ept', '##ic', 'conditions', 'and', 'son', 'and', 'pal', '##pa', '##tory', 'guidance', ',', 'a', '19', '-', 'gauge', 'needle', 'was', 'placed', 'in', 'the', 'left', 'arm', 'av', 'graf', '##t', 'with', 'the', 'needle', 'tip', 'pointing', 'towards', 'the', 've', '##nous', 'out', '##flow', '.', 'a', '01', '##8', 'wire', 'was', 'advanced', 'through', 'the', 'needle', 'and', 'into', 'the', 've', '##nous', 'out', '##flow', '.', 'after', 'removing', 'the', '01', '##8', 'wire', ',', 'a', '03', '##5', 'wire', 'was', 'advanced', 'through', 'the', 'needle', 'and', 'into', 'the', 'ax', '##illa', '##ry', 'vein', '.', 'needle', 'was', 'exchanged', 'for', 'a', '4', 'french', 'tip', 'sheath', '.', 'after', 'removing', 'the', 'inner', 'can', '##nu', '##la', 'and', 'wire', ',', 'a', 'small', 'amount', 'of', 'sterile', 'contrast', 'material', 'was', 'injected', 'through', 'the', 'side', '##arm', '.', 'subsequently', ',', 'a', '4', 'french', 'mp', '##a', 'cat', '##het', '##er', 'was', 'advanced', 'through', 'the', 'sheath', 'and', 'over', 'a', 'glide', '##wire', 'to', 'the', 'left', 'sub', '##cl', '##avian', 'vein', '.', 'hand', 'injection', 'was', 'performed', 'to', 'study', 'the', 'central', 'and', 'left', 'mid', '##line', 've', '##nous', 'structures', '.', 'the', 'cat', '##het', '##er', 'was', 'slowly', 'withdrawn', 'while', 'in', '##ject', '##ing', 'the', 'contrast', 'to', 'assess', 'the', 've', '##nous', 'out', '##flow', 'tract', '.', 'under', 'as', '##ept', '##ic', 'conditions', 'and', 'son', 'guidance', ',', 'a', 'micro', '##pu', '##nc', '##ture', 'needle', 'was', 'placed', 'in', 'the', 'patent', 'left', 'internal', 'jug', '##ular', 'vein', '.', 'a', '01', '##8', 'wire', 'was', 'advanced', 'through', 'the', 'needle', 'and', 'into', 'the', 'iv', '##c', '.', 'needle', 'was', 'exchanged', 'for', 'a', '5', 'french', '(', 'over', ')', '11', ':', '14', 'am', 'av', 'fist', '##ulo', '##gram', 'sc', '##h', 'clip', '#', 'reason', ':', 'please', 'perform', 'th', '##rom', '##be', '##ct', '##omy', 'admitting', 'diagnosis', ':', 'cl', '##otted', 'av', '##g', 'contrast', ':', 'om', '##ni', '##pa', '##que', 'am', '##t', ':', '45', 'final', 'report', '(', 'con', '##t', ')', 'micro', '##sh', '##ea', '##th', '.', 'appropriate', 'measurements', 'were', 'made', '.', 'inner', 'can', '##nu', '##la', 'and', 'wire', 'were', 'removed', 'to', 'place', 'a', '03', '##5', 'wire', ',', 'which', 'was', 'advanced', 'into', 'the', 'iv', '##c', '.', 'after', 'removing', 'the', 'micro', '##sh', '##ea', '##th', 'and', 'dil', '##ating', 'the', 'tract', 'with', 'a', '12', 'french', 'dil', '##ator', 'under', 'flu', '##oro', '##sco', '##py', ',', 'a', '12', 'french', '20', '-', 'cm', 'temporary', 'hem', '##od', '##ial', '##ysis', 'cat', '##het', '##er', 'with', 'vip', 'port', 'was', 'placed', 'over', 'the', 'wire', '.', 'cat', '##het', '##er', 'tip', 'was', 'confirmed', 'under', 'flu', '##oro', '##sco', '##py', 'to', 'be', 'in', 'the', 'lower', 'sv', '##c', '.', 'ports', 'were', 'as', '##pi', '##rated', 'and', 'flushed', '.', 'cat', '##het', '##er', 'was', 'secured', 'by', '0', 'silk', 'su', '##tures', '.', 'site', 'was', 'appropriately', 'dressed', '.', 'patient', 'tolerated', 'the', 'procedure', 'well', 'and', 'no', 'immediate', 'post', '-', 'procedure', 'complications', 'were', 'seen', '.', 'findings', ':', 'complete', 'th', '##rom', '##bos', '##is', 'of', 'the', 'left', 'arm', 'av', 'graf', '##t', '.', 'flow', 'was', 'noted', 'in', 'the', 'arterial', 'in', '##flow', 'on', 'son', '.', 'near', '-', 'complete', 'th', '##rom', '##bos', '##is', 'of', 'the', 'left', 'arm', 've', '##nous', 'out', '##flow', 'tract', '.', 'of', 'note', ',', 'was', 'the', 'extra', '##vas', '##ation', 'of', 'contrast', 'from', 'the', 'graf', '##t', 'adjacent', 'to', 'its', 've', '##nous', 'out', '##flow', 'ana', '##sto', '##mos', '##is', ',', 'presumably', 'resulting', 'from', 'prior', 'graf', '##t', 'access', '.', 'further', 'attempts', 'at', 'av', 'graf', '##t', 'dec', '##lot', 'were', 'abandoned', '.', 'impression', ':', 'un', '##com', '##pl', '##icated', 'av', 'graf', '##t', '-', 'gram', '.', 'unsuccessful', 'attempt', 'at', 'dec', '##lot', '##ting', '.', 'flu', '##oro', '##sco', '##py', 'and', 'son', 'used', 'for', 'guidance', '.', 'un', '##com', '##pl', '##icated', 'placement', 'of', 'a', '12', 'french', '20', '-', 'cm', 'temporary', 'hem', '##od', '##ial', '##ysis', 'cat', '##het', '##er', 'with', 'vip', 'port', 'via', 'the', 'patent', 'left', 'i', '##j', '##v', 'and', 'with', 'its', 'tip', 'in', 'the', 'lower', 'sv', '##c', ',', 'under', 'flu', '##oro', '##scopic', 'and', 'son', 'guidance', '.']\n","chunk 160 tokenize start!\n","First sentence tokenized\n","['date', 'of', 'service', ':', 'requesting', 'physician', ':', 'initial', 'consultation', ':', 'cc', '##u', 'presenting', 'complaint', ':', 'ar', '##rh', '##yt', '##hmi', '##a', ',', '(', 'other', ':', 'vt', ')', 'history', 'of', 'present', 'illness', ':', '51', 'yo', 'm', 'with', 'newly', 'diagnosed', 'heart', 'mum', '##ur', 'and', 'tt', '##e', 'showed', 'ao', '##rti', '##c', 'mass', '4', '##x', '##4', 'and', '+', 'ai', 'had', 'av', '##r', 'pod', '#', '.', 'bio', '##pro', '##st', '##hetic', 'av', '##r', '.', 'post', '-', 'op', 'no', 'com', '##plication', 'except', 'afi', '##b', ',', 'well', 'rate', 'controlled', 'but', 'on', 'floor', '1', ':', '43', '##am', 'vent', 'into', 'vt', '200', '##b', '##pm', 'with', 'sync', '##ope', 'and', 'card', '##io', '##verted', 'by', '##1', ':', '47', '##am', '.', 'now', 'still', 'in', 'afi', '##b', 'and', 'on', 'ami', '##oda', '##rone', '.', 'past', 'medical', 'history', ':', 'none', 'cad', 'risk', 'factors', 'cad', 'risk', 'factors', 'present', 'd', '##ys', '##lip', '##ide', '##mia', ',', 'hyper', '##tension', 'cad', 'risk', 'factors', 'absent', 'diabetes', 'mel', '##lit', '##us', 'all', '##er', '##gies', ':', 'nk', '##da', 'no', 'known', 'drug', 'all', '##er', '##gies', 'cardiovascular', 'ro', '##s', 'cardiovascular', 'ro', '##s', 'signs', 'and', 'symptoms', 'present', 'sync', '##ope', 'cardiovascular', 'ro', '##s', 'signs', 'and', 'symptoms', 'absent', 'murmur', ',', 'r', '##he', '##umatic', 'fever', ',', 'chest', 'pain', ',', 'sob', ',', 'doe', ',', 'p', '##nd', ',', 'or', '##th', '##op', '##nea', ',', 'ed', '##ema', ',', 'pal', '##pit', '##ations', ',', 'pre', '##sy', '##nco', '##pe', ',', 'light', '##head', '##ed', '##ness', ',', 'tia', '/', 'cv', '##a', ',', 'pulmonary', 'em', '##bol', '##ism', ',', 'd', '##v', '##t', ',', 'cl', '##aud', '##ication', ',', 'ex', '##ert', '##ional', 'butt', '##ock', 'pain', ',', 'ex', '##ert', '##ional', 'calf', 'pain', 'review', 'of', 'systems', 'organ', 'system', 'ro', '##s', 'normal', 'constitutional', ',', 'eyes', ',', 'en', '##t', ',', 'respiratory', ',', 'gas', '##tro', '##int', '##estinal', ',', 'end', '##oc', '##rine', ',', 'gen', '##ito', '##uri', '##nary', ',', 'mu', '##scu', '##los', '##kel', '##eta', '##l', ',', 'int', '##eg', '##umen', '##tary', ',', 'neurological', ',', 'psychiatric', ',', 'all', '##ergy', '/', 'immune', 'signs', 'and', 'symptoms', 'absent', 'recent', 'fever', '##s', ',', 'chill', '##s', ',', 'rig', '##ors', ',', 'cough', ',', 'hem', '##op', '##ty', '##sis', ',', 'black', '/', 'red', 'stool', ',', 'bleeding', 'during', 'surgery', ',', 'joint', 'pains', ',', 'my', '##al', '##gia', '##s', 'physical', 'exam', 'date', 'and', 'time', 'of', 'exam', ':', 'general', 'appearance', ':', 'nad', 'height', ':', '71', 'inch', ',', '180', 'cm', 'bp', 'right', 'arm', ':', '125', '/', '76', 'mm', '##hg', 'semi', '-', 'su', '##pine', 'hr', ':', '72', 'bp', '##m', 'eyes', ':', '(', 'con', '##jun', '##ct', '##iva', 'and', 'lids', ':', 'w', '##nl', ')', 'ears', ',', 'nose', ',', 'mouth', 'and', 'throat', ':', '(', 'oral', 'mu', '##cos', '##a', ':', 'w', '##nl', ')', ',', '(', 'teeth', ',', 'gum', '##s', 'and', 'palette', ':', 'w', '##nl', ')', 'neck', ':', '(', 'right', 'car', '##ot', '##id', 'artery', ':', 'no', 'br', '##uit', ')', ',', '(', 'left', 'car', '##ot', '##id', 'artery', ':', 'no', 'br', '##uit', ')', ',', '(', 'jug', '##ular', 'veins', ':', 'not', 'visible', ')', 'respiratory', ':', '(', 'effort', ':', 'w', '##nl', ')', ',', '(', 'aus', '##cu', '##lta', '##tion', ':', 'w', '##nl', ')', 'cardiac', ':', '(', 'rhythm', ':', 'irregular', ')', ',', '(', 'pal', '##pati', '##on', '/', 'pm', '##i', ':', 'w', '##nl', ',', 'anterior', 'chest', 'scar', ')', ',', '(', 'aus', '##cu', '##lta', '##tion', ':', 's', '##1', ':', 'w', '##nl', ',', 's', '##3', ':', 'absent', ')', 'abdominal', '/', 'gas', '##tro', '##int', '##estinal', ':', '(', 'bow', '##el', 'sounds', ':', 'w', '##nl', ',', 'obe', '##se', ')', ',', '(', 'br', '##uit', '##s', ':', 'no', ')', 'ex', '##tre', '##mit', '##ies', '/', 'mu', '##scu', '##los', '##kel', '##eta', '##l', ':', '(', 'digits', 'and', 'nails', ':', 'w', '##nl', ')', ',', '(', 'ed', '##ema', ':', 'right', ':', '0', ',', 'left', ':', '0', ')', 'skin', ':', '(', 'w', '##nl', ')', 'labs', '188', '3', '130', '0', '32', '1', '19', '97', '136', '3', '7', '04', ':', '39', 'pm', '06', ':', '46', 'pm', '07', ':', '00', 'pm', '08', ':', '21', 'pm', '09', ':', '16', 'pm', '01', ':', '56', 'am', '01', ':', '31', 'pm', '03', ':', '33', 'am', '01', ':', '47', 'am', '05', ':', '43', 'am', 'wb', '##c', '9', '7', '7', 'h', '##gb', '5', '2', '7', '3', 'hc', '##t', '(', 'serum', ')', '6', '8', '6', '3', 'pl', '##t', '188', '127', '188', 'in', '##r', '1', '1', 'pt', '##t', '9', '7', 'na', '+', '136', '132', '132', '136', 'k', '+', '(', 'serum', ')', '5', '1', '5', '5', '3', 'k', '+', '(', 'whole', 'blood', ')', '4', 'cl', '105', '100', '101', '97', 'hc', '##o', '##3', '24', '25', '25', '32', 'bun', '23', '26', '23', '19', 'cr', '##ea', '##tin', '##ine', '4', '6', '2', '0', 'glucose', '18', '109', '130', 'ck', '121', 'ck', '-', 'mb', '2', '2', 'tr', '##op', '##oni', '##n', 't', '20', '16', 'o', '##2', 'sat', '(', 'arterial', ')', '98', '98', '98', 'ab', '##g', ':', '/', '/', '/', '32', '/', 'values', 'as', 'of', '05', ':', '43', 'am', 'tests', 'ec', '##g', ':', '(', 'date', ':', ')', ',', 'afi', '##b', '.', 'lb', '##bb', 'echo', '##card', '##io', '##gram', ':', '(', 'date', ':', ')', ',', 'tee', 'intra', '##op', '-', 'e', '##f', '50', '-', '55', '%', 'cardiac', 'cat', '##h', ':', '(', 'date', ':', ')', ',', 'lad', '-', 'mid', '30', '%', 'lc', '##x', '-', 'om', '##3', '60', '-', '70', '%', 'rca', '-', 'diffuse', 'disease', 'assessment', 'and', 'plan', 'vt', '-', 'unclear', 'et', '##iology', 'as', 'he', 'has', 'no', 'real', 'is', '##che', '##mic', 'substrate', 'for', 'vt', 'with', 'normal', 'e', '##f', 'by', 'tee', '.', 'would', 'recommend', 'formal', 'tt', '##e', 'to', 'evaluate', 'e', '##f', 'and', 'wall', 'motion', '.', 'continue', 'ami', '##o', 'for', 'now', ',', 'but', 'would', 'hold', 'on', 'co', '##uma', '##din', 'for', 'now', 'in', 'case', 'we', 'need', 'to', 'implant', 'ic', '##d', '.', 'keep', 'np', '##o', 'after', 'midnight', 'for', 'possible', 'ic', '##d', '.', 'afi', '##b', 'started', 'on', 'pod', '#', '0', ',', 'now', 'on', 'ami', '##o', '.', 'was', 'on', 'co', '##uma', '##din', 'and', 'now', 'starting', 'he', '##par', '##in', '.', 'av', '##r', '-', 'bio', '##pro', '##st', '##hetic', '.', 'd', '/', 'w', 'doctor', 'and', 'will', 're', '##asse', '##ss', 'and', 'discuss', 'with', 'patient', 'tomorrow', 'am', '.']\n","chunk 161 tokenize start!\n","First sentence tokenized\n","['pt', 'is', '67', 'yo', 'male', 'who', 'presents', 'to', 'e', '##w', 'with', 'hem', '##ate', '##mes', '##is', 'and', 'mel', '##ena', 'at', 'nursing', 'home', 'that', 'evening', '.', 'sat', '##s', 'in', 'low', '90s', 'ra', ',', 't', '103', '##r', '.', 'in', 'e', '##w', ',', 'bp', '89', '/', '51', '-', '100', '##s', '/', '.', 'ty', '##len', '##ol', 'for', 'fever', ',', 'bc', 'sent', '.', 'c', '##x', '##r', '-', '>', '>', 'p', '##na', '.', 'van', '##co', 'and', 'z', '##os', '##yn', 'given', ',', '1', '##l', 'ns', '.', 'ng', 'lava', '##ged', '250', '##cc', 'for', 'coffee', 'grounds', 'then', 'clear', '.', 'hc', '##t', '7', ',', 'wb', '##c', 'transferred', 'to', 'mic', '##u', 'for', 'further', 'care', '.', 'gas', '##tro', '##int', '##estinal', 'bleed', ',', 'other', '(', 'gi', 'bleed', ',', 'gi', '##b', ')', 'assessment', ':', 'alert', ',', 'oriented', '.', 'speech', 'is', 'ga', '##rb', '##led', 's', '/', 'p', 'cv', '##a', '.', 'denies', 'abdominal', 'pain', ',', 'or', 'any', 'pain', '.', 'abd', 'soft', ',', '+', 'bs', '.', 'no', 'stool', '##s', ',', 'n', '/', 'v', 'in', 'mic', '##u', '.', 'bp', 'high', '90s', '/', '40', '##s', ',', 'decreased', '75', '/', 'ns', '##r', '/', 'sb', '59', '-', 'color', 'pink', ',', 'skin', 'w', '&', 'd', '.', '2', 'large', 'bore', 'iv', '##s', '.', 'action', ':', '500', '##cc', 'fluid', 'bo', '##lus', '.', 'cbc', ',', 'labs', 'sent', '@', '5', '##am', '.', 'response', ':', 'bp', '^', '^', '90s', '/', '40', '##s', 'after', 'fluid', 'bo', '##lus', '.', 'repeat', 'hc', '##t', 'plan', ':', 'monitor', 'for', 'further', 'bleeding', '.', 'follow', 'hc', '##ts', '.', 'np', '##o', 'for', 'now', 'for', 'possible', 'procedure', ',', 'gi', 'to', 'see', 'pt', '.', 'proton', '##ix']\n","chunk 162 tokenize start!\n","First sentence tokenized\n","['4', ':', '08', 'pm', 'ct', 'head', 'w', '/', 'o', 'contrast', 'clip', '#', 'reason', ':', 's', '/', 'p', 'trauma', 'medical', 'condition', ':', '59', 'year', 'old', 'man', 's', '/', 'p', 'trauma', 'mcc', 'reason', 'for', 'this', 'examination', ':', 's', '/', 'p', 'trauma', 'no', 'contra', '##ind', '##ication', '##s', 'for', 'iv', 'contrast', 'wet', 'read', ':', 'sh', '##sf', 'wed', '4', ':', '48', 'pm', 'right', 'posterior', 'part', '##ie', '##tal', 'con', '##tus', '##ion', 'with', 'va', '##so', '##genic', 'ed', '##ema', 'and', 'mass', 'effect', 'on', 'the', 'right', 'lateral', 'vent', '##ric', '##le', 'without', 'shift', 'of', 'mid', '##line', 'structures', '.', 'underlying', 'mass', 'cannot', 'be', 'excluded', '.', 'vein', 'of', 'var', '##ix', ',', 'likely', 'not', 'acute', '.', 'consider', 'mr', '##v', 'on', 'a', 'non', '-', 'emerge', '##nt', 'basis', 'large', 'frontal', 'sub', '##gal', '##eal', 'hem', '##ato', '##ma', '.', 'possible', 'non', '##dis', '##placed', 'right', 'nasal', 'bone', 'fracture', '.', 'wet', 'read', 'version', '#', '1', 'final', 'report', 'indication', ':', 'status', 'post', 'motorcycle', 'accident', 'with', 'seizure', 'activity', '.', 'technique', ':', 'contiguous', 'axial', 'images', 'obtained', 'through', 'the', 'brain', 'without', 'intra', '##ven', '##ous', 'contrast', '.', 'corona', '##l', 'and', 'sa', '##git', '##tal', 'reformation', '##s', 'were', 'prepared', '.', 'comparisons', ':', 'reference', 'images', 'from', '.', 'findings', ':', 'hyper', '##den', '##sities', 'in', 'the', 'right', 'par', '##ie', '##tal', 'lobe', 'with', 'surrounding', 'va', '##so', '##genic', 'ed', '##ema', 'may', 'be', 'due', 'to', 'evolving', 'con', '##tre', '##co', '##up', 'con', '##tus', '##ion', '.', 'resultant', 'mass', 'effect', 'with', 'resultant', 'partial', 'e', '##ffa', '##ce', '##ment', 'of', 'the', 'right', 'lateral', 'vent', '##ric', '##le', 'without', 'shift', 'of', 'mid', '##line', 'structures', 'or', 'evidence', 'of', 'hydro', '##ce', '##pha', '##lus', '.', 'no', 'additional', 'sites', 'of', 'con', '##tus', '##ion', 'or', 'hem', '##or', '##rh', '##age', 'are', 'seen', '.', 'there', 'is', 'no', 'major', 'vascular', 'territorial', 'in', '##far', '##ction', '.', 'the', 'vein', 'of', 'is', 'more', 'prominent', 'than', 'usually', 'seen', '(', '2', ':', '17', ')', 'which', 'could', 'represent', 'a', 've', '##nous', 'var', '##ix', 'or', 'simply', 'reflective', 'of', 'the', 'patient', 'having', 'received', 'intra', '##ven', '##ous', 'contrast', 'at', 'the', 'outside', 'facility', '.', 'large', 'frontal', 'sub', '##gal', '##eal', 'hem', '##ato', '##ma', 'is', 'also', 'noted', '.', 'possible', 'non', '##dis', '##placed', 'right', 'nasal', 'bone', 'fracture', 'is', 'also', 'seen', '.', 'impression', ':', 'findings', 'concerning', 'for', 'evolving', 'con', '##tre', '##co', '##up', 'con', '##tus', '##ion', 'in', 'the', 'right', 'par', '##ie', '##tal', 'lobe', '.', 'given', 'somewhat', 'at', '##yp', '##ical', 'appearance', 'underlying', 'mass', 'in', 'this', 'region', 'cannot', 'be', 'excluded', 'and', 'can', 'be', 'further', 'evaluated', 'for', 'on', 'mri', '.', 'prominent', 'vein', 'of', 'could', 'reflect', 'vein', 'of', 'var', '##ix', 'which', 'can', 'also', 'be', 'further', 'evaluated', 'on', 'mri', '/', 'mr', '##v', 'large', 'frontal', 'sub', '##gal', '##eal', 'hem', '##ato', '##ma', 'and', 'non', '##dis', '##placed', 'right', 'nasal', 'bone', 'fracture', '.']\n","chunk 163 tokenize start!\n","First sentence tokenized\n","['40', 'yo', 'portuguese', 'speaking', 'woman', 'with', '/', 'un', '##res', '##ect', '##able', 'es', '##op', '##h', 'cancer', 'd', '##x', ',', 'trans', 'from', '7', '##f', 'w', '/', 'st', '##rid', '##or', 'r', '/', 't', 'acute', 'la', '##ryn', '##ge', '##al', 'ed', '##ema', ',', 'likely', 'from', 'acid', 'd', '/', 't', 'vomiting']\n","chunk 164 tokenize start!\n","First sentence tokenized\n","['ts', '##ic', '##u', 'hp', '##i', ':', '66', 'yo', '##f', 'with', 'h', '/', 'o', 'right', '-', 'sided', 'sci', '##atic', '##a', ',', 'lu', '##mbo', '##sa', '##cr', '##al', 'poly', '##rad', '##ic', '##ulo', '##pathy', ',', 'seizure', 'disorder', 's', '/', 'p', 'fall', '.', 'pan', '-', 'ct', 'negative', ',', 'but', 'on', 'ne', '##uro', 'exam', '?', 'concern', 'for', 'c', '##3', 'l', '##v', '##l', 'injury', 'chief', 'complaint', ':', 'trauma', 'pm', '##h', '##x', ':', 'pm', '##h', ':', '-', 'right', '-', 'sided', 'sci', '##atic', '##a', ',', 'as', 'above', '.', '-', 'bilateral', 'lu', '##mbo', '##sa', '##cr', '##al', 'pl', '##ex', '##itis', 'as', 'above', '-', 'right', 'temporal', 'seizure', 'disorder', '-', 'qu', '##ali', '##tative', 'plate', '##let', 'disorder', 'nos', '-', 'divert', '##ic', '##uli', '##tis', ',', 's', '/', 'p', 'left', 'cole', '##ct', '##omy', '-', 'mit', '##ral', 'valve', 'pro', '##la', '##pse', '-', 'ge', '##rd', '-', 'fi', '##bro', '##my', '##al', '##gia', '-', 'plant', '##ar', 'fa', '##sc', '##ii', '##tis', '-', 'headache', '##s', ',', 'treated', 'with', 'fi', '##oric', '##et', 'ps', '##h', ':', 'app', '##y', ',', 'tons', '##ils', ',', 'ta', '##h', 'bs', '##o', ',', ':', '-', 'lam', '##ic', '##tal', '200', 'mg', 'am', ';', '250', '##mg', 'pm', '-', 'ne', '##xi', '##um', '20', 'mg', '-', 'lyric', '##a', '100', 'mg', '-', 'ti', '##zan', '##idi', '##ne', '4', 'mg', 'ti', '##d', 'pr', '##n', 'spa', '##sm', '-', 'flora', '##stor', '-', 'calcium', 'supplement', '-', 'fl', '##ax', 'seed', '-', 'fi', '##oric', '##et', 'as', 'needed', 'for', 'headache', '-', 'recently', 'started', 'on', 'tr', '##az', '##odon', '##e', '50', '##mg', 'current', 'medications', ':', '24', 'hour', 'events', ':', 'called', 'out', 'all', '##er', '##gies', ':', 'sul', '##fo', '##nami', '##des', 'hive', '##s', ';', 'ba', '##ct', '##rim', '(', 'oral', ')', '(', 'sul', '##fa', '##met', '##ho', '##xa', '##zo', '##le', '/', 'trim', '##eth', '##op', '##rim', ')', 'unknown', ';', 'rash', ';', 'last', 'dose', 'of', 'antibiotics', ':', 'in', '##fusion', '##s', ':', 'other', 'ic', '##u', 'medications', ':', 'he', '##par', '##in', 'sodium', '(', 'prop', '##hyl', '##ax', '##is', ')', '-', '07', ':', '41', 'pm', 'other', 'medications', ':', 'flows', '##hee', '##t', 'data', 'as', 'of', '06', ':', '42', 'am', 'vital', 'signs', 'hem', '##od', '##yna', '##mic', 'monitoring', 'fluid', 'balance', '24', 'hours', 'since', 'a', '.', 'm', '.', 't', '##max', ':', '3', 'c', '(', '1', 't', 'current', ':', '4', 'c', '(', '5', 'hr', ':', '85', '(', '77', '-', '97', ')', 'bp', '##m', 'bp', ':', '87', '/', '71', '(', '75', ')', '{', '87', '/', '42', '(', '55', ')', '-', '109', '/', '71', '(', '75', ')', '}', 'mm', '##hg', 'rr', ':', '13', '(', '10', '-', '21', ')', 'ins', '##p', '/', 'min', 'sp', '##o', '##2', ':', '97', '%', 'heart', 'rhythm', ':', 'sr', '(', 'sin', '##us', 'rhythm', ')', 'w', '##gt', '(', 'current', ')', ':', '6', 'kg', '(', 'admission', ')', ':', '3', 'kg', 'height', ':', '62', 'inch', 'total', 'in', ':', '76', '##1', 'ml', 'po', ':', '720', 'ml', 'tube', 'feeding', ':', 'iv', 'fluid', ':', '41', 'ml', 'blood', 'products', ':', 'total', 'out', ':', '2', ',', '470', 'ml', '345', 'ml', 'urine', ':', '2', ',', '470', 'ml', '345', 'ml', 'ng', ':', 'stool', ':', 'drains', ':', 'balance', ':', '-', '1', ',', '70', '##9', 'ml', '-', '345', 'ml', 'respiratory', 'support', 'o', '##2', 'delivery', 'device', ':', 'nasal', 'can', '##nu', '##la', 'sp', '##o', '##2', ':', '97', '%', 'ab', '##g', ':', '/', '/', '/', '32', '/', 'physical', 'examination', 'general', 'appearance', ':', 'no', 'acute', 'distress', 'hee', '##nt', ':', 'e', '##omi', 'cardiovascular', ':', '(', 'rhythm', ':', 'regular', ')', 'respiratory', '/', 'chest', ':', '(', 'breath', 'sounds', ':', 'ct', '##a', 'bilateral', ':', ')', ',', '(', 'stern', '##um', ':', 'stable', ')', 'abdominal', ':', 'soft', ',', 'non', '-', 'di', '##sten', '##ded', ',', 'non', '-', 'tender', 'left', 'ex', '##tre', '##mit', '##ies', ':', '(', 'temperature', ':', 'warm', ')', 'right', 'ex', '##tre', '##mit', '##ies', ':', '(', 'ed', '##ema', ':', 'absent', ')', ',', '(', 'temperature', ':', 'warm', ')', 'ne', '##uro', '##logic', ':', 'follows', 'simple', 'commands', ',', 'moves', 'all', 'ex', '##tre', '##mit', '##ies', 'labs', '/', 'radio', '##logy', '284', 'k', '/', 'ul', '7', 'g', '/', 'dl', '91', 'mg', '/', 'dl', '7', 'mg', '/', 'dl', '32', 'me', '##q', '/', 'l', '6', 'me', '##q', '/', 'l', '9', 'mg', '/', 'dl', '103', 'me', '##q', '/', 'l', '143', 'me', '##q', '/', 'l', '4', '%', '4', 'k', '/', 'ul', '01', ':', '30', 'am', '02', ':', '20', 'am', '02', ':', '10', 'am', 'wb', '##c', '1', '8', '4', 'hc', '##t', '7', '1', '4', 'pl', '##t', '259', '244', '284', 'cr', '##ea', '##tin', '##ine', '8', '6', '7', 'glucose', '87', '88', '91', 'other', 'labs', ':', 'ca', ':', '9', 'mg', '/', 'dl', ',', 'mg', ':', '3', 'mg', '/', 'dl', ',', 'po', '##4', ':', '1', 'mg', '/', 'dl', 'assessment', 'and', 'plan', 'pain', 'control', '(', 'acute', 'pain', ',', 'chronic', 'pain', ')', ',', 'fall', '(', 's', ')', ',', 'impaired', 'physical', 'mobility', 'assessment', 'and', 'plan', ':', '66', 'yo', '##f', 'with', 'h', '/', 'o', 'right', '-', 'sided', 'sci', '##atic', '##a', ',', 'lu', '##mbo', '##sa', '##cr', '##al', 'poly', '##rad', '##ic', '##ulo', '##pathy', ',', 'seizure', 'disorder', 's', '/', 'p', 'fall', '.', 'pan', '-', 'ct', 'negative', ',', 'but', 'on', 'ne', '##uro', 'exam', '?', 'concern', 'for', 'c', '##3', 'l', '##v', '##l', 'injury', '.', 'ne', '##uro', '##logic', ':', 'mri', 'showed', 'chronic', 'spinal', 'changes', ',', 'including', 'ste', '##nosis', 'and', 'dj', '##d', ',', 'but', 'no', 'acute', 'changes', '.', 'in', 'soft', 'collar', 'due', 'to', 'neck', 'pain', ',', 'pain', ':', 'tram', '##ado', '##l', ',', 'lyric', '##a', ',', 'pr', '##n', 'mor', '##phine', 'cardiovascular', ':', 'stable', 'no', 'issues', 'pulmonary', ':', 'no', 'issues', 'gas', '##tro', '##int', '##estinal', '/', 'abdomen', ':', 'no', 'issues', 'nutrition', ':', 'regular', 'diet', 'renal', ':', 'adequate', 'u', '##o', 'hem', '##ato', '##logy', ':', 'qu', '##ali', '##tative', 'plate', '##let', 'dysfunction', ',', 'spoke', 'with', 'doctor', ',', 'hem', '##ato', '##logist', 'who', 'has', 'seen', 'her', 'in', 'the', 'past', ',', 'who', 'approved', 'of', 'using', 'sc', 'he', '##par', '##in', 'at', '500', '##uni', '##ts', '.', 'now', 'off', 'since', 'patient', 'no', 'longer', 'on', 'log', 'roll', 'end', '##oc', '##rine', ':', 'iss', 'infectious', 'disease', ':', 'no', 'issues', 'lines', '/', 'tubes', '/', 'drains', ':', 'pi', '##v', ',', 'soft', 'collar', 'wounds', ':', 'imaging', ':', 'fluids', ':', 'kv', '##o', 'consult', '##s', ':', 'trauma', 'surgery', ',', 'ne', '##uro', '##logy', 'billing', 'diagnosis', ':', 'ic', '##u', 'care', 'nutrition', ':', 'g', '##ly', '##ce', '##mic', 'control', ':', 'regular', 'insulin', 'sliding', 'scale', 'lines', ':', '16', 'gauge', '-', '12', ':', '40', 'pm', 'prop', '##hyl', '##ax', '##is', ':', 'd', '##v', '##t', ':', 'boots', 'stress', 'ul', '##cer', ':', 'h', '##2', 'block', '##er', 'va', '##p', 'bundle', ':', 'comments', ':', 'communication', ':', 'ic', '##u', 'consent', 'signed', 'comments', ':', 'code', 'status', ':', 'full', 'code', 'disposition', ':', 'transfer', 'to', 'floor', 'total', 'time', 'spent', ':', '31']\n","chunk 165 tokenize start!\n","First sentence tokenized\n","['hp', '##i', ':', 'patient', 'is', 'a', '69', '-', 'year', '-', 'old', 'right', '-', 'handed', 'asian', 'woman', ',', 'with', 'c', '/', 'o', 'left', 'facial', 'spa', '##sms', 'since', ',', 'seen', 'by', 'doctor', 'for', 'an', 'en', '##lar', '##ging', 'left', 'ce', '##re', '##bell', '##op', '##ont', '##ine', 'angle', 'men', '##ing', '##iom', '##a', '.', 'the', 'patient', 'had', 'been', 'image', '##d', 'in', 'the', 'past', 'and', 'was', 'followed', 'by', 'sequential', 'scans', 'at', 'an', 'os', '##h', ';', 'the', 'les', '##ion', 'was', 'progressing', 'in', 'size', 'she', 'does', 'report', 'inter', '##mit', '##ted', 'and', 'cr', '##es', '##cend', '##o', 'l', 'facial', 'twitching', 'for', 'about', '3', 'years', ';', 'she', 'also', 'reports', 'l', 'complete', 'hearing', 'loss', 'and', 'intermittent', 'episodes', 'of', 'l', 'global', 'ha', '1', '-', '3', 'times', 'a', 'week', '.', 'patient', 'is', 'mandarin', 'speaking', '.', 'nk', '##da', '.', 'pm', '##h', '-', 'h', '##t', '##n', ',', 'd', '##ys', '##lip', '##ide', '##mia', 'brain', 'abs', '##ces', '##s', '(', 'cn', '##s', 'abs', '##ces', '##s', ')', 'assessment', ':', 'patient', 'had', 'cr', '##ani', '##oto', '##my', 'and', 'removal', 'of', 'ce', '##re', '##bell', '##op', '##ont', '##ine', 'angle', 'men', '##ing', '##iom', '##a', '.', 'at', 'start', 'of', 'shift', ',', 'patient', 'alert', ',', 'orient', '##ated', 'x', '##3', '(', 'per', ')', 'per', '##rl', '##a', ',', 'complain', '##s', 'of', 'headache', '.', 'at', 'midnight', 'patient', 'complaining', 'of', 'headache', ',', 'restless', '.', 'bp', 'elevated', 'becoming', 'more', 'un', '##res', '##pon', '##sive', ',', 'patient', 'brought', 'to', 'or', '.', 'action', ':', 'patient', 'had', 'mri', 'at', 'start', 'of', 'shift', '.', 'ne', '##uro', 'exam', 'monitored', 'q', '##2', 'when', 'patient', 'became', 'restless', ',', 'to', 'assess', 'for', 'confusion', 'as', 'patient', 'does', 'not', 'speak', 'english', ',', 'patient', 'refused', 'to', 'speak', 'to', '.', 'contracted', 'ne', '##uro', '-', 'who', 'came', 'and', 'reviewed', 'patient', ',', 'and', 'reviewed', 'earlier', 'mri', 'scan', '.', 'iv', 'lo', '##press', '##or', 'given', 'with', 'little', 'effect', '.', 'iv', 'hydra', '##la', '##zine', '10', '##mg', '##s', 'given', 'x', 'sb', '##p', '140', '-', '150', '2a', '##m', 'patient', 'more', 'let', '##har', '##gic', ',', 'will', 'not', 'open', 'eyes', 'to', 'speech', '.', 'no', 'vocal', '##ization', ',', 'no', 'spontaneous', 'movement', ',', 'does', 'not', 'follow', 'commands', '.', 'will', 'withdrawn', 'to', 'painful', 'stimuli', '.', 'ne', '##uro', 'and', 'came', 'to', 'review', 'patient', '.', 'ct', '##scan', 'ordered', 'and', 'obtained', '.', 'patient', 'brought', 'to', 'or', 'for', 'evacuation', 'of', 'bleed', '.', 'attempted', 'to', 'contact', 'family', 'to', 'inform', 'them', 'of', 'patients', 'condition', '.', 'response', ':', 'patient', 'ct', '##scan', 'showed', 'bleed', 'patient', 'brought', 'to', 'or', 'plan', ':', 'continue', 'to', 'monitor']\n","chunk 166 tokenize start!\n","First sentence tokenized\n","['altered', 'mental', 'status', '(', 'not', 'del', '##iri', '##um', ')', 'assessment', ':', 'eyes', 'remain', 'open', ',', 'but', 'un', '##res', '##pon', '##sive', '.', 'hyper', '##dy', '##nami', '##c', 'at', 'times', '.', 'mae', '?', 'purpose', '##fully', '.', 'pupils', 'equal', 'and', 'slug', '##gis', '##hly', 'reactive', ',', 'gag', 'impaired', '.', 'action', ':', 'assess', 'for', 'pain', 'and', 'anxiety', ',', 'med', '##icated', 'accordingly', '.', 'response', ':', 'responding', 'well', 'to', 'current', 'medication', 'regime', '##n', '.', 'plan', ':', 'continue', 'to', 'monitor', '.', 'impaired', 'skin', 'integrity', 'assessment', ':', 'see', 'flows', '##hee', '##t', 'for', 'specific', 'data', '.', 'dressing', '##s', 'all', 'dry', 'and', 'intact', '.', 'action', ':', 'turn', 'and', 'rep', '##osition', ',', 'monitor', 'skin', 'assessment', '.', 'response', ':', 'no', 'further', 'skin', 'breakdown', ',', 'wounds', 'healing', 'appropriately', '.', 'plan', ':', 'continue', 'to', 'monitor', '.', 'respiratory', 'failure', ',', 'acute', '(', 'not', 'ar', '##ds', '/', ')', 'assessment', ':', 'no', 'vent', 'changes', 'made', '.', 'rr', 'and', 'sao', '##2', 'stable', ',', 'ab', '##g', 'stable', ',', 'moderate', 'amounts', 'of', 'thick', 'yellow', 'secret', '##ions', '.', 'action', ':', 'frequent', 'su', '##ction', ',', 'pulmonary', 'toilet', 'response', ':', 'rr', 'in', 'teens', 'for', 'multiple', 'hours', 'when', 'patient', 'sleeping', 'over', 'night', '.', 'plan', ':', 'continue', 'to', 'attempt', 'to', 'we', '##an', 'towards', 'tr', '##ach', 'mask', '.']\n","chunk 167 tokenize start!\n","First sentence tokenized\n","['patient', '/', 'test', 'information', ':', 'indication', ':', 'intra', '-', 'op', 'tee', 'for', 'descending', 'thor', '##ac', '##ic', 'ao', '##rti', '##c', 'an', '##eur', '##ys', '##m', 'repair', 'height', ':', '(', 'in', ')', '64', 'weight', '(', 'lb', ')', ':', '169', 'bs', '##a', '(', 'm2', ')', ':', '82', 'm2', 'bp', '(', 'mm', 'h', '##g', ')', ':', '130', '/', '69', 'hr', '(', 'bp', '##m', ')', ':', '66', 'status', ':', 'in', '##patient', 'date', '/', 'time', ':', 'at', '13', ':', '16', 'test', ':', 'tee', '(', 'complete', ')', 'do', '##pp', '##ler', ':', 'limited', 'do', '##pp', '##ler', 'and', 'color', 'do', '##pp', '##ler', 'contrast', ':', 'none', 'technical', 'quality', ':', 'adequate', 'interpretation', ':', 'findings', ':', 'a', ')', 'patient', 'status', 'post', '4', 'vessel', 'cab', '##g', 'and', 'ascending', 'ao', '##rta', 'as', 'well', 'as', 'arch', 'elephant', 'trunk', 'repair', 'in', 'b', ')', 'tee', 'placed', 'at', '##ra', '##umatic', '##ally', 'c', ')', 'wire', 'visual', '##ized', 'in', 'sv', '##c', 'prior', 'to', 'ri', '##j', 'cord', '##is', 'placement', 'left', 'atrium', ':', 'dil', '##ated', 'la', '.', 'right', 'atrium', '/', 'inter', '##at', '##rial', 'sept', '##um', ':', 'normal', 'ra', 'size', '.', 'normal', 'inter', '##at', '##rial', 'sept', '##um', '.', 'no', 'as', '##d', 'by', '2d', 'or', 'color', 'do', '##pp', '##ler', '.', 'left', 'vent', '##ric', '##le', ':', 'mild', 'symmetric', 'l', '##v', '##h', 'with', 'normal', 'cavity', 'size', '.', 'overall', 'normal', 'l', '##ve', '##f', '(', '>', '55', '%', ')', '.', 'right', 'vent', '##ric', '##le', ':', 'normal', 'rv', 'chamber', 'size', 'and', 'free', 'wall', 'motion', '.', 'ao', '##rta', ':', 'markedly', 'dil', '##ated', 'descending', 'ao', '##rta', 'thick', '##ened', 'ao', '##rti', '##c', 'wall', 'c', '/', 'w', 'intra', '##mura', '##l', 'hem', '##ato', '##ma', '.', 'ao', '##rti', '##c', 'valve', ':', 'mildly', 'thick', '##ened', 'ao', '##rti', '##c', 'valve', 'leaflets', '(', '3', ')', '.', 'no', 'ar', '.', 'mit', '##ral', 'valve', ':', 'mildly', 'thick', '##ened', 'mit', '##ral', 'valve', 'leaflets', '.', 'trivial', 'mr', '.', 'tri', '##cus', '##pid', 'valve', ':', 'ph', '##ys', '##iol', '##og', '##ic', 'tr', '.', 'per', '##ica', '##rdi', '##um', ':', 'trivial', '/', 'ph', '##ys', '##iol', '##og', '##ic', 'per', '##ica', '##rdial', 'e', '##ff', '##usion', '.', 'general', 'comments', ':', 'a', 'tee', 'was', 'performed', 'in', 'the', 'location', 'listed', 'above', '.', 'i', 'ce', '##rti', '##fy', 'i', 'was', 'present', 'in', 'compliance', 'with', 'hc', '##fa', 'regulations', '.', 'the', 'patient', 'was', 'under', 'general', 'an', '##esthesia', 'throughout', 'the', 'procedure', '.', 'no', 'tee', 'related', 'complications', '.', 'the', 'patient', 'appears', 'to', 'be', 'in', 'sin', '##us', 'rhythm', '.', 'results', 'were', 'personally', 'reviewed', 'with', 'the', 'md', 'caring', 'for', 'the', 'patient', '.', 'see', 'conclusions', 'for', 'post', '-', 'bypass', 'data', 'the', 'post', '-', 'bypass', 'study', 'was', 'performed', 'while', 'the', 'patient', 'was', 'receiving', 'va', '##so', '##active', 'in', '##fusion', '##s', '(', 'see', 'conclusions', 'for', 'listing', 'of', 'medications', ')', '.', '1', ')', 'ep', '##ia', '##ort', '##ic', 'images', 'ann', '##ota', '##ted', '2', ')', 'wire', 'from', 'left', 'fe', '##moral', 'artery', 'image', '##d', 'in', 'ao', '##rta', 'as', 'left', 'fe', '##moral', 'artery', 'can', '##nu', '##lated', '3', ')', 'graf', '##t', 'visual', '##ized', 'after', 'repair', 'conclusions', ':', 'the', 'left', 'atrium', 'is', 'dil', '##ated', '.', 'no', 'at', '##rial', 'sept', '##al', 'defect', 'is', 'seen', 'by', '2d', 'or', 'color', 'do', '##pp', '##ler', '.', 'there', 'is', 'mild', 'symmetric', 'left', 'vent', '##ric', '##ular', 'hyper', '##tro', '##phy', 'with', 'normal', 'cavity', 'size', '.', 'overall', 'left', 'vent', '##ric', '##ular', 'sy', '##sto', '##lic', 'function', 'is', 'normal', '(', 'l', '##ve', '##f', '>', '55', '%', ')', '.', 'right', 'vent', '##ric', '##ular', 'chamber', 'size', 'and', 'free', 'wall', 'motion', 'are', 'normal', '.', 'an', 'ascending', 'ao', '##rti', '##c', 'and', 'arch', 'graf', '##t', 'is', 'seen', 'from', 'previous', 'eu', '##rger', '##y', '.', 'the', 'descending', 'thor', '##ac', '##ic', 'ao', '##rta', 'is', 'markedly', 'dil', '##ated', '.', 'the', 'ao', '##rti', '##c', 'wall', 'is', 'thick', '##ened', 'consistent', 'with', 'an', 'intra', '##mura', '##l', 'hem', '##ato', '##ma', '.', 'the', 'ao', '##rti', '##c', 'valve', 'leaflets', '(', '3', ')', 'are', 'mildly', 'thick', '##ened', '.', 'no', 'ao', '##rti', '##c', 'reg', '##urg', '##itation', 'is', 'seen', '.', 'the', 'mit', '##ral', 'valve', 'leaflets', 'are', 'mildly', 'thick', '##ened', '.', 'trivial', 'mit', '##ral', 'reg', '##urg', '##itation', 'is', 'seen', '.', 'there', 'is', 'a', 'trivial', '/', 'ph', '##ys', '##iol', '##og', '##ic', 'per', '##ica', '##rdial', 'e', '##ff', '##usion', '.', 'doctor', 'was', 'notified', 'in', 'person', 'of', 'the', 'result', 'post', '-', 'bypass', ':', 'for', 'the', 'post', '-', 'bypass', 'study', ',', 'the', 'patient', 'was', 'receiving', 'va', '##so', '##active', 'in', '##fusion', '##s', 'including', 'ph', '##en', '##hyl', '##ep', '##hri', '##ne', '.', 'bi', '##vent', '##ric', '##ular', 'function', 'is', 'preserved', 'a', 'descending', 'ao', '##rti', '##c', 'graf', '##t', 'is', 'seen']\n","chunk 168 tokenize start!\n","First sentence tokenized\n","['sub', '##dur', '##al', 'hem', '##or', '##rh', '##age', '(', 'sd', '##h', ')', 'assessment', ':', 'no', 'change', 'in', 'ne', '##uro', 'exam', 'from', 'previous', 'shifts', '.', 'pupils', 'equal', ',', '?', 'l', 'pupil', 'slug', '##gis', '##h', 'at', 'times', ',', 'r', 'non', '-', 'reactive', '.', 'continues', 'to', 'move', 'r', 'ex', '##tre', '##mit', '##ies', 'spontaneously', ',', 'not', 'following', 'commands', ',', 'withdraw', '##s', 'l', 'ex', '##tre', '##mit', '##ies', 'to', 'pain', '.', 'pt', 'remains', 'on', 'cp', '##ap', '5', '/', 'action', ':', 'ne', '##uro', 'exam', 'q', '##4', '##hr', '##s', ',', 'maintain', 'safety', ',', 'providing', 'appropriate', 'ic', '##u', 'care', 'response', ':', 'pt', 'remains', 'stable', ',', 'no', 'change', 'in', 'condition', 'plan', ':', 'continue', 'with', 'ne', '##uro', 'exams', ',', 'continue', 'to', 'provide', 'appropriate', 'ic', '##u', 'care', ',', 'maintain', 'pt', 'safety', ',', 'await', 'guardians', '##hip', 'decision', 'in', 'order', 'to', 'tr', '##ach', 'and', 'peg', 'pt', '.']\n","chunk 169 tokenize start!\n","First sentence tokenized\n","['admitted', 'ed', 'sob', 'ex', '##ace', '##rba', '##tion', 'of', 'cop', '##d', 'and', 'ch', '##f', '.', 'patient', 'di', '##ures', '##ed', 'developed', 'afi', '##b', '.', 'patient', 'started', 'on', 'he', '##par', '##in', 'gt', '##t', 'and', 'co', '##uma', '##din', ',', 'developed', 'numb', '##ness', '/', 'tingling', 'left', 'thigh', ',', 'ultra', 'sound', 'ne', '##g', 'for', 'd', '##v', '##t', '.', 'hc', '##t', 'started', 'dropping', '33', '-', '20', ',', 'cr', '##ea', '##t', 'elevated', 'patient', 'had', 'episode', 'of', 'h', '##yp', '##ote', '##ns', '##ion', 'was', 'treated', 'with', 'iv', 'fluids', 'and', 'ff', '##p', '.', 'patient', 'transfer', '##ed', 'to', 'sic', '##u', 'a', ',', 'with', 'retro', '##per', '##ito', '##nea', '##l', 'bleed', ',', 'left', 'il', '##iac', 'f', '##ossa', 'hem', '##ato', '##ma', '.', 'on', 'admission', 'to', 'sic', '##u', 'a', 'patient', 'is', 'alert', 'orient', '##ated', 'x', '##3', ',', 'per', '##rl', '##a', '.', 'denies', 'chest', 'pain', ',', 'get', 'sob', 'on', 'ex', '##cre', '##tion', ',', 'on', '2', '##l', 'nc', '.', 'lungs', 'w', '##hee', '##zing', 'bilateral', 'with', 'r', '##hon', '##chi', ',', 'o', '##2', 'sat', '##s', '97', '%', '.', 'di', '##sten', '##ded', 'non', '-', 'tender', 'bs', 'noted', '.', 'patient', 'complain', '##s', 'of', 'feeling', 'b', '##lo', '##ated', 'con', '##sti', '##pate', '##d', '.', 'remains', 'np', '##o', 'until', 'further', 'review', 'by', 'team', '.', 'patient', 'in', 'afi', '##b', 'rate', '80', '-', '100', 's', ',', 'blood', 'pressure', 'stable', ',', 'see', 'ic', '##u', 'flow', 'sheet', '.', 'afi', '##bri', '##le', 'on', 'admission', ',', 'labs', 'sent', 'as', 'ordered', '.', 'patient', 'has', 'foley', 'draining', 'clear', 'yellow', 'urine', '.', 'patient', 'completed', '1', 'unit', 'of', 'blood', '.', '2', 'he', '##pl', '##ocks', 'patent', '.', 'patients', 'skin', 'intact', ',', 'had', 'ec', '##chy', '##mos', '##is', 'on', 'left', 'and', 'right', 'thighs', '.', 'pedal', 'pulses', 'present', '.', 'retro', '##per', '##ito', '##nea', '##l', 'bleed', '(', 'r', '##p', 'bleed', ')', ',', 'spontaneous', 'assessment', ':', 'action', ':', 'response', ':', 'plan', ':']\n","chunk 170 tokenize start!\n","First sentence tokenized\n","['cv', '##ic', '##u', 'hp', '##i', ':', 'pod', '1', '55', '##m', 's', '/', 'p', 'bi', '##lat', '.', 'mini', 'maze', '/', 'la', '##a', 'liga', '##tion', 'e', '##f', ':', '60', '%', 'cr', '.', ':', '8', 'w', '##t', '.', ':', '3', '##k', '##g', 'h', '##gb', '##a1', '##c', ':', '5', 'pm', '##h', '##x', ':', 'par', '##ox', '##ys', '##mal', 'a', 'flutter', '-', 's', '/', 'p', 'dc', '##c', '##v', '-', '>', 'sr', ',', 'mar', '##fan', \"'\", 's', 'syndrome', ',', 's', '/', 'p', 'ab', '##lation', ',', 'mvp', '/', 'mr', ',', 's', '/', 'p', 'app', '##y', ',', 's', '/', 'p', 'bi', '##l', '.', 'i', '##hr', 'chief', 'complaint', ':', 'pm', '##h', '##x', ':', 'current', 'medications', ':', 'ace', '##tam', '##ino', '##ph', '##en', ',', 'as', '##pi', '##rin', 'ec', ',', 'calcium', 'g', '##lu', '##cona', '##te', ',', 'ce', '##fa', '##zo', '##lin', ',', 'col', '##chi', '##cine', ',', 'dex', '##tro', '##se', '50', '%', ',', 'dil', '##tia', '##ze', '##m', ',', 'doc', '##usa', '##te', 'sodium', ',', 'hydro', '##mo', '##rp', '##hone', '(', 'dil', '##aud', '##id', ')', ',', 'indo', '##met', '##ha', '##cin', ',', 'insulin', ',', 'los', '##art', '##an', 'potassium', ',', 'magnesium', 'sulfate', ',', 'met', '##oc', '##lo', '##pr', '##ami', '##de', ',', 'met', '##op', '##rol', '##ol', 'tar', '##tra', '##te', ',', 'milk', 'of', 'mag', '##nesia', ',', 'mor', '##phine', 'sulfate', ',', 'ni', '##tro', '##gly', '##cer', '##in', ',', 'ph', '##en', '##yle', '##ph', '##rine', ',', 'potassium', 'chloride', ',', 'prop', '##af', '##eno', '##ne', 'hc', '##l', ',', 'rani', '##ti', '##dine', ',', 'sodium', 'chloride', '9', '%', 'flush', ',', 'war', '##far', '##in', '24', 'hour', 'events', ':', 'int', '##uba', '##tion', '-', 'at', '03', ':', '57', 'pm', 'int', '##uba', '##ted', 'from', 'or', 'invasive', 'ventilation', '-', 'start', '03', ':', '57', 'pm', 'arterial', 'line', '-', 'start', '04', ':', '00', 'pm', 'multi', 'lu', '##men', '-', 'start', '04', ':', '42', 'pm', 'ex', '##tub', '##ation', '-', 'at', '07', ':', '15', 'pm', 'invasive', 'ventilation', '-', 'stop', '07', ':', '15', 'pm', 'post', 'operative', 'day', ':', 'pod', '1', '55', '##m', 's', '/', 'p', 'bi', '##lat', '.', 'mini', 'maze', '/', 'la', '##a', 'liga', '##tion', 'all', '##er', '##gies', ':', 'pen', '##ici', '##llins', 'rash', ';', 'last', 'dose', 'of', 'antibiotics', ':', 'ce', '##fa', '##zo', '##lin', '-', '08', ':', '00', 'am', 'in', '##fusion', '##s', ':', 'other', 'ic', '##u', 'medications', ':', 'mor', '##phine', 'sulfate', '-', '07', ':', '08', 'pm', 'other', 'medications', ':', 'flows', '##hee', '##t', 'data', 'as', 'of', '12', ':', '49', 'pm', 'vital', 'signs', 'hem', '##od', '##yna', '##mic', 'monitoring', 'fluid', 'balance', '24', 'hours', 'since', 'a', '.', 'm', '.', 't', '##max', ':', '6', 'c', '(', '7', 't', 'current', ':', '2', 'c', '(', '99', 'hr', ':', '86', '(', '86', '-', '106', ')', 'bp', '##m', 'bp', ':', '110', '/', '61', '(', '73', ')', '{', '110', '/', '61', '(', '73', ')', '-', '117', '/', '69', '(', '79', ')', '}', 'mm', '##hg', 'rr', ':', '15', '(', '9', '-', '18', ')', 'ins', '##p', '/', 'min', 'sp', '##o', '##2', ':', '97', '%', 'heart', 'rhythm', ':', 'sr', '(', 'sin', '##us', 'rhythm', ')', 'w', '##gt', '(', 'current', ')', ':', '80', 'kg', '(', 'admission', ')', ':', '4', 'kg', 'height', ':', '73', 'inch', 'cv', '##p', ':', '8', '(', '0', '-', '11', ')', 'mm', '##hg', 'total', 'in', ':', '4', ',', '81', '##7', 'ml', '94', '##5', 'ml', 'po', ':', '240', 'ml', '620', 'ml', 'tube', 'feeding', ':', 'iv', 'fluid', ':', '4', ',', '57', '##7', 'ml', '325', 'ml', 'blood', 'products', ':', 'total', 'out', ':', '1', ',', '71', '##6', 'ml', '67', '##8', 'ml', 'urine', ':', '1', ',', '330', 'ml', '57', '##4', 'ml', 'ng', ':', 'stool', ':', 'drains', ':', 'balance', ':', '3', ',', '101', 'ml', '267', 'ml', 'respiratory', 'support', 'o', '##2', 'delivery', 'device', ':', 'none', 'vent', '##ila', '##tor', 'mode', ':', 'cp', '##ap', '/', 'ps', '##v', 'sp', '##o', '##2', ':', '97', '%', 'ab', '##g', ':', '40', '/', '34', '/', '203', '/', '23', '/', '-', '2', 'physical', 'examination', 'general', 'appearance', ':', 'no', 'acute', 'distress', 'hee', '##nt', ':', 'per', '##rl', 'cardiovascular', ':', '(', 'rhythm', ':', 'regular', ')', 'respiratory', '/', 'chest', ':', '(', 'expansion', ':', 'symmetric', ')', ',', '(', 'breath', 'sounds', ':', 'ct', '##a', 'bilateral', ':', ')', 'abdominal', ':', 'soft', ',', 'non', '-', 'di', '##sten', '##ded', ',', 'non', '-', 'tender', ',', 'bow', '##el', 'sounds', 'present', 'left', 'ex', '##tre', '##mit', '##ies', ':', '(', 'ed', '##ema', ':', 'trace', ')', ',', '(', 'temperature', ':', 'warm', ')', ',', '(', 'pulse', '-', 'dorsal', '##is', 'pe', '##dis', ':', 'present', ')', ',', '(', 'pulse', '-', 'posterior', 'ti', '##bial', ':', 'present', ')', 'right', 'ex', '##tre', '##mit', '##ies', ':', '(', 'ed', '##ema', ':', 'trace', ')', ',', '(', 'temperature', ':', 'warm', ')', ',', '(', 'pulse', '-', 'dorsal', '##is', 'pe', '##dis', ':', 'present', ')', ',', '(', 'pulse', '-', 'posterior', 'ti', '##bial', ':', 'present', ')', 'skin', ':', '(', 'inc', '##ision', ':', 'clean', '/', 'dry', '/', 'intact', ')', 'ne', '##uro', '##logic', ':', '(', 'awake', '/', 'alert', '/', 'oriented', ':', 'x', '3', ')', ',', 'follows', 'simple', 'commands', ',', 'moves', 'all', 'ex', '##tre', '##mit', '##ies', 'labs', '/', 'radio', '##logy', '351', 'k', '/', 'ul', '7', 'g', '/', 'dl', '107', 'mg', '/', 'dl', '7', 'mg', '/', 'dl', '23', 'me', '##q', '/', 'l', '2', 'me', '##q', '/', 'l', '13', 'mg', '/', 'dl', '102', 'me', '##q', '/', 'l', '137', 'me', '##q', '/', 'l', '7', '%', '7', 'k', '/', 'ul', '04', ':', '25', 'pm', '04', ':', '29', 'pm', '05', ':', '54', 'pm', '06', ':', '40', 'pm', '07', ':', '04', 'pm', '11', ':', '04', 'pm', '11', ':', '12', 'pm', '05', ':', '55', 'am', 'wb', '##c', '8', '7', 'hc', '##t', '0', '3', '7', 'pl', '##t', '326', '351', 'cr', '##ea', '##tin', '##ine', '6', '7', 'tc', '##o', '##2', '29', '24', '22', '22', 'glucose', '130', '119', '132', '107', 'other', 'labs', ':', 'pt', '/', 'pt', '##t', '/', 'in', '##r', ':', '4', '/', '9', '/', '5', 'imaging', ':', 'c', '##x', '##r', ':', 'all', 'lines', 'in', 'good', 'placement', 'micro', '##biology', ':', 'ne', '##g', 'assessment', 'and', 'plan', 'problem', '-', 'enter', 'description', 'in', 'comments', 'assessment', 'and', 'plan', ':', 'pt', '.', 'doing', 'very', 'well', 'post', 'op', '.', 'had', 'nerve', 'blocks', 'repeated', 'today', '.', 'will', 'd', '/', 'c', 'chest', 'tubes', '.', 'transfer', 'to', 'floor', '.', 'start', 'anti', '##co', '##ag', '##ulation', 'with', 'co', '##uma', '##din', '.', 'con', '##t', '.', 'present', 'care', '.', 'ne', '##uro', '##logic', ':', 'cardiovascular', ':', 'as', '##pi', '##rin', 'pulmonary', ':', 'is', 'gas', '##tro', '##int', '##estinal', '/', 'abdomen', ':', 'nutrition', ':', 'advance', 'diet', 'as', 'tolerated', 'renal', ':', 'foley', 'hem', '##ato', '##logy', ':', 'end', '##oc', '##rine', ':', 'ri', '##ss', 'infectious', 'disease', ':', 'ne', '##g', 'lines', '/', 'tubes', '/', 'drains', ':', 'foley', ',', 'chest', 'tube', '-', 'pl', '##eur', '##al', 'wounds', ':', 'dry', 'dressing', '##s', 'imaging', ':', 'c', '##x', '##r', 'today', 'fluids', ':', 'consult', '##s', ':', 'p', '.', 't', '.', 'ic', '##u', 'care', 'nutrition', ':', 'g', '##ly', '##ce', '##mic', 'control', ':', 'regular', 'insulin', 'sliding', 'scale', 'lines', ':', 'arterial', 'line', '-', '04', ':', '00', 'pm', 'multi', 'lu', '##men', '-', '04', ':', '42', 'pm', '16', 'gauge', '-', '04', ':', '43', 'pm', 'prop', '##hyl', '##ax', '##is', ':', 'd', '##v', '##t', ':', 'boots', '(', 'systemic', 'anti', '##co', '##ag', '##ulation', ':', 'co', '##uma', '##din', '(', 'r', ')', ')', 'stress', 'ul', '##cer', ':', 'h', '##2', 'block', '##er', 'va', '##p', 'bundle', ':', 'comments', ':', 'communication', ':', 'patient', 'discussed', 'on', 'interdisciplinary', 'rounds', 'comments', ':', 'code', 'status', ':', 'full', 'code', 'disposition', ':', 'transfer', 'to', 'floor']\n","chunk 171 tokenize start!\n","First sentence tokenized\n","['sic', '##u', 'hp', '##i', ':', '68', '##m', 'with', 'et', '##oh', 'ci', '##rr', '##hosis', 'found', 'to', 'have', 'sm', '##v', 'th', '##rom', '##bos', '##is', ',', 's', '/', 'p', 'ex', '##la', '##p', 'and', 'ile', '##al', 'res', '##ection', 'for', 'is', '##che', '##mic', 'bow', '##el', ',', 'end', '-', 'end', 'ana', '##sto', '##mos', '##is', '(', ')', '.', 'second', 'look', 'revealed', 'healthy', 'bow', '##el', '.', 'underwent', 'successful', 'or', '##th', '##oto', '##pic', 'liver', 'transplant', 'cb', 'high', 'volume', 'as', '##cite', '##s', 'returned', 'to', 'or', 'for', 'ana', '##sta', '##mos', '##is', 'leak', 'with', 'improvement', 'in', 'as', '##cite', '##s', '.', 'chief', 'complaint', ':', 'ci', '##rr', '##hosis', 's', '/', 'p', 'ot', '##l', 'transplant', 'pm', '##h', '##x', ':', 'pm', '##h', ':', 'et', '##oh', 'ci', '##rr', '##hosis', 'w', '/', 'as', '##cite', '##s', 'on', 'tr', '##as', '##pl', '##ant', 'list', ',', 'portal', 'h', '##t', '##n', ',', 'var', '##ices', ',', 'sp', '##len', '##ome', '##gal', '##y', ',', 'h', '##t', '##n', ',', 'st', '##rh', '##ini', '##ts', ',', 'art', '##hiti', '##s', ',', 's', '/', 'p', 'l', 't', '##kr', '##ress', 'ne', '##g', ',', 'echo', 'e', '##f', '>', '60', '%', ',', 'd', '##m', ',', 'asthma', '/', 'cop', '##d', ',', 'allergic', 'current', 'medications', ':', '1000', 'ml', 'd', '##5', '1', '/', '2', '##ns', 'al', '##bu', '##terol', 'in', '##hale', '##r', 'doc', '##usa', '##te', 'sodium', 'flu', '##cona', '##zo', '##le', 'flu', '##tica', '##son', '##e', 'prop', '##ion', '##ate', 'nasal', 'he', '##par', '##in', 'insulin', 'ip', '##rat', '##rop', '##ium', 'bro', '##mide', 'md', '##i', 'lan', '##sop', '##raz', '##ole', 'oral', 'di', '##sin', '##te', '##grating', 'tab', 'met', '##op', '##rol', '##ol', 'tar', '##tra', '##te', 'met', '##oc', '##lo', '##pr', '##ami', '##de', 'mic', '##ona', '##zo', '##le', 'powder', '2', '%', 'my', '##co', '##ph', '##eno', '##late', 'mo', '##fe', '##ti', '##l', 'ny', '##sta', '##tin', 'oral', 'suspension', 'on', '##dan', '##set', '##ron', 'pre', '##d', '##nis', '##one', 'pro', '##ch', '##lor', '##per', '##azi', '##ne', 'sodium', 'chloride', 'nasal', 'sodium', 'chloride', '9', '%', 'flush', 'sodium', 'chloride', '9', '%', 'flush', 'sodium', 'chloride', '9', '%', 'flush', 'sul', '##fa', '##met', '##h', '/', 'trim', '##eth', '##op', '##rim', 'suspension', 'ta', '##cr', '##oli', '##mus', 'val', '##gan', '##cic', '##lov', '##ir', 'suspension', 'war', '##far', '##in', '24', 'hour', 'events', ':', 'er', '##cp', '-', 'at', '01', ':', '30', 'pm', 'post', 'operative', 'day', ':', 'pod', '#', '42', '-', 'bow', '##el', 'res', '##ection', '.', 'pod', '#', '40', '-', 'ex', 'lap', 'pod', '#', '36', '-', 'liver', 'transplant', ':', 'primary', 'bile', '##du', '##ct', 'ana', '##sta', '##mos', '##is', 'to', 'sp', '##eni', '##c', 'artery', '>', 'not', 'to', 'he', '##pati', '##c', 'artery', 'pod', '#', '24', '-', 'ex', '-', 'lap', 'and', 'bow', '##el', 'res', '##ection', '.', 'abdomen', 'closed', 'and', 'va', '##c', 'dressing', 'removed', '.', 'all', '##er', '##gies', ':', 'no', 'known', 'drug', 'all', '##er', '##gies', 'last', 'dose', 'of', 'antibiotics', ':', 'flu', '##cona', '##zo', '##le', '-', '06', ':', '52', 'pm', 'amp', '##ici', '##llin', '-', '01', ':', '14', 'pm', 'gen', '##tam', '##ici', '##n', '-', '01', ':', '30', 'pm', 'in', '##fusion', '##s', ':', 'he', '##par', '##in', 'sodium', '-', '800', 'units', '/', 'hour', 'other', 'ic', '##u', 'medications', ':', 'other', 'medications', ':', 'flows', '##hee', '##t', 'data', 'as', 'of', '05', ':', '59', 'am', 'vital', 'signs', 'hem', '##od', '##yna', '##mic', 'monitoring', 'fluid', 'balance', '24', 'hours', 'since', 'a', '.', 'm', '.', 't', '##max', ':', '1', 'c', '(', '7', 't', 'current', ':', '1', 'c', '(', '9', 'hr', ':', '76', '(', '68', '-', '97', ')', 'bp', '##m', 'bp', ':', '102', '/', '55', '(', '65', ')', '{', '97', '/', '52', '(', '62', ')', '-', '124', '/', '70', '(', '82', ')', '}', 'mm', '##hg', 'rr', ':', '13', '(', '13', '-', '19', ')', 'ins', '##p', '/', 'min', 'sp', '##o', '##2', ':', '100', '%', 'heart', 'rhythm', ':', 'sr', '(', 'sin', '##us', 'rhythm', ')', 'w', '##gt', '(', 'current', ')', ':', '1', 'kg', '(', 'admission', ')', ':', '3', 'kg', 'height', ':', '72', 'inch', 'total', 'in', ':', '1', ',', '37', '##3', 'ml', '281', 'ml', 'po', ':', 'tube', 'feeding', ':', 'iv', 'fluid', ':', '1', ',', '193', 'ml', '281', 'ml', 'blood', 'products', ':', 'total', 'out', ':', '1', ',', '800', 'ml', '355', 'ml', 'urine', ':', '1', ',', '550', 'ml', '355', 'ml', 'ng', ':', 'stool', ':', 'drains', ':', '250', 'ml', 'balance', ':', '-', '42', '##7', 'ml', '-', '74', 'ml', 'respiratory', 'support', 'o', '##2', 'delivery', 'device', ':', 'aero', '##sol', '-', 'cool', ',', 'tr', '##ach', 'mask', 'sp', '##o', '##2', ':', '100', '%', 'ab', '##g', ':', '/', '/', '/', '31', '/', 'physical', 'examination', 'general', 'appearance', ':', 'no', 'acute', 'distress', 'hee', '##nt', ':', 'per', '##rl', 'cardiovascular', ':', '(', 'rhythm', ':', 'no', '(', 't', ')', 'regular', ')', 'respiratory', '/', 'chest', ':', '(', 'expansion', ':', 'symmetric', ')', ',', '(', 'breath', 'sounds', ':', 'ct', '##a', 'bilateral', ':', ')', 'abdominal', ':', 'soft', ',', 'non', '-', 'di', '##sten', '##ded', ',', 'non', '-', 'tender', ',', 'bow', '##el', 'sounds', 'present', 'left', 'ex', '##tre', '##mit', '##ies', ':', '(', 'ed', '##ema', ':', '1', '+', ')', 'right', 'ex', '##tre', '##mit', '##ies', ':', '(', 'ed', '##ema', ':', '1', '+', ')', 'labs', '/', 'radio', '##logy', '147', 'k', '/', 'ul', '7', 'g', '/', 'dl', '79', 'mg', '/', 'dl', '8', 'mg', '/', 'dl', '31', 'me', '##q', '/', 'l', '1', 'me', '##q', '/', 'l', '36', 'mg', '/', 'dl', '103', 'me', '##q', '/', 'l', '138', 'me', '##q', '/', 'l', '7', '%', '6', 'k', '/', 'ul', '03', ':', '09', 'am', '03', ':', '00', 'am', '05', ':', '46', 'pm', '02', ':', '53', 'am', '02', ':', '11', 'am', '02', ':', '00', 'am', '03', ':', '17', 'am', '03', ':', '22', 'am', '04', ':', '04', 'am', '02', ':', '50', 'am', 'wb', '##c', '3', '8', '2', '3', '2', '4', '2', '0', '6', 'hc', '##t', '4', '9', '6', '7', '1', '7', '1', '4', '7', 'pl', '##t', '95', '109', '114', '118', '134', '0', '155', '146', '147', 'cr', '##ea', '##tin', '##ine', '7', '6', '7', '8', '8', '9', '1', '0', '9', '8', 'glucose', '155', '121', '125', '145', '78', '116', '135', '141', '88', '79', 'other', 'labs', ':', 'pt', '/', 'pt', '##t', '/', 'in', '##r', ':', '1', '/', '6', '/', '3', ',', 'ck', '/', 'ck', '-', 'mb', '/', 'tr', '##op', '##oni', '##n', 't', ':', '17', '/', '4', '/', '05', ',', 'alt', '/', 'as', '##t', ':', '181', '/', '202', ',', 'al', '##k', '-', 'ph', '##os', '/', 't', 'bi', '##li', ':', '85', '##4', '/', '9', ',', 'amy', '##lase', '/', 'lip', '##ase', ':', '29', '/', '15', ',', 'differential', '-', 'ne', '##uts', ':', '0', '%', ',', 'band', ':', '0', '%', ',', 'l', '##ym', '##ph', ':', '0', '%', ',', 'mono', ':', '0', '%', ',', 'e', '##os', ':', '0', '%', ',', 'fi', '##bri', '##no', '##gen', ':', '323', 'mg', '/', 'dl', ',', 'lac', '##tic', 'acid', ':', '0', 'mm', '##ol', '/', 'l', ',', 'album', '##in', ':', '2', 'g', '/', 'dl', ',', 'ld', '##h', ':', '182', 'i', '##u', '/', 'l', ',', 'ca', ':', '4', 'mg', '/', 'dl', ',', 'mg', ':', '0', 'mg', '/', 'dl', ',', 'po', '##4', ':', '4', 'mg', '/', 'dl', 'assessment', 'and', 'plan', 'h', '##yp', '##oma', '##gne', '##se', '##mia', '(', 'low', 'mag', '##nese', '##ium', ')', ',', 'liver', 'function', 'abnormalities', ',', 'as', '##cite', '##s', ',', 'ne', '##ut', '##rop', '##enia', ',', 'aero', '##bic', 'capacity', '/', 'endurance', ',', 'impaired', ',', 'air', '##way', 'clearance', ',', 'impaired', ',', 'balance', ',', 'impaired', ',', 'arousal', ',', 'attention', ',', 'and', 'cognition', ',', 'impaired', ',', 'muscle', 'perform', '##ace', ',', 'impaired', ',', 'knowledge', ',', 'impaired', ',', 'joint', 'mobility', ',', 'impaired', ',', '.', 'h', '/', 'o', 'hem', '##or', '##rh', '##age', '/', 'hem', '##ato', '##ma', ',', 'procedure', '-', 'related', '(', 'e', '.', 'g', '.', ',', 'cat', '##h', ',', 'pace', '##maker', ',', 'ic', '##d', 'bleed', ')', ',', 'problem', '-', 'enter', 'description', 'in', 'comments', ',', 'respiratory', 'failure', ',', 'chronic', ',', 'transplant', ',', 'liver', ',', 'electro', '##ly', '##te', '&', 'fluid', 'disorder', ',', 'other', ',', 'end', '##oc', '##rid', '##ine', 'disorder', ',', 'other', ',', 'int', '##estinal', 'is', '##che', '##mia', '(', 'including', 'me', '##sen', '##ter', '##ic', 've', '##nous', '/', 'arterial', 'th', '##rom', '##bos', '##is', ',', 'bow', '##el', 'is', '##che', '##mia', ')', ',', 'h', '##yp', '##ote', '##ns', '##ion', '(', 'not', 'shock', ')', ',', 'ci', '##rr', '##hosis', 'of', 'liver', ',', 'alcoholic', ',', 'an', '##emia', ',', 'other', ',', 'altered', 'mental', 'status', '(', 'not', 'del', '##iri', '##um', ')', 'assessment', 'and', 'plan', ':', '68', 'y', '/', 'o', 's', '/', 'p', 'or', '##th', '##oto', '##pic', 'liver', 'transplant', 'c', '/', 'b', 'ile', '##al', 'leak', 's', '/', 'p', 'take', '##back', 'and', 'repair', '.', 'also', 'with', 'sm', '##v', 'th', '##rom', '##bos', '##is', 'being', 'treated', 'with', 'anti', '##co', '##ag', '##ulation', '.', 'now', 'with', 'rising', 'al', '##k', 'ph', '##os', '.', 'ne', '##uro', '##logic', ':', 'follows', 'commands', ',', 'no', 'se', '##dation', 'or', 'pain', 'med', '##s', 'cardiovascular', ':', 'lo', '##press', '##or', '5', 'ti', '##d', 'for', 'hyper', '##tension', ',', 'keep', 'on', 'board', 'for', 'afl', '##utter', '/', 'afi', '##b', 'control', 'pulmonary', ':', 'tr', '##ach', ',', 'con', '##t', 'tr', '##ach', 'mask', 'gas', '##tro', '##int', '##estinal', '/', 'abdomen', ':', 'full', 'strength', 't', '##f', 'on', 'hold', 'until', 'post', 'p', '##yl', '##oric', 'do', '##bo', '##ff', 'can', 'be', 'confirmed', ',', 'al', '##k', 'ph', '##os', 'trend', '##ing', 'upward', '.', 'continue', 'to', 'follow', 'l', '##ft', '##s', ',', 'va', '##c', 'changed', ',', 'er', '##cp', 'done', ',', 'normal', 'study', 'nutrition', ':', 'tube', 'feeding', 'renal', ':', 'foley', 'hem', '##ato', '##logy', ':', 'started', 'co', '##uma', '##din', 'and', 'he', '##par', '##in', 'post', 'er', '##cp', 'end', '##oc', '##rine', ':', 'ri', '##ss', 'infectious', 'disease', ':', 'lines', '/', 'tubes', '/', 'drains', ':', 'foley', ',', 'do', '##bh', '##off', ',', 'to', 'ir', 'for', 'do', '##bo', '##ff', 'placement', 'if', 'has', 'not', 'migrated', 'post', 'p', '##yl', '##oric', 'wounds', ':', 'imaging', ':', 'c', '##x', '##r', 'today', 'fluids', ':', 'kv', '##o', 'consult', '##s', ':', 'transplant', 'billing', 'diagnosis', ':', 'ic', '##u', 'care', 'nutrition', ':', 'g', '##ly', '##ce', '##mic', 'control', ':', 'regular', 'insulin', 'sliding', 'scale', 'lines', ':', 'pic', '##c', 'line', '-', '02', ':', '26', 'pm', 'prop', '##hyl', '##ax', '##is', ':', 'd', '##v', '##t', ':', 'boots', '(', 'systemic', 'anti', '##co', '##ag', '##ulation', ':', 'he', '##par', '##in', 'drip', ',', 'co', '##uma', '##din', '(', 'r', ')', ')', 'stress', 'ul', '##cer', ':', 'va', '##p', 'bundle', ':', 'comments', ':', 'communication', ':', 'comments', ':', 'code', 'status', ':', 'full', 'code', 'disposition', ':', 'total', 'time', 'spent', ':']\n","chunk 172 tokenize start!\n","First sentence tokenized\n","['demographics', 'air', '##way', 'air', '##way', 'placement', 'data', 'reason', ':', 'known', 'difficult', 'int', '##uba', '##tion', ':', 'no', 'procedure', 'location', ':', 'tube', 'type', 'et', '##t', ':', 'position', ':', 'cm', 'at', 'teeth', 'route', ':', 'nasal', 'type', ':', 'standard', 'size', ':', '5', '##mm', 'cuff', 'management', ':', 'vol', '/', 'press', ':', 'cuff', 'pressure', ':', '28', 'cm', '##h', '##2', '##o', 'cuff', 'volume', ':', 'ml', '/', 'air', 'lung', 'sounds', 'r', '##ll', 'lung', 'sounds', ':', 'diminished', 'ru', '##l', 'lung', 'sounds', ':', 'r', '##hon', '##chi', 'lu', '##l', 'lung', 'sounds', ':', 'r', '##hon', '##chi', 'll', '##l', 'lung', 'sounds', ':', 'diminished', 'comments', ':', 'secret', '##ions', 'sp', '##ut', '##um', 'color', '/', 'consistency', ':', 'yellow', '/', 'thick', 'sp', '##ut', '##um', 'source', '/', 'amount', ':', 'su', '##ction', '##ed', '/', 'scan', '##t', 'comments', ':', 'ventilation', 'assessment', 'level', 'of', 'breathing', 'assistance', ':', 'continuous', 'invasive', 'ventilation', 'visual', 'assessment', 'of', 'breathing', 'pattern', ':', 'normal', 'quiet', 'breathing', 'assessment', 'of', 'breathing', 'comfort', ':', 'no', 'claim', 'of', 'd', '##ys', '##p', '##nea', ')', 'non', '-', 'invasive', 'ventilation', 'assessment', ':', 'invasive', 'ventilation', 'assessment', ':', 'trigger', 'work', 'assessment', ':', 'triggering', 'sync', '##hr', '##ono', '##usly', 'plan', 'next', '24', '-', '48', 'hours', ':', 'maintain', 'pee', '##p', 'at', 'current', 'level', 'and', 'reduce', 'fi', '##o', '##2', 'as', 'tolerated', 'reason', 'for', 'continuing', 'current', 'vent', '##ila', '##tory', 'support', ':', 'underlying', 'illness', 'not', 'resolved']\n","chunk 173 tokenize start!\n","First sentence tokenized\n","['title', ':', '57', 'y', '##r', 'old', 'male', ',', 'with', 'd', '##m', '##2', ',', 'h', '##t', '##n', ',', 'os', '##a', 's', '/', ',', 'previous', 'ex', '-', 'lap', 'for', 'si', '##gm', '##oid', '/', 'left', 'cole', '##ct', '##omy', 'c', '/', 'b', 'color', '##ect', '##al', 'fist', '##ula', 'repaired', 'in', '99', ',', 'chronic', 'th', '##rom', '##bo', '##cy', '##top', '##enia', ',', 'h', '##t', '##n', ',', 'h', '##yp', '##oth', '##yr', '##oid', '##ism', '.', 'recently', 'd', '##x', 'with', 'prostate', 'ca', ',', 's', '/', 'p', 'elect', '##ive', 'open', 'prostate', '##ct', '##omy', '.', 'prolonged', 'fibre', '##op', '##tic', 'int', '##uba', '##tion', 'was', 'required', '.', 'got', '10', 'l', 'of', 'iv', '##f', ',', 'e', '##bl', '5', 'l', '.']\n","chunk 0 has 10000 notes\n","chunk 1 has 10000 notes\n","chunk 2 has 10000 notes\n","chunk 3 has 10000 notes\n","chunk 4 has 10000 notes\n","chunk 5 has 10000 notes\n","chunk 6 has 10000 notes\n","chunk 7 has 10000 notes\n","chunk 8 has 10000 notes\n","chunk 9 has 10000 notes\n","chunk 10 has 10000 notes\n","chunk 11 has 10000 notes\n","chunk 12 has 10000 notes\n","chunk 13 has 10000 notes\n","chunk 14 has 10000 notes\n","chunk 15 has 10000 notes\n","chunk 16 has 10000 notes\n","chunk 17 has 10000 notes\n","chunk 18 has 10000 notes\n","chunk 19 has 10000 notes\n","chunk 20 has 10000 notes\n","chunk 21 has 10000 notes\n","chunk 22 has 10000 notes\n","chunk 23 has 10000 notes\n","chunk 24 has 10000 notes\n","chunk 25 has 10000 notes\n","chunk 26 has 10000 notes\n","chunk 27 has 10000 notes\n","chunk 28 has 10000 notes\n","chunk 29 has 10000 notes\n","chunk 30 has 10000 notes\n","chunk 31 has 10000 notes\n","chunk 32 has 10000 notes\n","chunk 33 has 10000 notes\n","chunk 34 has 10000 notes\n","chunk 35 has 10000 notes\n","chunk 36 has 10000 notes\n","chunk 37 has 10000 notes\n","chunk 38 has 10000 notes\n","chunk 39 has 10000 notes\n","chunk 40 has 10000 notes\n","chunk 41 has 10000 notes\n","chunk 42 has 10000 notes\n","chunk 43 has 10000 notes\n","chunk 44 has 10000 notes\n","chunk 45 has 10000 notes\n","chunk 46 has 10000 notes\n","chunk 47 has 10000 notes\n","chunk 48 has 10000 notes\n","chunk 49 has 10000 notes\n","chunk 50 has 10000 notes\n","chunk 51 has 10000 notes\n","chunk 52 has 10000 notes\n","chunk 53 has 10000 notes\n","chunk 54 has 10000 notes\n","chunk 55 has 10000 notes\n","chunk 56 has 10000 notes\n","chunk 57 has 10000 notes\n","chunk 58 has 10000 notes\n","chunk 59 has 10000 notes\n","chunk 60 has 10000 notes\n","chunk 61 has 10000 notes\n","chunk 62 has 10000 notes\n","chunk 63 has 10000 notes\n","chunk 64 has 10000 notes\n","chunk 65 has 10000 notes\n","chunk 66 has 10000 notes\n","chunk 67 has 10000 notes\n","chunk 68 has 10000 notes\n","chunk 69 has 10000 notes\n","chunk 70 has 10000 notes\n","chunk 71 has 10000 notes\n","chunk 72 has 10000 notes\n","chunk 73 has 10000 notes\n","chunk 74 has 10000 notes\n","chunk 75 has 10000 notes\n","chunk 76 has 10000 notes\n","chunk 77 has 10000 notes\n","chunk 78 has 10000 notes\n","chunk 79 has 10000 notes\n","chunk 80 has 10000 notes\n","chunk 81 has 10000 notes\n","chunk 82 has 10000 notes\n","chunk 83 has 10000 notes\n","chunk 84 has 10000 notes\n","chunk 85 has 10000 notes\n","chunk 86 has 10000 notes\n","chunk 87 has 10000 notes\n","chunk 88 has 10000 notes\n","chunk 89 has 10000 notes\n","chunk 90 has 10000 notes\n","chunk 91 has 10000 notes\n","chunk 92 has 10000 notes\n","chunk 93 has 10000 notes\n","chunk 94 has 10000 notes\n","chunk 95 has 10000 notes\n","chunk 96 has 10000 notes\n","chunk 97 has 10000 notes\n","chunk 98 has 10000 notes\n","chunk 99 has 10000 notes\n","chunk 100 has 10000 notes\n","chunk 101 has 10000 notes\n","chunk 102 has 10000 notes\n","chunk 103 has 10000 notes\n","chunk 104 has 10000 notes\n","chunk 105 has 10000 notes\n","chunk 106 has 10000 notes\n","chunk 107 has 10000 notes\n","chunk 108 has 10000 notes\n","chunk 109 has 10000 notes\n","chunk 110 has 10000 notes\n","chunk 111 has 10000 notes\n","chunk 112 has 10000 notes\n","chunk 113 has 10000 notes\n","chunk 114 has 10000 notes\n","chunk 115 has 10000 notes\n","chunk 116 has 10000 notes\n","chunk 117 has 10000 notes\n","chunk 118 has 10000 notes\n","chunk 119 has 10000 notes\n","chunk 120 has 10000 notes\n","chunk 121 has 10000 notes\n","chunk 122 has 10000 notes\n","chunk 123 has 10000 notes\n","chunk 124 has 10000 notes\n","chunk 125 has 10000 notes\n","chunk 126 has 10000 notes\n","chunk 127 has 10000 notes\n","chunk 128 has 10000 notes\n","chunk 129 has 10000 notes\n","chunk 130 has 10000 notes\n","chunk 131 has 10000 notes\n","chunk 132 has 10000 notes\n","chunk 133 has 10000 notes\n","chunk 134 has 10000 notes\n","chunk 135 has 10000 notes\n","chunk 136 has 10000 notes\n","chunk 137 has 10000 notes\n","chunk 138 has 10000 notes\n","chunk 139 has 10000 notes\n","chunk 140 has 10000 notes\n","chunk 141 has 10000 notes\n","chunk 142 has 10000 notes\n","chunk 143 has 10000 notes\n","chunk 144 has 10000 notes\n","chunk 145 has 10000 notes\n","chunk 146 has 10000 notes\n","chunk 147 has 10000 notes\n","chunk 148 has 10000 notes\n","chunk 149 has 10000 notes\n","chunk 150 has 10000 notes\n","chunk 151 has 10000 notes\n","chunk 152 has 10000 notes\n","chunk 153 has 10000 notes\n","chunk 154 has 10000 notes\n","chunk 155 has 10000 notes\n","chunk 156 has 10000 notes\n","chunk 157 has 10000 notes\n","chunk 158 has 10000 notes\n","chunk 159 has 10000 notes\n","chunk 160 has 10000 notes\n","chunk 161 has 10000 notes\n","chunk 162 has 10000 notes\n","chunk 163 has 10000 notes\n","chunk 164 has 10000 notes\n","chunk 165 has 10000 notes\n","chunk 166 has 10000 notes\n","chunk 167 has 10000 notes\n","chunk 168 has 10000 notes\n","chunk 169 has 10000 notes\n","chunk 170 has 10000 notes\n","chunk 171 has 10000 notes\n","chunk 172 has 10000 notes\n","chunk 173 has 4946 notes\n","In the full dataset Positive Patients' Notes: 222164, Negative Patients' Notes: 1512782\n","Total Positive Patients' ids: 5276, Total Negative Patients' ids: 51746\n","In the train dataset Positive Patients' Notes: 177864, Negative  Patients' Notes: 123393\n","In the validation dataset Positive Patients' Notes: 22991, Negative Patients' Notes: 16044\n","In the test dataset Positive Patients' Notes: 21309, Negative Patients' Notes: 17326\n","In the not use dataset Negative Patients' Notes: 1356019\n","Data saved in the ../clinical-bert-data\n"]}]},{"cell_type":"code","source":["# Chunks the data\n","%cd ../\n","!python ./FTL-Trans/split_into_chunk.py \\\n","  --data_dir \"/content/drive/MyDrive/CS598-DL-Healthcare/clinical-bert-data\" \\\n","  --train_data \"train.csv\" \\\n","  --val_data \"val.csv\" \\\n","  --test_data \"test.csv\" \\\n","  --log_path \"log.txt\" \\\n","  --output_dir \"clinical-bert-chunks\" \\\n","  --max_seq_length 128"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YCDpYLNwk-74","executionInfo":{"status":"ok","timestamp":1746384731318,"user_tz":300,"elapsed":123808,"user":{"displayName":"Ryan Kupiec","userId":"06324388248644264738"}},"outputId":"1d32c939-6482-41a3-ba97-d0dfb3de71fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/CS598-DL-Healthcare\n","New Split Job Start! \n","data_dir: /content/drive/MyDrive/CS598-DL-Healthcare/clinical-bert-data, train_data: train.csv, val_data: val.csv, test_data: test.csv \n","log_path: log.txt, output_dir: clinical-bert-chunks, max_seq_length: 128\n","100% 301257/301257 [00:38<00:00, 7904.87it/s]\n","100% 39035/39035 [00:04<00:00, 7818.53it/s]\n","100% 38635/38635 [00:04<00:00, 7772.62it/s]\n","In the train dataset Positive Patients' Chunks: 679334, Negative Patients' Chunks: 400818\n","In the validation dataset Positive Patients' Chunks: 89974, Negative Patients' Chunks: 53329\n","In the test dataset Positive Patients' Chunks: 86711, Negative Patients' Chunks: 54324\n","Split finished\n"]}]},{"cell_type":"code","source":["# Runs either of the models\n","#%cd ./FTL-Trans/\n","#!python3 ./run_clbert_lstm.py \\\n","!python3 ./FTL.py \\\n","  --data_dir \"../clinical-bert-chunks\" \\\n","  --train_data \"train.csv\" \\\n","  --val_data \"val.csv\" \\\n","  --test_data \"test.csv\" \\\n","  --log_path \"./log.txt\" \\\n","  --bert_model \"./ClinicalBERT_pretraining\" \\\n","  --output_dir \"./LSTM-Clinical-Bert-Mod\" \\\n","  --embed_mode all \\\n","  --task_name LSTM_Prediction \\\n","  --max_seq_length    128 \\\n","  --train_batch_size  32 \\\n","  --eval_batch_size   1 \\\n","  --learning_rate     2e-5 \\\n","  --max_chunk_num     32 \\\n","  --warmup_proportion 0.1 \\\n","  --num_train_epochs  3 \\\n","  --seed              42 \\\n","  --gradient_accumulation_steps 1 \\\n","  --save_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qlg0eqVPCYNB","executionInfo":{"status":"ok","timestamp":1746456184951,"user_tz":300,"elapsed":4084441,"user":{"displayName":"Ryan Kupiec","userId":"06324388248644264738"}},"outputId":"7df176c4-cc2e-4782-83db-69a6566be6e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["in the modeling class\n","2025-05-05 13:35:05.907130: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1746452105.928288   25832 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1746452105.934780   25832 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","05/05/2025 13:35:08 - INFO - modeling_readmission -   loading archive file ./ClinicalBERT_pretraining\n","05/05/2025 13:35:08 - INFO - modeling_readmission -   Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"max_position_embeddings\": 512,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30522\n","}\n","\n","New Job Start! Config: {'hidden_dropout_prob': 0.1, 'layer_norm_eps': 1e-12, 'initializer_range': 0.02, 'max_note_position_embedding': 1000, 'max_chunk_position_embedding': 1000, 'embed_mode': 'all', 'hidden_size': 768, 'lstm_layers': 1, 'task_name': 'LSTM_Prediction'}\n","Tokenize Start!\n","Tokenize Finished!\n","Training start!\n","[Epoch 0] train loss = 0.4420\n","[Epoch 0] val acc = 0.8513\n","[Epoch 1] train loss = 0.2743\n","[Epoch 1] val acc = 0.8655\n","[Epoch 2] train loss = 0.1831\n","[Epoch 2] val acc = 0.8788\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/CS598-DL-Healthcare/FTL-Trans/./run_clbert_lstm.py\", line 369, in <module>\n","    main()\n","  File \"/content/drive/MyDrive/CS598-DL-Healthcare/FTL-Trans/./run_clbert_lstm.py\", line 343, in main\n","    test_note_ids, test_chunk_ids, test_times\n","                                   ^^^^^^^^^^\n","NameError: name 'test_times' is not defined. Did you mean: 'test_ids'?\n"]}]},{"cell_type":"code","source":["import time\n","import os\n","import torch\n","import random\n","import argparse\n","import numpy as np\n","import pandas as pd\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from tqdm import trange\n","from torch.optim import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","\n","# ←—— updated imports —————————————————————————————————————————————\n","from transformers import BertTokenizer, BertConfig\n","# ——————————————————————————————————————————————————————————————————————\n","\n","from modeling_readmission import BertModel as ClinicalBertModel\n","from modeling_patient import FTLSTMLayer\n","from other_func import (\n","    write_log,\n","    Tokenize_with_note_id_hour,\n","    concat_by_id_list_with_note_chunk_id_time,\n","    convert_note_ids,\n","    flat_accuracy,\n","    write_performance,\n","    reorder_by_time,\n",")\n","from utils import time_batch_generator\n","from dotmap import DotMap\n","import matplotlib.pyplot as plt\n"],"metadata":{"id":"USQZdWVcEmyZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Bert-Base-Uncased Performance\n","config = DotMap(\n","        hidden_dropout_prob=0.1,\n","        layer_norm_eps=1e-12,\n","        initializer_range=0.02,\n","        max_note_position_embedding=1000,\n","        max_chunk_position_embedding=1000,\n","        embed_mode=\"all\",\n","        hidden_size=768,\n","        lstm_layers=1,\n","        task_name=\"test\",\n","    )\n","\n","test_df  = reorder_by_time(pd.read_csv(\"/content/drive/MyDrive/CS598-DL-Healthcare/bert-base-uncased-chunks/test.csv\"))\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n","MAX_LEN = 128\n","el, ei, em, eni, et = Tokenize_with_note_id_hour(test_df,  MAX_LEN, tokenizer)\n","test_inputs, test_masks, test_labels, test_times = (\n","        torch.tensor(ei, dtype=torch.long),\n","        torch.tensor(em, dtype=torch.long),\n","        torch.tensor(el, dtype=torch.float),\n","        torch.tensor(et, dtype=torch.float),\n","    )\n","test_labels, test_inputs, test_masks, test_ids, test_note_ids, test_chunk_ids, test_times = \\\n","      concat_by_id_list_with_note_chunk_id_time(test_df, el, test_inputs, test_masks,\n","                                                eni, test_times, MAX_LEN)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","bert = ClinicalBertModel.from_pretrained(\"bert-base-uncased\").to(device)\n","lstm = FTLSTMLayer(config=config, num_labels=1).to(device)\n","ckpt = torch.load(\"./Bert-Base-Uncased/ckpt_epoch2.pt\", map_location=device)\n","bert.load_state_dict(ckpt[\"bert_state\"])\n","lstm.load_state_dict(ckpt[\"lstm_state\"])\n","bert.eval(); lstm.eval()\n","\n","val_acc = 0.0\n","val_steps = 0\n","gen_val = time_batch_generator(\n","    32, test_inputs, test_labels, test_masks,\n","        test_note_ids, test_chunk_ids, test_times\n",")\n","predictions, true_labels = [], []\n","for _ in range(len(test_ids)):\n","    with torch.no_grad():\n","        b_input_ids, b_labels, b_input_mask, b_note_ids, b_chunk_ids, b_times = next(gen_val)\n","        b_input_ids = b_input_ids.to(device)\n","        b_input_mask= b_input_mask.to(device)\n","        b_new_note_ids = convert_note_ids(b_note_ids).to(device)\n","        b_chunk_ids = b_chunk_ids.unsqueeze(0).to(device)\n","        b_times     = b_times.unsqueeze(0).to(device)\n","        b_labels = torch.tensor(b_labels, dtype=torch.float, device=device).unsqueeze(0)\n","        _, pooled_output = bert(\n","            b_input_ids, attention_mask=b_input_mask, token_type_ids=None\n","        )\n","        pooled_output = pooled_output.unsqueeze(0)\n","        preds = lstm(\n","            pooled_output, b_times, b_new_note_ids.unsqueeze(0), b_chunk_ids\n","        )  # second return = logits\n","        label_ids = b_labels.detach().cpu().numpy()[0]\n","        predictions.append(preds.detach().cpu().numpy())\n","        true_labels.append(label_ids)\n","\n","    val_acc += flat_accuracy(preds.detach().cpu().numpy(),\n","                            b_labels.detach().cpu().numpy())\n","    val_steps += 1\n","\n","# Flatten the predictions and true values for aggregate Matthew's evaluation on the whole dataset\n","flat_logits = [item for sublist in predictions for item in sublist]\n","flat_predictions = np.asarray([1 if i else 0 for i in (np.array(flat_logits) >= 0.5)])\n","flat_true_labels = np.asarray(true_labels)\n","\n","from other_func import (\n","    accuracy_score, f1_score, precision_score, recall_score, matthews_corrcoef,\n","    model_auc, model_aupr\n",")\n","test_accuracy = accuracy_score(flat_true_labels, flat_predictions)\n","test_f1 = f1_score(flat_true_labels, flat_predictions, average='binary')\n","test_prec = precision_score(flat_true_labels, flat_predictions, average='binary')\n","test_rec = recall_score(flat_true_labels, flat_predictions, average='binary')\n","test_auc, _, _, _ = model_auc(flat_true_labels, flat_logits)\n","test_mc = matthews_corrcoef(flat_true_labels, flat_predictions)\n","test_aupr, _, _, _ = model_aupr(flat_true_labels, flat_logits)\n","print(\"Test Patient Level Accuracy: {}\\n\"\n","              \"Test Patient Level F1 Score: {}\\n\"\n","              \"Test Patient Level Precision: {}\\n\"\n","              \"Test Patient Level Recall: {}\\n\"\n","              \"Test Patient Level AUC: {} \\n\"\n","              \"Test Patient Level Matthew's correlation coefficient: {}\\n\"\n","              \"Test Patient Level AUPR: {} \\n\"\n","              \"All Finished!\".format(test_accuracy,\n","                                     test_f1,\n","                                     test_prec,\n","                                     test_rec,\n","                                     test_auc,\n","                                     test_mc,\n","                                     test_aupr))"],"metadata":{"id":"8rjP8IWtVs0N","executionInfo":{"status":"ok","timestamp":1746449325280,"user_tz":300,"elapsed":96440,"user":{"displayName":"Ryan Kupiec","userId":"06324388248644264738"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"70e3783d-8b0f-453b-a7b6-d8ad609be9ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Patient Level Accuracy: 0.7893738140417458\n","Test Patient Level F1 Score: 0.7819253438113949\n","Test Patient Level Precision: 0.8105906313645621\n","Test Patient Level Recall: 0.7552182163187856\n","Test Patient Level AUC: 0.8687209473983633 \n","Test Patient Level Matthew's correlation coefficient: 0.580102712061101\n","Test Patient Level AUPR: 0.8786625176824754 \n","All Finished!\n"]}]},{"cell_type":"code","source":["# Bert-Large-Uncased Performance\n","bert_cfg = BertConfig.from_pretrained(\"bert-large-uncased\")\n","bert = ClinicalBertModel.from_pretrained(\"bert-large-uncased\").to(device)\n","config = DotMap(\n","        hidden_dropout_prob=0.1,\n","        layer_norm_eps=1e-12,\n","        initializer_range=0.02,\n","        max_note_position_embedding=1000,\n","        max_chunk_position_embedding=1000,\n","        embed_mode=\"all\",\n","        hidden_size=bert_cfg.hidden_size,\n","        lstm_layers=1,\n","        task_name=\"test\",\n","    )\n","\n","test_df  = reorder_by_time(pd.read_csv(\"/content/drive/MyDrive/CS598-DL-Healthcare/bert-large-uncased-chunks/test.csv\"))\n","tokenizer = BertTokenizer.from_pretrained(\"bert-large-uncased\", do_lower_case=True)\n","MAX_LEN = 128\n","el, ei, em, eni, et = Tokenize_with_note_id_hour(test_df,  MAX_LEN, tokenizer)\n","test_inputs, test_masks, test_labels, test_times = (\n","        torch.tensor(ei, dtype=torch.long),\n","        torch.tensor(em, dtype=torch.long),\n","        torch.tensor(el, dtype=torch.float),\n","        torch.tensor(et, dtype=torch.float),\n","    )\n","test_labels, test_inputs, test_masks, test_ids, test_note_ids, test_chunk_ids, test_times = \\\n","      concat_by_id_list_with_note_chunk_id_time(test_df, el, test_inputs, test_masks,\n","                                                eni, test_times, MAX_LEN)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","bert = ClinicalBertModel.from_pretrained(\"bert-large-uncased\").to(device)\n","lstm = FTLSTMLayer(config=config, num_labels=1).to(device)\n","ckpt = torch.load(\"./Bert-Large-Uncased/ckpt_epoch2.pt\", map_location=device)\n","bert.load_state_dict(ckpt[\"bert_state\"])\n","lstm.load_state_dict(ckpt[\"lstm_state\"])\n","bert.eval(); lstm.eval()\n","\n","val_acc = 0.0\n","val_steps = 0\n","gen_val = time_batch_generator(\n","    32, test_inputs, test_labels, test_masks,\n","        test_note_ids, test_chunk_ids, test_times\n",")\n","predictions, true_labels = [], []\n","for _ in range(len(test_ids)):\n","    with torch.no_grad():\n","        b_input_ids, b_labels, b_input_mask, b_note_ids, b_chunk_ids, b_times = next(gen_val)\n","        b_input_ids = b_input_ids.to(device)\n","        b_input_mask= b_input_mask.to(device)\n","        b_new_note_ids = convert_note_ids(b_note_ids).to(device)\n","        b_chunk_ids = b_chunk_ids.unsqueeze(0).to(device)\n","        b_times     = b_times.unsqueeze(0).to(device)\n","        b_labels = torch.tensor(b_labels, dtype=torch.float, device=device).unsqueeze(0)\n","        _, pooled_output = bert(\n","            b_input_ids, attention_mask=b_input_mask, token_type_ids=None\n","        )\n","        pooled_output = pooled_output.unsqueeze(0)\n","        preds = lstm(\n","            pooled_output, b_times, b_new_note_ids.unsqueeze(0), b_chunk_ids\n","        )  # second return = logits\n","        label_ids = b_labels.detach().cpu().numpy()[0]\n","        predictions.append(preds.detach().cpu().numpy())\n","        true_labels.append(label_ids)\n","\n","    val_acc += flat_accuracy(preds.detach().cpu().numpy(),\n","                            b_labels.detach().cpu().numpy())\n","    val_steps += 1\n","\n","# Flatten the predictions and true values for aggregate Matthew's evaluation on the whole dataset\n","flat_logits = [item for sublist in predictions for item in sublist]\n","flat_predictions = np.asarray([1 if i else 0 for i in (np.array(flat_logits) >= 0.5)])\n","flat_true_labels = np.asarray(true_labels)\n","\n","from other_func import (\n","    accuracy_score, f1_score, precision_score, recall_score, matthews_corrcoef,\n","    model_auc, model_aupr\n",")\n","test_accuracy = accuracy_score(flat_true_labels, flat_predictions)\n","test_f1 = f1_score(flat_true_labels, flat_predictions, average='binary')\n","test_prec = precision_score(flat_true_labels, flat_predictions, average='binary')\n","test_rec = recall_score(flat_true_labels, flat_predictions, average='binary')\n","test_auc, _, _, _ = model_auc(flat_true_labels, flat_logits)\n","test_mc = matthews_corrcoef(flat_true_labels, flat_predictions)\n","test_aupr, _, _, _ = model_aupr(flat_true_labels, flat_logits)\n","print(\"Test Patient Level Accuracy: {}\\n\"\n","              \"Test Patient Level F1 Score: {}\\n\"\n","              \"Test Patient Level Precision: {}\\n\"\n","              \"Test Patient Level Recall: {}\\n\"\n","              \"Test Patient Level AUC: {} \\n\"\n","              \"Test Patient Level Matthew's correlation coefficient: {}\\n\"\n","              \"Test Patient Level AUPR: {} \\n\"\n","              \"All Finished!\".format(test_accuracy,\n","                                     test_f1,\n","                                     test_prec,\n","                                     test_rec,\n","                                     test_auc,\n","                                     test_mc,\n","                                     test_aupr))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pn9I_dCEXIXO","executionInfo":{"status":"ok","timestamp":1746449584593,"user_tz":300,"elapsed":226975,"user":{"displayName":"Ryan Kupiec","userId":"06324388248644264738"}},"outputId":"b4718f19-2759-414b-ce76-b024cc801e25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Patient Level Accuracy: 0.5455407969639469\n","Test Patient Level F1 Score: 0.5838401390095569\n","Test Patient Level Precision: 0.5384615384615384\n","Test Patient Level Recall: 0.6375711574952562\n","Test Patient Level AUC: 0.5744718772616472 \n","Test Patient Level Matthew's correlation coefficient: 0.09266478335988364\n","Test Patient Level AUPR: 0.5758099861445012 \n","All Finished!\n"]}]},{"cell_type":"code","source":["# Clinical-Bert Performance\n","bert_cfg = BertConfig.from_pretrained(\"./ClinicalBERT_pretraining\")\n","bert = ClinicalBertModel.from_pretrained(\"./ClinicalBERT_pretraining\").to(device)\n","config = DotMap(\n","        hidden_dropout_prob=0.1,\n","        layer_norm_eps=1e-12,\n","        initializer_range=0.02,\n","        max_note_position_embedding=1000,\n","        max_chunk_position_embedding=1000,\n","        embed_mode=\"all\",\n","        hidden_size=bert_cfg.hidden_size,\n","        lstm_layers=1,\n","        task_name=\"test\",\n","    )\n","\n","test_df  = reorder_by_time(pd.read_csv(\"/content/drive/MyDrive/CS598-DL-Healthcare/clinical-bert-chunks/test.csv\"))\n","\n","tokenizer = BertTokenizer.from_pretrained(\"./ClinicalBERT_pretraining\", do_lower_case=True)\n","MAX_LEN = 128\n","el, ei, em, eni, et = Tokenize_with_note_id_hour(test_df,  MAX_LEN, tokenizer)\n","test_inputs, test_masks, test_labels, test_times = (\n","        torch.tensor(ei, dtype=torch.long),\n","        torch.tensor(em, dtype=torch.long),\n","        torch.tensor(el, dtype=torch.float),\n","        torch.tensor(et, dtype=torch.float),\n","    )\n","test_labels, test_inputs, test_masks, test_ids, test_note_ids, test_chunk_ids, test_times = \\\n","      concat_by_id_list_with_note_chunk_id_time(test_df, el, test_inputs, test_masks,\n","                                                eni, test_times, MAX_LEN)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","bert = ClinicalBertModel.from_pretrained(\"./ClinicalBERT_pretraining\").to(device)\n","lstm = FTLSTMLayer(config=config, num_labels=1).to(device)\n","\n","ckpt = torch.load(\"./Clinical-Bert-Mod/ckpt_epoch2.pt\", map_location=device)\n","bert.load_state_dict(ckpt[\"bert_state\"])\n","lstm.load_state_dict(ckpt[\"lstm_state\"])\n","bert.eval(); lstm.eval()\n","\n","val_acc = 0.0\n","val_steps = 0\n","gen_val = time_batch_generator(\n","    32, test_inputs, test_labels, test_masks,\n","        test_note_ids, test_chunk_ids, test_times\n",")\n","predictions, true_labels = [], []\n","for _ in range(len(test_ids)):\n","    with torch.no_grad():\n","        b_input_ids, b_labels, b_input_mask, b_note_ids, b_chunk_ids, b_times = next(gen_val)\n","        b_input_ids = b_input_ids.to(device)\n","        b_input_mask= b_input_mask.to(device)\n","        b_new_note_ids = convert_note_ids(b_note_ids).to(device)\n","        b_chunk_ids = b_chunk_ids.unsqueeze(0).to(device)\n","        b_times     = b_times.unsqueeze(0).to(device)\n","        b_labels = torch.tensor(b_labels, dtype=torch.float, device=device).unsqueeze(0)\n","        _, pooled_output = bert(\n","            b_input_ids, attention_mask=b_input_mask, token_type_ids=None\n","        )\n","        pooled_output = pooled_output.unsqueeze(0)\n","        preds = lstm(\n","            pooled_output, b_times, b_new_note_ids.unsqueeze(0), b_chunk_ids\n","        )  # second return = logits\n","        label_ids = b_labels.detach().cpu().numpy()[0]\n","        predictions.append(preds.detach().cpu().numpy())\n","        true_labels.append(label_ids)\n","\n","    val_acc += flat_accuracy(preds.detach().cpu().numpy(),\n","                            b_labels.detach().cpu().numpy())\n","    val_steps += 1\n","\n","# Flatten the predictions and true values for aggregate Matthew's evaluation on the whole dataset\n","flat_logits = [item for sublist in predictions for item in sublist]\n","flat_predictions = np.asarray([1 if i else 0 for i in (np.array(flat_logits) >= 0.5)])\n","flat_true_labels = np.asarray(true_labels)\n","\n","from other_func import (\n","    accuracy_score, f1_score, precision_score, recall_score, matthews_corrcoef,\n","    model_auc, model_aupr\n",")\n","test_accuracy = accuracy_score(flat_true_labels, flat_predictions)\n","test_f1 = f1_score(flat_true_labels, flat_predictions, average='binary')\n","test_prec = precision_score(flat_true_labels, flat_predictions, average='binary')\n","test_rec = recall_score(flat_true_labels, flat_predictions, average='binary')\n","test_auc, _, _, _ = model_auc(flat_true_labels, flat_logits)\n","test_mc = matthews_corrcoef(flat_true_labels, flat_predictions)\n","test_aupr, _, _, _ = model_aupr(flat_true_labels, flat_logits)\n","print(\"Test Patient Level Accuracy: {}\\n\"\n","              \"Test Patient Level F1 Score: {}\\n\"\n","              \"Test Patient Level Precision: {}\\n\"\n","              \"Test Patient Level Recall: {}\\n\"\n","              \"Test Patient Level AUC: {} \\n\"\n","              \"Test Patient Level Matthew's correlation coefficient: {}\\n\"\n","              \"Test Patient Level AUPR: {} \\n\"\n","              \"All Finished!\".format(test_accuracy,\n","                                     test_f1,\n","                                     test_prec,\n","                                     test_rec,\n","                                     test_auc,\n","                                     test_mc,\n","                                     test_aupr))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RxqjhlkweNy3","executionInfo":{"status":"ok","timestamp":1746449981227,"user_tz":300,"elapsed":93372,"user":{"displayName":"Ryan Kupiec","userId":"06324388248644264738"}},"outputId":"bbcb606a-1575-4b9e-ba4b-6b64d9974276"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Patient Level Accuracy: 0.793168880455408\n","Test Patient Level F1 Score: 0.781563126252505\n","Test Patient Level Precision: 0.8280254777070064\n","Test Patient Level Recall: 0.7400379506641366\n","Test Patient Level AUC: 0.8816760223095176 \n","Test Patient Level Matthew's correlation coefficient: 0.5896764022644368\n","Test Patient Level AUPR: 0.8873331184376569 \n","All Finished!\n"]}]},{"cell_type":"code","source":["import time\n","import os\n","import torch\n","import random\n","import argparse\n","import numpy as np\n","import pandas as pd\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from tqdm import trange\n","from torch.optim import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","\n","# ←—— updated imports —————————————————————————————————————————————\n","from transformers import BertTokenizer, BertConfig\n","# ——————————————————————————————————————————————————————————————————————\n","\n","from modeling_readmission import BertModel as ClinicalBertModel\n","from modeling_patient import LSTMLayer\n","from other_func import (\n","    write_log,\n","    Tokenize_with_note_id_hour,\n","    concat_by_id_list_with_note_chunk_id_time,\n","    convert_note_ids,\n","    flat_accuracy,\n","    write_performance,\n","    reorder_by_time,\n",")\n","from utils import time_batch_generator\n","from dotmap import DotMap\n","import matplotlib.pyplot as plt\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","\n","# Clinical-Bert Performance\n","bert_cfg = BertConfig.from_pretrained(\"./ClinicalBERT_pretraining\")\n","bert = ClinicalBertModel.from_pretrained(\"./ClinicalBERT_pretraining\").to(device)\n","config = DotMap(\n","        hidden_dropout_prob=0.1,\n","        layer_norm_eps=1e-12,\n","        initializer_range=0.02,\n","        max_note_position_embedding=1000,\n","        max_chunk_position_embedding=1000,\n","        embed_mode=\"all\",\n","        hidden_size=bert_cfg.hidden_size,\n","        lstm_layers=1,\n","        task_name=\"test\",\n","    )\n","\n","test_df  = reorder_by_time(pd.read_csv(\"/content/drive/MyDrive/CS598-DL-Healthcare/clinical-bert-chunks/test.csv\"))\n","\n","tokenizer = BertTokenizer.from_pretrained(\"./ClinicalBERT_pretraining\", do_lower_case=True)\n","MAX_LEN = 128\n","el, ei, em, eni, et = Tokenize_with_note_id_hour(test_df,  MAX_LEN, tokenizer)\n","test_inputs, test_masks, test_labels, test_times = (\n","        torch.tensor(ei, dtype=torch.long),\n","        torch.tensor(em, dtype=torch.long),\n","        torch.tensor(el, dtype=torch.float),\n","        torch.tensor(et, dtype=torch.float),\n","    )\n","test_labels, test_inputs, test_masks, test_ids, test_note_ids, test_chunk_ids, test_times = \\\n","      concat_by_id_list_with_note_chunk_id_time(test_df, el, test_inputs, test_masks,\n","                                                eni, test_times, MAX_LEN)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","bert = ClinicalBertModel.from_pretrained(\"./ClinicalBERT_pretraining\").to(device)\n","lstm = LSTMLayer(config=config, num_labels=1).to(device)\n","\n","ckpt = torch.load(\"./LSTM-Clinical-Bert-Mod/ckpt_epoch2.pt\", map_location=device)\n","bert.load_state_dict(ckpt[\"bert_state\"])\n","lstm.load_state_dict(ckpt[\"lstm_state\"])\n","bert.eval(); lstm.eval()\n","\n","val_acc = 0.0\n","val_steps = 0\n","gen_val = time_batch_generator(\n","    32, test_inputs, test_labels, test_masks,\n","        test_note_ids, test_chunk_ids\n",")\n","predictions, true_labels = [], []\n","for _ in range(len(test_ids)):\n","    with torch.no_grad():\n","        b_input_ids, b_labels, b_input_mask, b_note_ids, b_chunk_ids = next(gen_val)\n","        b_input_ids = b_input_ids.to(device)\n","        b_input_mask= b_input_mask.to(device)\n","        b_new_note_ids = convert_note_ids(b_note_ids).to(device)\n","        b_chunk_ids = b_chunk_ids.unsqueeze(0).to(device)\n","        b_labels = torch.tensor(b_labels, dtype=torch.float, device=device).unsqueeze(0)\n","        _, pooled_output = bert(\n","            b_input_ids, attention_mask=b_input_mask, token_type_ids=None\n","        )\n","        pooled_output = pooled_output.unsqueeze(0)\n","        preds = lstm(\n","            pooled_output, b_new_note_ids.unsqueeze(0), b_chunk_ids\n","        )  # second return = logits\n","        label_ids = b_labels.detach().cpu().numpy()[0]\n","        predictions.append(preds.detach().cpu().numpy())\n","        true_labels.append(label_ids)\n","\n","    val_acc += flat_accuracy(preds.detach().cpu().numpy(),\n","                            b_labels.detach().cpu().numpy())\n","    val_steps += 1\n","\n","# Flatten the predictions and true values for aggregate Matthew's evaluation on the whole dataset\n","flat_logits = [item for sublist in predictions for item in sublist]\n","flat_predictions = np.asarray([1 if i else 0 for i in (np.array(flat_logits) >= 0.5)])\n","flat_true_labels = np.asarray(true_labels)\n","\n","from other_func import (\n","    accuracy_score, f1_score, precision_score, recall_score, matthews_corrcoef,\n","    model_auc, model_aupr\n",")\n","test_accuracy = accuracy_score(flat_true_labels, flat_predictions)\n","test_f1 = f1_score(flat_true_labels, flat_predictions, average='binary')\n","test_prec = precision_score(flat_true_labels, flat_predictions, average='binary')\n","test_rec = recall_score(flat_true_labels, flat_predictions, average='binary')\n","test_auc, _, _, _ = model_auc(flat_true_labels, flat_logits)\n","test_mc = matthews_corrcoef(flat_true_labels, flat_predictions)\n","test_aupr, _, _, _ = model_aupr(flat_true_labels, flat_logits)\n","print(\"Test Patient Level Accuracy: {}\\n\"\n","              \"Test Patient Level F1 Score: {}\\n\"\n","              \"Test Patient Level Precision: {}\\n\"\n","              \"Test Patient Level Recall: {}\\n\"\n","              \"Test Patient Level AUC: {} \\n\"\n","              \"Test Patient Level Matthew's correlation coefficient: {}\\n\"\n","              \"Test Patient Level AUPR: {} \\n\"\n","              \"All Finished!\".format(test_accuracy,\n","                                     test_f1,\n","                                     test_prec,\n","                                     test_rec,\n","                                     test_auc,\n","                                     test_mc,\n","                                     test_aupr))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"srge-ILU-9Ib","executionInfo":{"status":"ok","timestamp":1746458387342,"user_tz":300,"elapsed":70434,"user":{"displayName":"Ryan Kupiec","userId":"06324388248644264738"}},"outputId":"d8b43cb0-d907-4a9a-a688-eb3386743ad6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Patient Level Accuracy: 0.8889943074003795\n","Test Patient Level F1 Score: 0.8860759493670886\n","Test Patient Level Precision: 0.91\n","Test Patient Level Recall: 0.8633776091081594\n","Test Patient Level AUC: 0.9566375855600243 \n","Test Patient Level Matthew's correlation coefficient: 0.7790116852629192\n","Test Patient Level AUPR: 0.9586082350350303 \n","All Finished!\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1L8oSEdJSqpUvAEBstqUtFi0qLPzJp-gL","timestamp":1746512218676}],"mount_file_id":"1L8oSEdJSqpUvAEBstqUtFi0qLPzJp-gL","authorship_tag":"ABX9TyM9v3Zs0FKvF93gslysctUY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}